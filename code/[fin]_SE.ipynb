{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gk7i0ESk9Eg2",
        "tBJigVODNNlr",
        "r1hFX4yX6ePt",
        "pQZLiDdwpVIz",
        "SYZvszluRcsL",
        "nY-z98IU3iab",
        "JZwbA47wXtt3",
        "41F0TRZZiOIy",
        "jy8I3XoIY9bO",
        "v6BIietlieGN",
        "BlbvPT8ziUaO",
        "QIGEVe7r4EVT",
        "kcyYwO35qQ3m",
        "qAreuTC_J4Sd",
        "QuwyDK7gr1mZ",
        "nnYJibSEcS8y",
        "uEsR9wCuc5fw",
        "a9IgyB7oIdOp",
        "5LokeyVaXy7C",
        "NtdQqtfMszGD",
        "lzpPN4Qu3uA7",
        "PIDwYSlE3uA-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### settings"
      ],
      "metadata": {
        "id": "VAYtsFRowFsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BI3peI2NdBYU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87afd199-93b3-4323-a9de-3b73b653c8e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/test2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IZcus0-dC62",
        "outputId": "5eec0a3f-f6d8-408a-b70b-0543f4e5c45b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/test2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ASZAlzE6U0A",
        "outputId": "83edac5b-5bbf-4635-f969-f289d4876d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mutual_info_score\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from itertools import product\n",
        "\n",
        "from sklearn.model_selection import train_test_split, ParameterGrid\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from kerastuner import HyperModel, RandomSearch"
      ],
      "metadata": {
        "id": "A_RG1cczc0qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a016296-bb1d-45cb-f4a2-48a499c473fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-53f8577369e1>:19: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner import HyperModel, RandomSearch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.20 - res - standard scaler (method 1)"
      ],
      "metadata": {
        "id": "tBJigVODNNlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mutual_info_score\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from itertools import product\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from kerastuner import HyperModel, RandomSearch"
      ],
      "metadata": {
        "id": "i49cDG9VNNl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('SE_Original_(NOT SHARED) FOR USE_2020_residential.xlsx')\n",
        "X_ori = data.iloc[:, 3:27].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X_ori)\n",
        "\n",
        "# Split\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "qImcQ1pKNNmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def create_autoencoder(input_dim, encoding_dim, hidden_layers_before, hidden_layers_after, neurons_before, neurons_after):\n",
        "    # Define the input layer\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "\n",
        "    # Build the encoder part\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons_before, activation='relu', name=f'dense_encoder_{i+1}')(x)\n",
        "\n",
        "    # Bottleneck layer (encoding layer)\n",
        "    bottleneck = Dense(encoding_dim, activation='relu', name='bottleneck')(x)\n",
        "\n",
        "    # Build the decoder part\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons_after, activation='relu', name=f'dense_decoder_{i+1}')(x)\n",
        "\n",
        "    # Output layer, with the same dimension as the input\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Define the complete autoencoder model\n",
        "    autoencoder = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "lB1JbaazNNmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial tuning\n",
        "hidden_layers_options = [2, 4, 6, 8]  # Even numbers to ensure symmetry\n",
        "neurons_options = [8, 12, 16]\n",
        "encoding_dims_options = [1, 2, 3, 4, 5]\n",
        "results = []\n",
        "\n",
        "\n",
        "# Iterate through each combination of hyperparameters\n",
        "for hidden_layers in hidden_layers_options:\n",
        "    hidden_layers_before = hidden_layers // 2\n",
        "    hidden_layers_after = hidden_layers // 2\n",
        "\n",
        "    for neurons in neurons_options:\n",
        "        for encoding_dim in encoding_dims_options:\n",
        "            autoencoder = create_autoencoder(\n",
        "                input_dim=X_train.shape[1],\n",
        "                encoding_dim=encoding_dim,\n",
        "                hidden_layers_before=hidden_layers_before,\n",
        "                hidden_layers_after=hidden_layers_after,\n",
        "                neurons_before=neurons,\n",
        "                neurons_after=neurons\n",
        "            )\n",
        "            autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "            history = autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, verbose=0, validation_data=(X_test, X_test))\n",
        "\n",
        "            # Calculate average loss on the test set\n",
        "            test_loss = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
        "            results.append((hidden_layers, encoding_dim, neurons, test_loss))\n",
        "\n",
        "# Sort results by the lowest test loss and select the best two configurations\n",
        "sorted_results = sorted(results, key=lambda x: x[3])\n",
        "best_configs = sorted_results[:2]\n",
        "\n",
        "# Print best configurations for reference and show model summary\n",
        "print(\"Top two configurations:\")\n",
        "for config in best_configs:\n",
        "    hidden_layers, encoding_dim, neurons, test_loss = config\n",
        "    print(f\"Hidden layers: {hidden_layers}, Encoding dimension: {encoding_dim}, Neurons: {neurons}, Test loss: {test_loss}\")\n",
        "\n",
        "    # Recreate and display the model summary for the best configurations\n",
        "    autoencoder = create_autoencoder(\n",
        "        input_dim=X_train.shape[1],\n",
        "        encoding_dim=encoding_dim,\n",
        "        hidden_layers_before=hidden_layers // 2,\n",
        "        hidden_layers_after=hidden_layers // 2,\n",
        "        neurons_before=neurons,\n",
        "        neurons_after=neurons\n",
        "    )\n",
        "    autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "outputId": "91afb928-f87d-4836-8b04-d18d1c2b851d",
        "id": "RKnWK4R9NNmA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top two configurations:\n",
            "Hidden layers: 8, Encoding dimension: 5, Neurons: 16, Test loss: 0.4799385964870453\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m96\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m408\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,621\u001b[0m (10.24 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,621</span> (10.24 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,621\u001b[0m (10.24 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,621</span> (10.24 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden layers: 6, Encoding dimension: 4, Neurons: 16, Test loss: 0.48775815963745117\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │              \u001b[38;5;34m68\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m80\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m408\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,044\u001b[0m (7.98 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,044</span> (7.98 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,044\u001b[0m (7.98 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,044</span> (7.98 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner import Hyperband\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def build_model(hp, input_dim, hidden_layers_before, hidden_layers_after):\n",
        "    # Hyperparameters to tune\n",
        "    encoding_dim = hp.Int('encoding_dim', min_value=2, max_value=5, step=1)\n",
        "    neurons = hp.Int('neurons', min_value=6, max_value=21, step=3)\n",
        "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "    batch_size = hp.Choice('batch_size', [16, 32, 64])\n",
        "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "    # Build the model structure\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_encoder_{i+1}')(x)\n",
        "    bottleneck = Dense(encoding_dim, activation=activation, name='bottleneck')(x)\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_decoder_{i+1}')(x)\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Compile model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
        "    return model"
      ],
      "metadata": {
        "id": "BLkwFHljNNmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import Hyperband\n",
        "\n",
        "\n",
        "tuner_config_1 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=4, hidden_layers_after=4),\n",
        "    objective='val_loss', max_epochs=50, factor=3, directory='hyperparam_tuning1__0__0', project_name='model_config_1'\n",
        ")\n",
        "\n",
        "tuner_config_2 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=3, hidden_layers_after=3),\n",
        "    objective='val_loss', max_epochs=50, factor=3, directory='hyperparam_tuning2__0__0', project_name='model_config_2'\n",
        ")"
      ],
      "metadata": {
        "id": "XRMH2jBMNNmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning for configuration 1\n",
        "tuner_config_1.search(X_train, X_train, epochs=50, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get the best model for configuration 1\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebe33498-62b6-41f4-8722-da3704fadd73",
        "id": "-3zhSFI8NNmA"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 90 Complete [00h 00m 29s]\n",
            "val_loss: 0.4627886712551117\n",
            "\n",
            "Best val_loss So Far: 0.3832147717475891\n",
            "Total elapsed time: 00h 27m 28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning for configuration 2\n",
        "tuner_config_2.search(X_train, X_train, epochs=50, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get the best model for configuration 2\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c26bd21-0383-4573-a0d7-c73d3d2b7400",
        "id": "69fTnnCiNNmA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 42s]\n",
            "val_loss: 0.9605245590209961\n",
            "\n",
            "Best val_loss So Far: 0.410219669342041\n",
            "Total elapsed time: 00h 47m 40s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### regularization"
      ],
      "metadata": {
        "id": "A2Fb1kFzQj5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "id": "nMJbXQH7Qj5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_1.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_1.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30d55aa6-c82d-4279-9f0d-8a37aad97871",
        "id": "ONPq1bs9Qj5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 5, 'neurons': 12, 'learning_rate': 0.01, 'batch_size': 32, 'activation': 'tanh', 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0068'}\n",
            "\n",
            "Test Loss: 0.3832147717475891\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "[[ 1.          0.30797033  0.54945184  0.0214523   0.25289563]\n",
            " [ 0.30797033  1.          0.58627533  0.14808727  0.30258413]\n",
            " [ 0.54945184  0.58627533  1.          0.02314082  0.02965746]\n",
            " [ 0.0214523   0.14808727  0.02314082  1.         -0.34512566]\n",
            " [ 0.25289563  0.30258413  0.02965746 -0.34512566  1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer"
      ],
      "metadata": {
        "id": "t2f3KUZDQj5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract encoder and decoder from the trained autoencoder\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=best_model_config_1.get_layer('bottleneck').output)\n",
        "\n",
        "# Create a decoder model (assuming symmetric architecture)\n",
        "bottleneck_input = tf.keras.Input(shape=(encoder.output.shape[1],))\n",
        "x = bottleneck_input\n",
        "for layer_name in [l.name for l in best_model_config_1.layers if 'dense_decoder' in l.name]:\n",
        "    x = best_model_config_1.get_layer(layer_name)(x)\n",
        "decoder_output = best_model_config_1.get_layer('output_layer')(x)\n",
        "decoder = Model(inputs=bottleneck_input, outputs=decoder_output)\n"
      ],
      "metadata": {
        "id": "DoM60CJQQj5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "289vJ-2WQj5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate bottleneck contributions\n",
        "def calculate_bottleneck_contributions(autoencoder, encoder, decoder, X):\n",
        "    bottleneck_output = encoder.predict(X)\n",
        "    contributions = []\n",
        "\n",
        "    for dim in range(bottleneck_output.shape[1]):\n",
        "        # Isolate one dimension at a time\n",
        "        isolated_latent = np.zeros_like(bottleneck_output)\n",
        "        isolated_latent[:, dim] = bottleneck_output[:, dim]\n",
        "\n",
        "        # Reconstruct input using only the isolated latent dimension\n",
        "        reconstructed = decoder.predict(isolated_latent)\n",
        "\n",
        "        # Compute reconstruction loss (e.g., MSE)\n",
        "        loss = mean_squared_error(X, reconstructed)\n",
        "        contributions.append(loss)\n",
        "\n",
        "    # Normalize contributions\n",
        "    contributions = np.array(contributions)\n",
        "    normalized_contributions = 1 - (contributions / np.sum(contributions))\n",
        "\n",
        "    return normalized_contributions"
      ],
      "metadata": {
        "id": "eflSrwRtQj5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contributions\n",
        "contributions = calculate_bottleneck_contributions(best_model_config_1, encoder, decoder, X_train)\n",
        "\n",
        "# Print contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e3988a-ece6-4190-bff7-47ee3569a014",
        "id": "BAL9Ik2LQj5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.7954\n",
            "Latent Dimension 2: 0.8117\n",
            "Latent Dimension 3: 0.7506\n",
            "Latent Dimension 4: 0.8516\n",
            "Latent Dimension 5: 0.7908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the contributions so they sum to 1\n",
        "def normalize_contributions(contributions):\n",
        "    total = sum(contributions)\n",
        "    return [c / total for c in contributions]\n",
        "\n",
        "# Calculate contributions\n",
        "#contributions = calculate_bottleneck_contributions(best_model_config_1, encoder, decoder, X_train)\n",
        "\n",
        "# Normalize contributions\n",
        "normalized_contributions = normalize_contributions(contributions)\n",
        "\n",
        "# Print normalized contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(normalized_contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")\n",
        "\n",
        "# Verify they sum to 1\n",
        "print(\"Sum of Normalized Contributions:\", sum(normalized_contributions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ec7782c-eede-44a5-c51f-354e67a88cc1",
        "id": "wo8WkwcxQj5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.1989\n",
            "Latent Dimension 2: 0.2029\n",
            "Latent Dimension 3: 0.1876\n",
            "Latent Dimension 4: 0.2129\n",
            "Latent Dimension 5: 0.1977\n",
            "Sum of Normalized Contributions: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_contributions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4686bf7a-c3ae-4042-f71b-261127db0d2c",
        "id": "mILtY-lJQj5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19885344280211373,\n",
              " 0.20292241596737712,\n",
              " 0.18764130512713662,\n",
              " 0.21288798019149158,\n",
              " 0.197694855911881]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_1 = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder_model_config_1 = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer_config_1)\n",
        "bottleneck_output_1 = encoder_model_config_1.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "084f3720-bfa5-4c6c-811d-3909a0c987b8",
        "id": "7DlBQhMHQj5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions = np.array(normalized_contributions)\n",
        "\n",
        "# Calculate MI scores\n",
        "mi_scores = []\n",
        "for i in range(bottleneck_output_1.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_1[:, i], random_state=42)\n",
        "    mi_scores.append(mi)"
      ],
      "metadata": {
        "id": "6m8XqMUvQj5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d879d5-22f8-4de8-fad0-2fc2a811d066",
        "id": "SnxJoCI0Qj5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_1.shape[1]))\n",
        "\n",
        "# Multiply MI scores by latent space contributions for each bottleneck dimension\n",
        "for dim in range(bottleneck_output_1.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim] * latent_contributions[dim]"
      ],
      "metadata": {
        "id": "xN3pGXrqQj5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8606e5ad-98e9-4cff-f1b4-73da45c114fc",
        "id": "TkxtxgZ6Qj5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.19885344, 0.20292242, 0.18764131, 0.21288798, 0.19769486])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_mi_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a6813b-85ba-4302-a301-cb1d6c552619",
        "id": "-dFyQRImQj5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.07002899, 0.00512558, 0.01160491, 0.01829804, 0.0590255 ],\n",
              "       [0.        , 0.02895349, 0.01594705, 0.03066119, 0.02398362],\n",
              "       [0.03184994, 0.01501085, 0.01285349, 0.01868057, 0.08619057],\n",
              "       [0.05063481, 0.07142526, 0.05096472, 0.0548023 , 0.09137574],\n",
              "       [0.02449121, 0.02435147, 0.02120332, 0.05046647, 0.04469847],\n",
              "       [0.03257792, 0.06110832, 0.02130724, 0.0336327 , 0.04084748],\n",
              "       [0.01230042, 0.00709941, 0.02275787, 0.06576877, 0.02594564],\n",
              "       [0.11578865, 0.07002974, 0.10147225, 0.0382213 , 0.00994035],\n",
              "       [0.09259996, 0.11402428, 0.11376249, 0.08644002, 0.07510392],\n",
              "       [0.04747113, 0.05511851, 0.0917666 , 0.03027567, 0.00827904],\n",
              "       [0.03668028, 0.04834172, 0.03867838, 0.09723794, 0.03907018],\n",
              "       [0.01205423, 0.03218533, 0.05426946, 0.0656523 , 0.01717193],\n",
              "       [0.05172083, 0.03377742, 0.04068113, 0.01923531, 0.01101608],\n",
              "       [0.02902567, 0.01327519, 0.03033655, 0.07552114, 0.01370998],\n",
              "       [0.10427439, 0.09261184, 0.06777724, 0.02501816, 0.07822155],\n",
              "       [0.08139759, 0.07175696, 0.06217445, 0.03390038, 0.08814312],\n",
              "       [0.07257151, 0.03962346, 0.0205004 , 0.02084397, 0.05977866],\n",
              "       [0.00240665, 0.0138187 , 0.01701491, 0.0063947 , 0.09091302],\n",
              "       [0.00755049, 0.05249614, 0.04617539, 0.00132249, 0.05293144],\n",
              "       [0.05651012, 0.05132849, 0.08735214, 0.05043278, 0.02941803],\n",
              "       [0.02609824, 0.0471905 , 0.04106435, 0.06473097, 0.04883931],\n",
              "       [0.        , 0.02619593, 0.        , 0.04338482, 0.        ],\n",
              "       [0.03236959, 0.01796098, 0.0286407 , 0.01912459, 0.00493706],\n",
              "       [0.00959738, 0.00719042, 0.00169498, 0.04995341, 0.00045931]])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))\n",
        "\n",
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "oAewUIlVQj5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excel\n",
        "df.to_excel(\"real_org_se_AUTOENCODER_best_auto_config1_1215_with_weights_res_ss.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "UfC1coeuQj5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "config 2"
      ],
      "metadata": {
        "id": "jZlvNKKXQj5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20e4cf67-1a49-4c65-8427-e39b4923915f",
        "id": "-8OEApI1Qj5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 34 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_2.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_2.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ff003f-2f78-4e23-92f7-e5664ee27ad5",
        "id": "dnkmyVITQj5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 4, 'neurons': 18, 'learning_rate': 0.01, 'batch_size': 64, 'activation': 'relu', 'tuner/epochs': 50, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
            "\n",
            "Test Loss: 0.410219669342041\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "[[ 1.          0.29696144 -0.1367382   0.52200028]\n",
            " [ 0.29696144  1.         -0.16077114  0.74088074]\n",
            " [-0.1367382  -0.16077114  1.         -0.21152383]\n",
            " [ 0.52200028  0.74088074 -0.21152383  1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract encoder and decoder from the trained autoencoder\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=best_model_config_2.get_layer('bottleneck').output)\n",
        "\n",
        "# Create a decoder model (assuming symmetric architecture)\n",
        "bottleneck_input = tf.keras.Input(shape=(encoder.output.shape[1],))\n",
        "x = bottleneck_input\n",
        "for layer_name in [l.name for l in best_model_config_2.layers if 'dense_decoder' in l.name]:\n",
        "    x = best_model_config_2.get_layer(layer_name)(x)\n",
        "decoder_output = best_model_config_2.get_layer('output_layer')(x)\n",
        "decoder = Model(inputs=bottleneck_input, outputs=decoder_output)"
      ],
      "metadata": {
        "id": "-Jl4zxIFQj5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contributions\n",
        "contributions = calculate_bottleneck_contributions(best_model_config_2, encoder, decoder, X_train)\n",
        "\n",
        "# Print contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c836af30-6439-418a-ae22-da39f76096f5",
        "id": "QGyro_e-Qj5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.8363\n",
            "Latent Dimension 2: 0.7287\n",
            "Latent Dimension 3: 0.7776\n",
            "Latent Dimension 4: 0.6574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize contributions\n",
        "normalized_contributions = normalize_contributions(contributions)\n",
        "\n",
        "# Print normalized contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(normalized_contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")\n",
        "\n",
        "# Verify they sum to 1\n",
        "print(\"Sum of Normalized Contributions:\", sum(normalized_contributions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e6d5ba4-16ca-4412-e8b7-0a6187288fff",
        "id": "6I8JpYSXQj5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.2788\n",
            "Latent Dimension 2: 0.2429\n",
            "Latent Dimension 3: 0.2592\n",
            "Latent Dimension 4: 0.2191\n",
            "Sum of Normalized Contributions: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_2 = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder_model_config_2 = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer_config_2)\n",
        "bottleneck_output_2 = encoder_model_config_2.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec8b98ef-4c05-4957-abf9-eb5d9a217b08",
        "id": "rmIOk4YSQj5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions = np.array(normalized_contributions)  # Make sure this is normalized\n",
        "\n",
        "mi_scores = []\n",
        "for i in range(bottleneck_output_2.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_2[:, i], random_state=42)\n",
        "    mi_scores.append(mi)"
      ],
      "metadata": {
        "id": "sxcklzyFQj5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e273c8-c9e2-4c5c-ef83-9376bc8e705e",
        "id": "goL_BdvjQj5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_2.shape[1]))\n",
        "\n",
        "# Multiply MI scores by latent space contributions for each bottleneck dimension\n",
        "for dim in range(bottleneck_output_2.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim] * latent_contributions[dim]"
      ],
      "metadata": {
        "id": "PR1SXXG4Qj5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))\n",
        "\n",
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "1R3h_oSFQj5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excel\n",
        "df.to_excel(\"real_org_se_AUTOENCODER_best_auto_config2_1208_with_weights_res_ss.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "orAV3gwcQj5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_config_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "913115bd-1cd0-46fd-be89-5196b8b419c2",
        "id": "xWtkBkB0Qj5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m125\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m144\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m600\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,069\u001b[0m (19.80 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,069</span> (19.80 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,069\u001b[0m (19.80 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,069</span> (19.80 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_config_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "c8857668-128a-4c23-9dd0-42d7094bf98e",
        "id": "qdN_6bojQj5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m450\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │              \u001b[38;5;34m76\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │              \u001b[38;5;34m90\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m456\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">456</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,440\u001b[0m (9.53 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,440</span> (9.53 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,440\u001b[0m (9.53 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,440</span> (9.53 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## res - minmax scaler  (method 1)"
      ],
      "metadata": {
        "id": "pQZLiDdwpVIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('SE_Original_(NOT SHARED) FOR USE_2020_residential.xlsx')\n",
        "X_ori = data.iloc[:, 3:27].values\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X_ori)\n",
        "\n",
        "# Split\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ZC0wDsOtpVI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def create_autoencoder(input_dim, encoding_dim, hidden_layers_before, hidden_layers_after, neurons_before, neurons_after):\n",
        "    # Define the input layer\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "\n",
        "    # Build the encoder part\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons_before, activation='relu', name=f'dense_encoder_{i+1}')(x)\n",
        "\n",
        "    # Bottleneck layer (encoding layer)\n",
        "    bottleneck = Dense(encoding_dim, activation='relu', name='bottleneck')(x)\n",
        "\n",
        "    # Build the decoder part\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons_after, activation='relu', name=f'dense_decoder_{i+1}')(x)\n",
        "\n",
        "    # Output layer, with the same dimension as the input\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Define the complete autoencoder model\n",
        "    autoencoder = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "hbOA1M9YpVI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial tuning\n",
        "hidden_layers_options = [2, 4, 6, 8]  # Even numbers to ensure symmetry\n",
        "neurons_options = [8, 12, 16]\n",
        "encoding_dims_options = [1, 2, 3, 4, 5]\n",
        "results = []\n",
        "\n",
        "\n",
        "# Iterate through each combination of hyperparameters\n",
        "for hidden_layers in hidden_layers_options:\n",
        "    hidden_layers_before = hidden_layers // 2\n",
        "    hidden_layers_after = hidden_layers // 2\n",
        "\n",
        "    for neurons in neurons_options:\n",
        "        for encoding_dim in encoding_dims_options:\n",
        "            autoencoder = create_autoencoder(\n",
        "                input_dim=X_train.shape[1],\n",
        "                encoding_dim=encoding_dim,\n",
        "                hidden_layers_before=hidden_layers_before,\n",
        "                hidden_layers_after=hidden_layers_after,\n",
        "                neurons_before=neurons,\n",
        "                neurons_after=neurons\n",
        "            )\n",
        "            autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "            history = autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, verbose=0, validation_data=(X_test, X_test))\n",
        "\n",
        "            # Calculate average loss on the test set\n",
        "            test_loss = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
        "            results.append((hidden_layers, encoding_dim, neurons, test_loss))\n",
        "\n",
        "# Sort results by the lowest test loss and select the best two configurations\n",
        "sorted_results = sorted(results, key=lambda x: x[3])\n",
        "best_configs = sorted_results[:2]\n",
        "\n",
        "# Print best configurations for reference and show model summary\n",
        "print(\"Top two configurations:\")\n",
        "for config in best_configs:\n",
        "    hidden_layers, encoding_dim, neurons, test_loss = config\n",
        "    print(f\"Hidden layers: {hidden_layers}, Encoding dimension: {encoding_dim}, Neurons: {neurons}, Test loss: {test_loss}\")\n",
        "\n",
        "    # Recreate and display the model summary for the best configurations\n",
        "    autoencoder = create_autoencoder(\n",
        "        input_dim=X_train.shape[1],\n",
        "        encoding_dim=encoding_dim,\n",
        "        hidden_layers_before=hidden_layers // 2,\n",
        "        hidden_layers_after=hidden_layers // 2,\n",
        "        neurons_before=neurons,\n",
        "        neurons_after=neurons\n",
        "    )\n",
        "    autoencoder.summary()"
      ],
      "metadata": {
        "id": "uyZW8GLAjK-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner import Hyperband\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def build_model(hp, input_dim, hidden_layers_before, hidden_layers_after):\n",
        "    # Hyperparameters to tune\n",
        "    encoding_dim = hp.Int('encoding_dim', min_value=2, max_value=5, step=1)\n",
        "    neurons = hp.Int('neurons', min_value=6, max_value=24, step=3)\n",
        "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "    batch_size = hp.Choice('batch_size', [16, 32, 64])\n",
        "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "    # Build the model structure\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_encoder_{i+1}')(x)\n",
        "    bottleneck = Dense(encoding_dim, activation=activation, name='bottleneck')(x)\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_decoder_{i+1}')(x)\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Compile model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
        "    return model"
      ],
      "metadata": {
        "id": "3pUSNxu7pVI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import Hyperband\n",
        "\n",
        "# Define search space for each configuration\n",
        "tuner_config_1 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=3, hidden_layers_after=3),\n",
        "    objective='val_loss', max_epochs=50, factor=3, directory='hyperparam_tuning_1_001_0_0', project_name='model_config_1'\n",
        ")\n",
        "\n",
        "tuner_config_2 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=4, hidden_layers_after=4),\n",
        "    objective='val_loss', max_epochs=50, factor=3, directory='hyperparam_tuning_2_001_0_0', project_name='model_config_2'\n",
        ")"
      ],
      "metadata": {
        "id": "Go6NZ8gYpVI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning for configuration 1\n",
        "tuner_config_1.search(X_train, X_train, epochs=50, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get the best model for configuration 1\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea78ed02-b251-459e-8e19-2a45172ede3e",
        "id": "u0qr_A9WpVI1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 90 Complete [00h 00m 11s]\n",
            "val_loss: 0.04261470586061478\n",
            "\n",
            "Best val_loss So Far: 0.015086108818650246\n",
            "Total elapsed time: 00h 11m 21s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning for configuration 2\n",
        "tuner_config_2.search(X_train, X_train, epochs=50, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get the best model for configuration 2\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13521127-ef61-42df-91ff-1a97dda5acf3",
        "id": "uP2xSHBkpVI1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 88 Complete [00h 00m 19s]\n",
            "val_loss: 0.039806704968214035\n",
            "\n",
            "Best val_loss So Far: 0.013620617799460888\n",
            "Total elapsed time: 00h 14m 42s\n",
            "\n",
            "Search: Running Trial #89\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "4                 |5                 |encoding_dim\n",
            "12                |21                |neurons\n",
            "0.0001            |0.01              |learning_rate\n",
            "32                |32                |batch_size\n",
            "relu              |tanh              |activation\n",
            "50                |50                |tuner/epochs\n",
            "0                 |17                |tuner/initial_epoch\n",
            "0                 |3                 |tuner/bracket\n",
            "0                 |3                 |tuner/round\n",
            "\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 554ms/step - loss: 0.4000 - val_loss: 0.4131\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.3959 - val_loss: 0.4123\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3953 - val_loss: 0.4116\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3954 - val_loss: 0.4108\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3898 - val_loss: 0.4101\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3934 - val_loss: 0.4094\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3881 - val_loss: 0.4087\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3837 - val_loss: 0.4079\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3928 - val_loss: 0.4071\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3891 - val_loss: 0.4062\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3862 - val_loss: 0.4052\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3896 - val_loss: 0.4041\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3870 - val_loss: 0.4030\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3843 - val_loss: 0.4019\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3823 - val_loss: 0.4008\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3803 - val_loss: 0.3997\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3827 - val_loss: 0.3985\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3768 - val_loss: 0.3973\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3833 - val_loss: 0.3962\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3839 - val_loss: 0.3949\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3821 - val_loss: 0.3937\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3762 - val_loss: 0.3924\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3746 - val_loss: 0.3911\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3688 - val_loss: 0.3898\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3726 - val_loss: 0.3884\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3670 - val_loss: 0.3870\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3744 - val_loss: 0.3855\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3657 - val_loss: 0.3840\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3661 - val_loss: 0.3824\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3680 - val_loss: 0.3808\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3637 - val_loss: 0.3790\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3626 - val_loss: 0.3772\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3601 - val_loss: 0.3754\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3606 - val_loss: 0.3734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### regularization"
      ],
      "metadata": {
        "id": "NeZhojnnpVI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "id": "w4rSQmtSpVI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_1.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_1.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dadca22-7e51-48a1-bf4c-48b12f1779f2",
        "id": "wbgKBWwXpVI2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 5, 'neurons': 12, 'learning_rate': 0.01, 'batch_size': 64, 'activation': 'tanh', 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0049'}\n",
            "\n",
            "Test Loss: 0.015086108818650246\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "[[ 1.         -0.16989383 -0.40071922 -0.31207698 -0.08475396]\n",
            " [-0.16989383  1.          0.50516099  0.37197808 -0.05713703]\n",
            " [-0.40071922  0.50516099  1.          0.87811357 -0.23301824]\n",
            " [-0.31207698  0.37197808  0.87811357  1.         -0.11183346]\n",
            " [-0.08475396 -0.05713703 -0.23301824 -0.11183346  1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer"
      ],
      "metadata": {
        "id": "RBpajC1PpVI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract encoder and decoder from the trained autoencoder\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=best_model_config_1.get_layer('bottleneck').output)\n",
        "\n",
        "# Create a decoder model\n",
        "bottleneck_input = tf.keras.Input(shape=(encoder.output.shape[1],))\n",
        "x = bottleneck_input\n",
        "for layer_name in [l.name for l in best_model_config_1.layers if 'dense_decoder' in l.name]:\n",
        "    x = best_model_config_1.get_layer(layer_name)(x)\n",
        "decoder_output = best_model_config_1.get_layer('output_layer')(x)\n",
        "decoder = Model(inputs=bottleneck_input, outputs=decoder_output)\n"
      ],
      "metadata": {
        "id": "zzLgkf0ipVI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "68caQzXTpVI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate bottleneck contributions\n",
        "def calculate_bottleneck_contributions(autoencoder, encoder, decoder, X):\n",
        "    bottleneck_output = encoder.predict(X)\n",
        "    contributions = []\n",
        "\n",
        "    for dim in range(bottleneck_output.shape[1]):\n",
        "        # Isolate one dimension at a time\n",
        "        isolated_latent = np.zeros_like(bottleneck_output)\n",
        "        isolated_latent[:, dim] = bottleneck_output[:, dim]\n",
        "\n",
        "        # Reconstruct input using only the isolated latent dimension\n",
        "        reconstructed = decoder.predict(isolated_latent)\n",
        "\n",
        "        # Compute reconstruction loss (e.g., MSE)\n",
        "        loss = mean_squared_error(X, reconstructed)\n",
        "        contributions.append(loss)\n",
        "\n",
        "    # Normalize contributions\n",
        "    contributions = np.array(contributions)\n",
        "    normalized_contributions = 1 - (contributions / np.sum(contributions))\n",
        "\n",
        "    return normalized_contributions"
      ],
      "metadata": {
        "id": "_RlySmJJpVI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contributions\n",
        "contributions = calculate_bottleneck_contributions(best_model_config_1, encoder, decoder, X_train)\n",
        "\n",
        "# Print contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")"
      ],
      "metadata": {
        "id": "ArabkBLgpVI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d26fec7-49a9-40d0-e821-7781aae895e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f3695adfac0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 216ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f3695adfac0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.7761\n",
            "Latent Dimension 2: 0.8138\n",
            "Latent Dimension 3: 0.7645\n",
            "Latent Dimension 4: 0.8158\n",
            "Latent Dimension 5: 0.8297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the contributions so they sum to 1\n",
        "def normalize_contributions(contributions):\n",
        "    total = sum(contributions)\n",
        "    return [c / total for c in contributions]\n",
        "\n",
        "# Calculate contributions\n",
        "#contributions = calculate_bottleneck_contributions(best_model_config_1, encoder, decoder, X_train)\n",
        "\n",
        "# Normalize contributions\n",
        "normalized_contributions = normalize_contributions(contributions)\n",
        "\n",
        "# Print normalized contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(normalized_contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")\n",
        "\n",
        "# Verify they sum to 1\n",
        "print(\"Sum of Normalized Contributions:\", sum(normalized_contributions))"
      ],
      "metadata": {
        "id": "zZj9ahn2pVI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9798ce95-7764-4de6-cc97-0bb754e5103d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.1940\n",
            "Latent Dimension 2: 0.2035\n",
            "Latent Dimension 3: 0.1911\n",
            "Latent Dimension 4: 0.2040\n",
            "Latent Dimension 5: 0.2074\n",
            "Sum of Normalized Contributions: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_contributions"
      ],
      "metadata": {
        "id": "9hEtO6uBpVI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca5d27d-513b-48ac-fecb-b78bd47cec79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19403405904532117,\n",
              " 0.20345870938985638,\n",
              " 0.1911372112227145,\n",
              " 0.2039520857023381,\n",
              " 0.20741793463976987]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_1 = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder_model_config_1 = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer_config_1)\n",
        "bottleneck_output_1 = encoder_model_config_1.predict(X)"
      ],
      "metadata": {
        "id": "2F1MiNwdpVI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a8d811-31e5-4499-e512-b57ac34223e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions = np.array(normalized_contributions)\n",
        "\n",
        "# Calculate MI scores\n",
        "mi_scores = []\n",
        "for i in range(bottleneck_output_1.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_1[:, i], random_state=42)\n",
        "    mi_scores.append(mi)"
      ],
      "metadata": {
        "id": "1MJH6UVEpVI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "id": "qUanlPOxpVI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ca63915-5e3a-4c54-b434-d91407fc06ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_1.shape[1]))\n",
        "\n",
        "# Multiply MI scores by latent space contributions for each bottleneck dimension\n",
        "for dim in range(bottleneck_output_1.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim] * latent_contributions[dim]"
      ],
      "metadata": {
        "id": "flh8xUjwpVI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions"
      ],
      "metadata": {
        "id": "y9rNjig9pVI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b02b31c-26a0-419d-9807-936b900a780d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.19403406, 0.20345871, 0.19113721, 0.20395209, 0.20741793])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_mi_scores"
      ],
      "metadata": {
        "id": "nzSDe7k2pVI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53ea8f3-c04f-49f9-eb22-9a3cfb9205d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.05455457, 0.02020102, 0.02092671, 0.02279347, 0.07840452],\n",
              "       [0.0094563 , 0.00288066, 0.01862264, 0.03112839, 0.03553254],\n",
              "       [0.05116817, 0.02504367, 0.01868611, 0.01812341, 0.02813357],\n",
              "       [0.13456826, 0.06264247, 0.03143379, 0.03352727, 0.03829521],\n",
              "       [0.00183345, 0.04526236, 0.01010196, 0.00733088, 0.02467917],\n",
              "       [0.01498898, 0.04531716, 0.04054242, 0.01223486, 0.03305241],\n",
              "       [0.01799518, 0.01839382, 0.04540517, 0.0485257 , 0.03162676],\n",
              "       [0.03910827, 0.        , 0.07709839, 0.13970399, 0.00541697],\n",
              "       [0.07066447, 0.05032809, 0.13204969, 0.1717924 , 0.10998619],\n",
              "       [0.04184259, 0.01340253, 0.03213333, 0.04228886, 0.06556817],\n",
              "       [0.01984796, 0.03739627, 0.07937835, 0.05664472, 0.10804157],\n",
              "       [0.02921321, 0.02480861, 0.07088309, 0.0564372 , 0.04079494],\n",
              "       [0.04505863, 0.01419747, 0.03541828, 0.03484762, 0.02077405],\n",
              "       [0.01396048, 0.02919417, 0.0515004 , 0.04382218, 0.03613565],\n",
              "       [0.12917578, 0.01509085, 0.03320564, 0.02569613, 0.00801565],\n",
              "       [0.11523582, 0.05861028, 0.03168487, 0.03159585, 0.03097972],\n",
              "       [0.06801411, 0.02590338, 0.02921649, 0.01608409, 0.01008439],\n",
              "       [0.00215816, 0.00680241, 0.00644375, 0.00374592, 0.05546762],\n",
              "       [0.02490796, 0.01691602, 0.01833242, 0.01760401, 0.02703583],\n",
              "       [0.02158225, 0.02954639, 0.06694342, 0.05857386, 0.07862088],\n",
              "       [0.03606016, 0.09872498, 0.06657947, 0.03822162, 0.07025837],\n",
              "       [0.02628771, 0.27911072, 0.02246729, 0.0137972 , 0.03151633],\n",
              "       [0.01455127, 0.03355622, 0.03079678, 0.03520061, 0.00774982],\n",
              "       [0.01776623, 0.04667044, 0.03014953, 0.04027977, 0.02382965]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))\n",
        "\n",
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "EXD1l-fxpVI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Excel\n",
        "df.to_excel(\"real_org_se_AUTOENCODER_best_auto_config1_1215_with_weights_res_mm.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "eupRrTflpVI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "config 2"
      ],
      "metadata": {
        "id": "xpRqZAwnpVI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "id": "yuibU7oHpVI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82ca0026-6075-4e73-bdf7-1fd29a7689ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 42 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_2.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_2.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6d2f41e-f588-4783-f560-b9b7342b2b54",
        "id": "Dx3JKeZspVI3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 5, 'neurons': 21, 'learning_rate': 0.01, 'batch_size': 32, 'activation': 'tanh', 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0046'}\n",
            "\n",
            "Test Loss: 0.013620617799460888\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "[[ 1.          0.33023841 -0.27611846 -0.39997989  0.13483466]\n",
            " [ 0.33023841  1.         -0.27150449 -0.67782445 -0.13697377]\n",
            " [-0.27611846 -0.27150449  1.          0.49294685 -0.21667334]\n",
            " [-0.39997989 -0.67782445  0.49294685  1.          0.05789381]\n",
            " [ 0.13483466 -0.13697377 -0.21667334  0.05789381  1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract encoder and decoder from the trained autoencoder\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=best_model_config_2.get_layer('bottleneck').output)\n",
        "\n",
        "# Create a decoder model\n",
        "bottleneck_input = tf.keras.Input(shape=(encoder.output.shape[1],))\n",
        "x = bottleneck_input\n",
        "for layer_name in [l.name for l in best_model_config_2.layers if 'dense_decoder' in l.name]:\n",
        "    x = best_model_config_2.get_layer(layer_name)(x)\n",
        "decoder_output = best_model_config_2.get_layer('output_layer')(x)\n",
        "decoder = Model(inputs=bottleneck_input, outputs=decoder_output)"
      ],
      "metadata": {
        "id": "thIGQsZ7pVI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contributions\n",
        "contributions = calculate_bottleneck_contributions(best_model_config_2, encoder, decoder, X_train)\n",
        "\n",
        "# Print contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")"
      ],
      "metadata": {
        "id": "jyOdHOG4pVI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d5e9d6-9ed2-418e-f387-e0cc7ff33a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.7740\n",
            "Latent Dimension 2: 0.8088\n",
            "Latent Dimension 3: 0.7952\n",
            "Latent Dimension 4: 0.8121\n",
            "Latent Dimension 5: 0.8098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize contributions\n",
        "normalized_contributions = normalize_contributions(contributions)\n",
        "\n",
        "# Print normalized contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(normalized_contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")\n",
        "\n",
        "# Verify sum to 1\n",
        "print(\"Sum of Normalized Contributions:\", sum(normalized_contributions))"
      ],
      "metadata": {
        "id": "CRjDPBc1pVI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59d01d27-7002-44be-8a82-5b6bcf471471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.1935\n",
            "Latent Dimension 2: 0.2022\n",
            "Latent Dimension 3: 0.1988\n",
            "Latent Dimension 4: 0.2030\n",
            "Latent Dimension 5: 0.2025\n",
            "Sum of Normalized Contributions: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_2 = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder_model_config_2 = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer_config_2)\n",
        "bottleneck_output_2 = encoder_model_config_2.predict(X)"
      ],
      "metadata": {
        "id": "MuOu6qUzpVI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61af66c8-b428-4304-9447-854547393d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions = np.array(normalized_contributions)\n",
        "\n",
        "mi_scores = []\n",
        "for i in range(bottleneck_output_2.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_2[:, i], random_state=42)\n",
        "    mi_scores.append(mi)"
      ],
      "metadata": {
        "id": "7JYzH4WSpVI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "id": "ObD9jpdypVI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0608a2-a8a6-48fd-f08b-10248ce37e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_2.shape[1]))\n",
        "\n",
        "# Multiply MI scores by latent space contributions for each bottleneck dimension\n",
        "for dim in range(bottleneck_output_2.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim] * latent_contributions[dim]"
      ],
      "metadata": {
        "id": "SpAy5v0wpVI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))\n",
        "\n",
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "sLp3JMLFpVI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excel\n",
        "df.to_excel(\"real_org_se_AUTOENCODER_best_auto_config2_1215_with_weights_res_mm.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "J8GBXhmFpVI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_config_1.summary()"
      ],
      "metadata": {
        "id": "a9jfSmBBpVI4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "09edf558-4429-45c1-b3a6-4a7dc73fa381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │              \u001b[38;5;34m72\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m312\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,373\u001b[0m (5.36 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,373</span> (5.36 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,373\u001b[0m (5.36 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,373</span> (5.36 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_config_2.summary()"
      ],
      "metadata": {
        "id": "dBrQKPYZpVI4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "24f13511-24ae-4d80-ad6b-6901fb0fd71b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m525\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m110\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m126\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">525</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,061\u001b[0m (15.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,061</span> (15.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,061\u001b[0m (15.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,061</span> (15.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  mod - standard scaler (method 1)"
      ],
      "metadata": {
        "id": "t_1YxA77JpYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('SE_Original_(NOT SHARED) FOR USE_2020_mod.xlsx')\n",
        "X_ori = data.iloc[:, 3:27].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X_ori)\n",
        "\n",
        "# Split\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "koNc0gw2JpYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def create_autoencoder(input_dim, encoding_dim, hidden_layers_before, hidden_layers_after, neurons_before, neurons_after):\n",
        "    # Define the input layer\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "\n",
        "    # Build the encoder part\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons_before, activation='relu', name=f'dense_encoder_{i+1}')(x)\n",
        "\n",
        "    # Bottleneck layer (encoding layer)\n",
        "    bottleneck = Dense(encoding_dim, activation='relu', name='bottleneck')(x)\n",
        "\n",
        "    # Build the decoder part\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons_after, activation='relu', name=f'dense_decoder_{i+1}')(x)\n",
        "\n",
        "    # Output layer, with the same dimension as the input\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Define the complete autoencoder model\n",
        "    autoencoder = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "HCmxM8i6JpYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial tuning\n",
        "hidden_layers_options = [2, 4, 6, 8]  # Even numbers to ensure symmetry\n",
        "neurons_options = [8, 12, 16]\n",
        "encoding_dims_options = [1, 2, 3, 4, 5]\n",
        "results = []\n",
        "\n",
        "\n",
        "# Iterate through each combination of hyperparameters\n",
        "for hidden_layers in hidden_layers_options:\n",
        "    hidden_layers_before = hidden_layers // 2\n",
        "    hidden_layers_after = hidden_layers // 2\n",
        "\n",
        "    for neurons in neurons_options:\n",
        "        for encoding_dim in encoding_dims_options:\n",
        "            autoencoder = create_autoencoder(\n",
        "                input_dim=X_train.shape[1],\n",
        "                encoding_dim=encoding_dim,\n",
        "                hidden_layers_before=hidden_layers_before,\n",
        "                hidden_layers_after=hidden_layers_after,\n",
        "                neurons_before=neurons,\n",
        "                neurons_after=neurons\n",
        "            )\n",
        "            autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "            history = autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, verbose=0, validation_data=(X_test, X_test))\n",
        "\n",
        "            # Calculate average loss on the test set\n",
        "            test_loss = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
        "            results.append((hidden_layers, encoding_dim, neurons, test_loss))\n",
        "\n",
        "# Sort results by the lowest test loss and select the best two configurations\n",
        "sorted_results = sorted(results, key=lambda x: x[3])\n",
        "best_configs = sorted_results[:2]\n",
        "\n",
        "# Print best configurations for reference and show model summary\n",
        "print(\"Top two configurations:\")\n",
        "for config in best_configs:\n",
        "    hidden_layers, encoding_dim, neurons, test_loss = config\n",
        "    print(f\"Hidden layers: {hidden_layers}, Encoding dimension: {encoding_dim}, Neurons: {neurons}, Test loss: {test_loss}\")\n",
        "\n",
        "    # Recreate and display the model summary for the best configurations\n",
        "    autoencoder = create_autoencoder(\n",
        "        input_dim=X_train.shape[1],\n",
        "        encoding_dim=encoding_dim,\n",
        "        hidden_layers_before=hidden_layers // 2,\n",
        "        hidden_layers_after=hidden_layers // 2,\n",
        "        neurons_before=neurons,\n",
        "        neurons_after=neurons\n",
        "    )\n",
        "    autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "outputId": "849684f4-60b7-42d2-86ff-29e903cddb5b",
        "id": "_cqqw8_qJpYD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top two configurations:\n",
            "Hidden layers: 6, Encoding dimension: 5, Neurons: 16, Test loss: 0.03019469417631626\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m96\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m408\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,077\u001b[0m (8.11 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,077</span> (8.11 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,077\u001b[0m (8.11 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,077</span> (8.11 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden layers: 8, Encoding dimension: 4, Neurons: 16, Test loss: 0.03101118840277195\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │              \u001b[38;5;34m68\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m80\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m408\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,588\u001b[0m (10.11 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,588</span> (10.11 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,588\u001b[0m (10.11 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,588</span> (10.11 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner import Hyperband\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def build_model(hp, input_dim, hidden_layers_before, hidden_layers_after):\n",
        "    # Hyperparameters to tune\n",
        "    encoding_dim = hp.Int('encoding_dim', min_value=2, max_value=5, step=1)\n",
        "    neurons = hp.Int('neurons', min_value=6, max_value=21, step=3)\n",
        "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "    batch_size = hp.Choice('batch_size', [16, 32, 64])\n",
        "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "    # Build the model structure\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_encoder_{i+1}')(x)\n",
        "    bottleneck = Dense(encoding_dim, activation=activation, name='bottleneck')(x)\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_decoder_{i+1}')(x)\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Compile model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
        "    return model"
      ],
      "metadata": {
        "id": "xlKrN8r8JpYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import Hyperband\n",
        "\n",
        "# Define search space for each configuration\n",
        "tuner_config_1 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=3, hidden_layers_after=3),\n",
        "    objective='val_loss', max_epochs=50, factor=3, directory='hyperparam__tun_1_00_001', project_name='model_config_1'\n",
        ")\n",
        "\n",
        "tuner_config_2 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=4, hidden_layers_after=4),\n",
        "    objective='val_loss', max_epochs=50, factor=3, directory='hyperparam__tuni2_00_001', project_name='model_config_2'\n",
        ")"
      ],
      "metadata": {
        "id": "j4AtAGS5JpYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning for configuration 1\n",
        "tuner_config_1.search(X_train, X_train, epochs=50, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get the best model for configuration 1\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93514d40-f1f0-4b09-fdaf-e59a724478cd",
        "id": "13H3nq-0JpYD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 14s]\n",
            "val_loss: 0.12762096524238586\n",
            "\n",
            "Best val_loss So Far: 0.12762096524238586\n",
            "Total elapsed time: 00h 12m 36s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning for configuration 2\n",
        "tuner_config_2.search(X_train, X_train, epochs=50, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get the best model for configuration 2\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf10be61-8188-406e-dfec-13d64f5be4bc",
        "id": "PVbAj04xJpYD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 20s]\n",
            "val_loss: 0.5696251392364502\n",
            "\n",
            "Best val_loss So Far: 0.1425689309835434\n",
            "Total elapsed time: 00h 19m 47s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### regularization"
      ],
      "metadata": {
        "id": "Q-bW5WoTJpYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "id": "_PtBRt8UJpYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_1.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_1.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7611f1bd-b559-48a8-c4a8-14181add3939",
        "id": "hT9-rgXoJpYE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 5, 'neurons': 15, 'learning_rate': 0.01, 'batch_size': 16, 'activation': 'tanh', 'tuner/epochs': 50, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
            "\n",
            "Test Loss: 0.12762096524238586\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "[[ 1.         -0.42522991 -0.55274599  0.71814241 -0.67488728]\n",
            " [-0.42522991  1.         -0.0051193  -0.51272477  0.24704451]\n",
            " [-0.55274599 -0.0051193   1.         -0.52047143  0.61996209]\n",
            " [ 0.71814241 -0.51272477 -0.52047143  1.         -0.56127025]\n",
            " [-0.67488728  0.24704451  0.61996209 -0.56127025  1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer"
      ],
      "metadata": {
        "id": "dQi0TaB9JpYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract encoder and decoder from the trained autoencoder\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=best_model_config_1.get_layer('bottleneck').output)\n",
        "\n",
        "# Create a decoder model (assuming symmetric architecture)\n",
        "bottleneck_input = tf.keras.Input(shape=(encoder.output.shape[1],))\n",
        "x = bottleneck_input\n",
        "for layer_name in [l.name for l in best_model_config_1.layers if 'dense_decoder' in l.name]:\n",
        "    x = best_model_config_1.get_layer(layer_name)(x)\n",
        "decoder_output = best_model_config_1.get_layer('output_layer')(x)\n",
        "decoder = Model(inputs=bottleneck_input, outputs=decoder_output)\n"
      ],
      "metadata": {
        "id": "NwHujKQkJpYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "hIlGuCafJpYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate bottleneck contributions\n",
        "def calculate_bottleneck_contributions(autoencoder, encoder, decoder, X):\n",
        "    bottleneck_output = encoder.predict(X)\n",
        "    contributions = []\n",
        "\n",
        "    for dim in range(bottleneck_output.shape[1]):\n",
        "        # Isolate one dimension at a time\n",
        "        isolated_latent = np.zeros_like(bottleneck_output)\n",
        "        isolated_latent[:, dim] = bottleneck_output[:, dim]\n",
        "\n",
        "        # Reconstruct input using only the isolated latent dimension\n",
        "        reconstructed = decoder.predict(isolated_latent)\n",
        "\n",
        "        # Compute reconstruction loss (e.g., MSE)\n",
        "        loss = mean_squared_error(X, reconstructed)\n",
        "        contributions.append(loss)\n",
        "\n",
        "    # Normalize contributions\n",
        "    contributions = np.array(contributions)\n",
        "    normalized_contributions = 1 - (contributions / np.sum(contributions))\n",
        "\n",
        "    return normalized_contributions"
      ],
      "metadata": {
        "id": "Q_AGv-jvJpYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contributions\n",
        "contributions = calculate_bottleneck_contributions(best_model_config_1, encoder, decoder, X_train)\n",
        "\n",
        "# Print contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKIOiNruJpYE",
        "outputId": "b42a1dca-9cd8-4ec1-a7e9-341a63ec25e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.8027\n",
            "Latent Dimension 2: 0.8090\n",
            "Latent Dimension 3: 0.7978\n",
            "Latent Dimension 4: 0.7832\n",
            "Latent Dimension 5: 0.8073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the contributions so they sum to 1\n",
        "def normalize_contributions(contributions):\n",
        "    total = sum(contributions)\n",
        "    return [c / total for c in contributions]\n",
        "\n",
        "# Calculate contributions\n",
        "#contributions = calculate_bottleneck_contributions(best_model_config_1, encoder, decoder, X_train)\n",
        "\n",
        "# Normalize contributions\n",
        "normalized_contributions = normalize_contributions(contributions)"
      ],
      "metadata": {
        "id": "GebCe8fK3zMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print normalized contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(normalized_contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")\n",
        "\n",
        "# Verify they sum to 1\n",
        "print(\"Sum of Normalized Contributions:\", sum(normalized_contributions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVxqA6eZJpYE",
        "outputId": "80b40861-5127-4b37-e6ea-07c0b38c0dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.2007\n",
            "Latent Dimension 2: 0.2023\n",
            "Latent Dimension 3: 0.1995\n",
            "Latent Dimension 4: 0.1958\n",
            "Latent Dimension 5: 0.2018\n",
            "Sum of Normalized Contributions: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_contributions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIFU6_9OJpYE",
        "outputId": "b032b8da-7bc9-47e4-ebf5-74125945a0c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.20068282212358485,\n",
              " 0.20225030018813622,\n",
              " 0.19946112743781164,\n",
              " 0.19579165287560096,\n",
              " 0.2018140973748663]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_1 = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder_model_config_1 = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer_config_1)\n",
        "bottleneck_output_1 = encoder_model_config_1.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nXK8V3CJpYE",
        "outputId": "a216f6ae-803a-4cd7-e4f6-db246cb38fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions = np.array(normalized_contributions)\n",
        "\n",
        "# Calculate MI scores\n",
        "mi_scores = []\n",
        "for i in range(bottleneck_output_1.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_1[:, i], random_state=42)\n",
        "    mi_scores.append(mi)"
      ],
      "metadata": {
        "id": "YcL8sizxJpYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu5pfF4MJpYE",
        "outputId": "f17ed1cd-f38e-44c5-bc33-07288994966a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_1.shape[1]))\n",
        "\n",
        "# Multiply MI scores by latent space contributions for each bottleneck dimension\n",
        "for dim in range(bottleneck_output_1.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim] * latent_contributions[dim]"
      ],
      "metadata": {
        "id": "5bt5KCVjJpYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEG4nKehJpYE",
        "outputId": "59e9e0c7-d68d-4577-e816-881a4f0aa93e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.20068282, 0.2022503 , 0.19946113, 0.19579165, 0.2018141 ])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_mi_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hDizvQrJpYF",
        "outputId": "e472919b-92f1-4aa3-88da-f8f4edc1f04f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04506836, 0.0442941 , 0.03821024, 0.05480771, 0.04213401],\n",
              "       [0.03732239, 0.0443199 , 0.03801271, 0.03653718, 0.03931993],\n",
              "       [0.03767802, 0.05149054, 0.03826431, 0.04143186, 0.03620406],\n",
              "       [0.0621992 , 0.04103238, 0.04394444, 0.03890111, 0.03970796],\n",
              "       [0.0565258 , 0.04171799, 0.03636303, 0.03285133, 0.04440906],\n",
              "       [0.0380685 , 0.05298172, 0.04176086, 0.04295108, 0.04307252],\n",
              "       [0.03529352, 0.04076955, 0.03538346, 0.04083153, 0.05097274],\n",
              "       [0.04234658, 0.03983225, 0.03658004, 0.04786812, 0.04423753],\n",
              "       [0.05817101, 0.04866389, 0.04843819, 0.04970414, 0.06481478],\n",
              "       [0.05393561, 0.0419879 , 0.05222198, 0.04296094, 0.04250453],\n",
              "       [0.0389426 , 0.04162132, 0.05199782, 0.04226989, 0.05834244],\n",
              "       [0.00302001, 0.01051616, 0.01493002, 0.01740761, 0.02912733],\n",
              "       [0.03808041, 0.04728073, 0.04326012, 0.05573281, 0.03475857],\n",
              "       [0.037277  , 0.04498025, 0.04421609, 0.04141471, 0.04149851],\n",
              "       [0.06231611, 0.04327458, 0.03557483, 0.04562438, 0.03296164],\n",
              "       [0.05144993, 0.03992318, 0.03779742, 0.04440028, 0.04030303],\n",
              "       [0.04281594, 0.04424166, 0.04123849, 0.04981138, 0.04324411],\n",
              "       [0.03487653, 0.04075349, 0.04319947, 0.03512341, 0.03487495],\n",
              "       [0.03463842, 0.04985927, 0.04255256, 0.03878423, 0.0392041 ],\n",
              "       [0.04322306, 0.03814621, 0.04610146, 0.04456119, 0.05022352],\n",
              "       [0.03584195, 0.03598829, 0.06471017, 0.03598253, 0.03976843],\n",
              "       [0.03368747, 0.03666089, 0.04545322, 0.02777423, 0.03147784],\n",
              "       [0.0405209 , 0.04014589, 0.03901595, 0.04732746, 0.03614181],\n",
              "       [0.03670068, 0.03951784, 0.04077312, 0.04494089, 0.04069658]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))\n",
        "\n",
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "0U-109nmJpYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excel\n",
        "df.to_excel(\"real_org_se_AUTOENCODER_best_auto_config1_1208_with_weights_mod_ss.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "P-O8_ylEJpYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "config 2"
      ],
      "metadata": {
        "id": "0DSfh-E5JpYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "id": "xmPxH1_3JpYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_2.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_2.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a7545c-4853-45f6-dc07-7f79553200c0",
        "id": "Ln7BITwNJpYF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 3, 'neurons': 21, 'learning_rate': 0.01, 'batch_size': 64, 'activation': 'tanh', 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0046'}\n",
            "\n",
            "Test Loss: 0.1425689309835434\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "[[ 1.          0.24885691  0.02348047]\n",
            " [ 0.24885691  1.         -0.54123424]\n",
            " [ 0.02348047 -0.54123424  1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract encoder and decoder from the trained autoencoder\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=best_model_config_2.get_layer('bottleneck').output)\n",
        "\n",
        "# Create a decoder model (assuming symmetric architecture)\n",
        "bottleneck_input = tf.keras.Input(shape=(encoder.output.shape[1],))\n",
        "x = bottleneck_input\n",
        "for layer_name in [l.name for l in best_model_config_2.layers if 'dense_decoder' in l.name]:\n",
        "    x = best_model_config_2.get_layer(layer_name)(x)\n",
        "decoder_output = best_model_config_2.get_layer('output_layer')(x)\n",
        "decoder = Model(inputs=bottleneck_input, outputs=decoder_output)"
      ],
      "metadata": {
        "id": "YmtrHY_ZJpYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contributions\n",
        "contributions = calculate_bottleneck_contributions(best_model_config_2, encoder, decoder, X_train)\n",
        "\n",
        "# Print contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpn7GnJNJpYF",
        "outputId": "d0918a96-fe81-47d2-a1ec-79ea0ca73182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b13917fee60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.6339\n",
            "Latent Dimension 2: 0.7015\n",
            "Latent Dimension 3: 0.6645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize contributions\n",
        "normalized_contributions = normalize_contributions(contributions)\n",
        "\n",
        "# Print normalized contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(normalized_contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")\n",
        "\n",
        "# Verify they sum to 1\n",
        "print(\"Sum of Normalized Contributions:\", sum(normalized_contributions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrcEr2TdJpYF",
        "outputId": "6ecad115-5008-4723-d32b-e366273cc702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.3170\n",
            "Latent Dimension 2: 0.3508\n",
            "Latent Dimension 3: 0.3323\n",
            "Sum of Normalized Contributions: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_2 = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder_model_config_2 = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer_config_2)\n",
        "bottleneck_output_2 = encoder_model_config_2.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HHY6oNzJpYF",
        "outputId": "34995bdf-7263-4423-c8f3-a9041ed5214f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions = np.array(normalized_contributions)\n",
        "\n",
        "mi_scores = []\n",
        "for i in range(bottleneck_output_2.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_2[:, i], random_state=42)\n",
        "    mi_scores.append(mi)"
      ],
      "metadata": {
        "id": "e1MYpj0BJpYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mofyPDN9JpYF",
        "outputId": "c3b02aca-f8ea-4962-fc33-9674edaf1f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_2.shape[1]))\n",
        "\n",
        "# Multiply MI scores by latent space contributions for each bottleneck dimension\n",
        "for dim in range(bottleneck_output_2.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim] * latent_contributions[dim]"
      ],
      "metadata": {
        "id": "rpFtYt_gJpYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))\n",
        "\n",
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "EEZqJsQ1JpYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Excel\n",
        "df.to_excel(\"real_org_se_AUTOENCODER_best_auto_config2_1215_with_weights_mod_ss.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "lKEbKyDCJpYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_config_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "eP5zN27eJpYG",
        "outputId": "3c0c8a13-6218-48b0-a84d-e7870b69c0f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m125\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m144\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m600\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,669\u001b[0m (10.43 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,669</span> (10.43 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,669\u001b[0m (10.43 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,669</span> (10.43 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_config_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "KA3ftI-PJpYG",
        "outputId": "f96add68-b638-4f13-815b-4366ccd265e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m525\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m66\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │              \u001b[38;5;34m84\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">525</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,975\u001b[0m (15.53 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,975</span> (15.53 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,975\u001b[0m (15.53 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,975</span> (15.53 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mod - minmax scaler (method 1)"
      ],
      "metadata": {
        "id": "JZwbA47wXtt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('SE_Original_(NOT SHARED) FOR USE_2020_mod.xlsx')\n",
        "X_ori = data.iloc[:, 3:27].values\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X_ori)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "c8Y9ZnWVXtt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def create_autoencoder(input_dim, encoding_dim, hidden_layers_before, hidden_layers_after, neurons_before, neurons_after):\n",
        "    # Define the input layer\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "\n",
        "    # Build the encoder part\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons_before, activation='relu', name=f'dense_encoder_{i+1}')(x)\n",
        "\n",
        "    # Bottleneck layer (encoding layer)\n",
        "    bottleneck = Dense(encoding_dim, activation='relu', name='bottleneck')(x)\n",
        "\n",
        "    # Build the decoder part\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons_after, activation='relu', name=f'dense_decoder_{i+1}')(x)\n",
        "\n",
        "    # Output layer, with the same dimension as the input\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Define the complete autoencoder model\n",
        "    autoencoder = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "8GBQ6eYmXtt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial tuning\n",
        "hidden_layers_options = [2, 4, 6, 8]  # Even numbers to ensure symmetry\n",
        "neurons_options = [8, 12, 16]\n",
        "encoding_dims_options = [1, 2, 3, 4, 5]\n",
        "results = []\n",
        "\n",
        "\n",
        "# Iterate through each combination of hyperparameters\n",
        "for hidden_layers in hidden_layers_options:\n",
        "    hidden_layers_before = hidden_layers // 2\n",
        "    hidden_layers_after = hidden_layers // 2\n",
        "\n",
        "    for neurons in neurons_options:\n",
        "        for encoding_dim in encoding_dims_options:\n",
        "            autoencoder = create_autoencoder(\n",
        "                input_dim=X_train.shape[1],\n",
        "                encoding_dim=encoding_dim,\n",
        "                hidden_layers_before=hidden_layers_before,\n",
        "                hidden_layers_after=hidden_layers_after,\n",
        "                neurons_before=neurons,\n",
        "                neurons_after=neurons\n",
        "            )\n",
        "            autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "            history = autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, verbose=0, validation_data=(X_test, X_test))\n",
        "\n",
        "            # Calculate average loss on the test set\n",
        "            test_loss = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
        "            results.append((hidden_layers, encoding_dim, neurons, test_loss))\n",
        "\n",
        "# Sort results by the lowest test loss and select the best two configurations\n",
        "sorted_results = sorted(results, key=lambda x: x[3])\n",
        "best_configs = sorted_results[:2]\n",
        "\n",
        "# Print best configurations for reference and show model summary\n",
        "print(\"Top two configurations:\")\n",
        "for config in best_configs:\n",
        "    hidden_layers, encoding_dim, neurons, test_loss = config\n",
        "    print(f\"Hidden layers: {hidden_layers}, Encoding dimension: {encoding_dim}, Neurons: {neurons}, Test loss: {test_loss}\")\n",
        "\n",
        "    # Recreate and display the model summary for the best configurations\n",
        "    autoencoder = create_autoencoder(\n",
        "        input_dim=X_train.shape[1],\n",
        "        encoding_dim=encoding_dim,\n",
        "        hidden_layers_before=hidden_layers // 2,\n",
        "        hidden_layers_after=hidden_layers // 2,\n",
        "        neurons_before=neurons,\n",
        "        neurons_after=neurons\n",
        "    )\n",
        "    autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "outputId": "849684f4-60b7-42d2-86ff-29e903cddb5b",
        "id": "spr62HQ2Xtt8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top two configurations:\n",
            "Hidden layers: 6, Encoding dimension: 5, Neurons: 16, Test loss: 0.03019469417631626\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m96\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m408\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,077\u001b[0m (8.11 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,077</span> (8.11 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,077\u001b[0m (8.11 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,077</span> (8.11 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden layers: 8, Encoding dimension: 4, Neurons: 16, Test loss: 0.03101118840277195\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │              \u001b[38;5;34m68\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m80\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m408\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,588\u001b[0m (10.11 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,588</span> (10.11 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,588\u001b[0m (10.11 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,588</span> (10.11 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner import Hyperband\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def build_model(hp, input_dim, hidden_layers_before, hidden_layers_after):\n",
        "    # Hyperparameters to tune\n",
        "    encoding_dim = hp.Int('encoding_dim', min_value=2, max_value=5, step=1)\n",
        "    neurons = hp.Int('neurons', min_value=6, max_value=24, step=3)\n",
        "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "    batch_size = hp.Choice('batch_size', [16, 32, 64])\n",
        "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "    # Build the model structure\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_encoder_{i+1}')(x)\n",
        "    bottleneck = Dense(encoding_dim, activation=activation, name='bottleneck')(x)\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_decoder_{i+1}')(x)\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Compile model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
        "    return model"
      ],
      "metadata": {
        "id": "ENcXxTg4Xtt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import Hyperband\n",
        "\n",
        "# Define search space for each configuration\n",
        "tuner_config_1 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=3, hidden_layers_after=3),\n",
        "    objective='val_loss', max_epochs=50, factor=3, directory='hyperparam_tun_1_01', project_name='model_config_1'\n",
        ")\n",
        "\n",
        "tuner_config_2 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=2, hidden_layers_after=2),\n",
        "    objective='val_loss', max_epochs=50, factor=3, directory='hyperparam_tuni_2_01', project_name='model_config_2'\n",
        ")"
      ],
      "metadata": {
        "id": "biHqdO1dXtt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning for configuration 1\n",
        "tuner_config_1.search(X_train, X_train, epochs=50, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get the best model for configuration 1\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b5c41c4-896e-4d01-acc8-9ebbd532c6af",
        "id": "AbGSz0qKXtt_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 33s]\n",
            "val_loss: 0.1942932903766632\n",
            "\n",
            "Best val_loss So Far: 0.008733450435101986\n",
            "Total elapsed time: 00h 32m 35s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning for configuration 2\n",
        "tuner_config_2.search(X_train, X_train, epochs=50, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get the best model for configuration 2\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "407d13f3-3a46-49e8-9919-f0dd5c1329bb",
        "id": "X-A47sSLXtuA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 30s]\n",
            "val_loss: 0.024620352312922478\n",
            "\n",
            "Best val_loss So Far: 0.008665623143315315\n",
            "Total elapsed time: 00h 33m 54s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### regularization"
      ],
      "metadata": {
        "id": "8knS3zBaXtuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "id": "HIoKxygjXtuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_1.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_1.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb9578c-c826-450e-977c-a340d596fc62",
        "id": "0ABwtoNQXtuA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 5, 'neurons': 21, 'learning_rate': 0.01, 'batch_size': 16, 'activation': 'tanh', 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0046'}\n",
            "\n",
            "Test Loss: 0.008733450435101986\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "[[ 1.          0.27341915  0.5457976  -0.61524119 -0.55066915]\n",
            " [ 0.27341915  1.         -0.1533339  -0.29539084 -0.0314978 ]\n",
            " [ 0.5457976  -0.1533339   1.         -0.48274557 -0.38345682]\n",
            " [-0.61524119 -0.29539084 -0.48274557  1.          0.8591797 ]\n",
            " [-0.55066915 -0.0314978  -0.38345682  0.8591797   1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer"
      ],
      "metadata": {
        "id": "pYf0-7IsXtuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract encoder and decoder from the trained autoencoder\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=best_model_config_1.get_layer('bottleneck').output)\n",
        "\n",
        "# Create a decoder model (assuming symmetric architecture)\n",
        "bottleneck_input = tf.keras.Input(shape=(encoder.output.shape[1],))\n",
        "x = bottleneck_input\n",
        "for layer_name in [l.name for l in best_model_config_1.layers if 'dense_decoder' in l.name]:\n",
        "    x = best_model_config_1.get_layer(layer_name)(x)\n",
        "decoder_output = best_model_config_1.get_layer('output_layer')(x)\n",
        "decoder = Model(inputs=bottleneck_input, outputs=decoder_output)\n"
      ],
      "metadata": {
        "id": "RxZnoHrAXtuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "fvq3g4_CXtuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate bottleneck contributions\n",
        "def calculate_bottleneck_contributions(autoencoder, encoder, decoder, X):\n",
        "    bottleneck_output = encoder.predict(X)\n",
        "    contributions = []\n",
        "\n",
        "    for dim in range(bottleneck_output.shape[1]):\n",
        "        # Isolate one dimension at a time\n",
        "        isolated_latent = np.zeros_like(bottleneck_output)\n",
        "        isolated_latent[:, dim] = bottleneck_output[:, dim]\n",
        "\n",
        "        # Reconstruct input using only the isolated latent dimension\n",
        "        reconstructed = decoder.predict(isolated_latent)\n",
        "\n",
        "        # Compute reconstruction loss (e.g., MSE)\n",
        "        loss = mean_squared_error(X, reconstructed)\n",
        "        contributions.append(loss)\n",
        "\n",
        "    # Normalize contributions\n",
        "    contributions = np.array(contributions)\n",
        "    normalized_contributions = 1 - (contributions / np.sum(contributions))\n",
        "\n",
        "    return normalized_contributions"
      ],
      "metadata": {
        "id": "HxM-mGkqXtuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contributions\n",
        "contributions = calculate_bottleneck_contributions(best_model_config_1, encoder, decoder, X_train)\n",
        "\n",
        "# Print contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c28dd5ac-dc23-4ba8-ea3a-cc9c2e62166d",
        "id": "H0qLwAEIXtuB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.7679\n",
            "Latent Dimension 2: 0.7455\n",
            "Latent Dimension 3: 0.7569\n",
            "Latent Dimension 4: 0.8751\n",
            "Latent Dimension 5: 0.8545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the contributions so they sum to 1\n",
        "def normalize_contributions(contributions):\n",
        "    total = sum(contributions)\n",
        "    return [c / total for c in contributions]\n",
        "\n",
        "# Calculate contributions\n",
        "#contributions = calculate_bottleneck_contributions(best_model_config_1, encoder, decoder, X_train)\n",
        "\n",
        "# Normalize contributions\n",
        "normalized_contributions = normalize_contributions(contributions)\n",
        "\n",
        "# Print normalized contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(normalized_contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")\n",
        "\n",
        "# Verify they sum to 1\n",
        "print(\"Sum of Normalized Contributions:\", sum(normalized_contributions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01045d39-1578-4e28-abbb-148b903bf9e9",
        "id": "SBU5Mur7XtuB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.1920\n",
            "Latent Dimension 2: 0.1864\n",
            "Latent Dimension 3: 0.1892\n",
            "Latent Dimension 4: 0.2188\n",
            "Latent Dimension 5: 0.2136\n",
            "Sum of Normalized Contributions: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_contributions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75955972-f871-426d-93b8-aa9c12e0bf7b",
        "id": "5ZnHa0gTXtuC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19197492579607112,\n",
              " 0.1863806563451278,\n",
              " 0.1892238559408974,\n",
              " 0.21878465384800216,\n",
              " 0.21363590806990151]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_1 = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder_model_config_1 = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer_config_1)\n",
        "bottleneck_output_1 = encoder_model_config_1.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c770c2-e636-40b5-a4b8-439b6cb929e8",
        "id": "aBB82HJLXtuC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions = np.array(normalized_contributions)\n",
        "\n",
        "# Calculate MI scores\n",
        "mi_scores = []\n",
        "for i in range(bottleneck_output_1.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_1[:, i], random_state=42)\n",
        "    mi_scores.append(mi)"
      ],
      "metadata": {
        "id": "M-zElPyQXtuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d5398be-f1c5-4091-ed78-a601d8317bcd",
        "id": "vwI_k_AdXtuC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_1.shape[1]))\n",
        "\n",
        "# Multiply MI scores by latent space contributions for each bottleneck dimension\n",
        "for dim in range(bottleneck_output_1.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim] * latent_contributions[dim]"
      ],
      "metadata": {
        "id": "LoWbFeoNXtuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fecc93a-6060-4b19-d88c-d5e98dc69e92",
        "id": "E-g4e1HLXtuD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.19197493, 0.18638066, 0.18922386, 0.21878465, 0.21363591])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_mi_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c0440b-0059-46d8-c61e-b33c0b429210",
        "id": "zw8TYUwIXtuD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04218445, 0.03078654, 0.08440457, 0.03912206, 0.04635877],\n",
              "       [0.03773566, 0.03483614, 0.03606974, 0.04068296, 0.04374035],\n",
              "       [0.04748639, 0.03079026, 0.04163986, 0.03885202, 0.04129998],\n",
              "       [0.04901207, 0.03740175, 0.05388761, 0.04287349, 0.03937062],\n",
              "       [0.03882233, 0.02890048, 0.03574005, 0.03554469, 0.05043972],\n",
              "       [0.04205442, 0.04417397, 0.04279947, 0.04223007, 0.04296923],\n",
              "       [0.04711199, 0.04431725, 0.0378048 , 0.0408701 , 0.0430245 ],\n",
              "       [0.03438571, 0.05573018, 0.04352765, 0.04014563, 0.03666145],\n",
              "       [0.05761794, 0.08619784, 0.05250345, 0.06101956, 0.04347579],\n",
              "       [0.04581677, 0.04777077, 0.05362266, 0.03607465, 0.04587461],\n",
              "       [0.05226176, 0.05667895, 0.054738  , 0.05831268, 0.043774  ],\n",
              "       [0.01581146, 0.03530167, 0.01370284, 0.02208394, 0.01011167],\n",
              "       [0.02638561, 0.04146324, 0.03683826, 0.03817221, 0.03910067],\n",
              "       [0.04795623, 0.04528865, 0.0380058 , 0.04363853, 0.04156155],\n",
              "       [0.04916894, 0.04200865, 0.04406512, 0.03529245, 0.04807891],\n",
              "       [0.04845073, 0.0371715 , 0.0485399 , 0.0412858 , 0.03862889],\n",
              "       [0.04346934, 0.03669381, 0.04397269, 0.03898829, 0.03987933],\n",
              "       [0.03883783, 0.03368457, 0.03715388, 0.03616159, 0.040064  ],\n",
              "       [0.03471675, 0.0397736 , 0.0329337 , 0.04213128, 0.0379017 ],\n",
              "       [0.04346934, 0.05581278, 0.04171239, 0.04944107, 0.03660753],\n",
              "       [0.04268247, 0.04126741, 0.03337578, 0.05855825, 0.04074029],\n",
              "       [0.03656618, 0.02627865, 0.02484164, 0.03316755, 0.06171234],\n",
              "       [0.04033165, 0.03329525, 0.03467015, 0.04297995, 0.04447983],\n",
              "       [0.03766397, 0.0343761 , 0.03345001, 0.04237117, 0.04414426]])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))\n",
        "\n",
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "3NEDrKACXtuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Excel\n",
        "df.to_excel(\"real_org_se_AUTOENCODER_best_auto_config1_1208_with_weights_mod_mm.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "qLA3-3VQXtuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "config 2"
      ],
      "metadata": {
        "id": "hDiq8zVyXtuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2225484-3820-4a42-aa7f-39f8bba037f0",
        "id": "2eRwHWUjXtuE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 26 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_2.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_2.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adba4552-e93e-4436-f353-d18c55d84cf9",
        "id": "WCzri1-TXtuE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 5, 'neurons': 18, 'learning_rate': 0.01, 'batch_size': 64, 'activation': 'tanh', 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0046'}\n",
            "\n",
            "Test Loss: 0.008665623143315315\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "[[ 1.          0.90913048 -0.62404316 -0.25591497  0.40747206]\n",
            " [ 0.90913048  1.         -0.73806515 -0.43251889  0.26207923]\n",
            " [-0.62404316 -0.73806515  1.          0.50456251 -0.28659933]\n",
            " [-0.25591497 -0.43251889  0.50456251  1.          0.08879892]\n",
            " [ 0.40747206  0.26207923 -0.28659933  0.08879892  1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract encoder and decoder from the trained autoencoder\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=best_model_config_2.get_layer('bottleneck').output)\n",
        "\n",
        "# Create a decoder model (assuming symmetric architecture)\n",
        "bottleneck_input = tf.keras.Input(shape=(encoder.output.shape[1],))\n",
        "x = bottleneck_input\n",
        "for layer_name in [l.name for l in best_model_config_2.layers if 'dense_decoder' in l.name]:\n",
        "    x = best_model_config_2.get_layer(layer_name)(x)\n",
        "decoder_output = best_model_config_2.get_layer('output_layer')(x)\n",
        "decoder = Model(inputs=bottleneck_input, outputs=decoder_output)"
      ],
      "metadata": {
        "id": "NHYEFgIhXtuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contributions\n",
        "contributions = calculate_bottleneck_contributions(best_model_config_2, encoder, decoder, X_train)\n",
        "\n",
        "# Print contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e14822-bc3b-4087-9900-bb7ef9791673",
        "id": "da4rUqGuXtuE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.8262\n",
            "Latent Dimension 2: 0.8966\n",
            "Latent Dimension 3: 0.7111\n",
            "Latent Dimension 4: 0.7962\n",
            "Latent Dimension 5: 0.7699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize contributions\n",
        "normalized_contributions = normalize_contributions(contributions)\n",
        "\n",
        "# Print normalized contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(normalized_contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")\n",
        "\n",
        "# Verify they sum to 1\n",
        "print(\"Sum of Normalized Contributions:\", sum(normalized_contributions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77dde575-435d-46cb-82de-531499dd3c30",
        "id": "K00MwNXIXtuE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.2066\n",
            "Latent Dimension 2: 0.2242\n",
            "Latent Dimension 3: 0.1778\n",
            "Latent Dimension 4: 0.1991\n",
            "Latent Dimension 5: 0.1925\n",
            "Sum of Normalized Contributions: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_2 = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder_model_config_2 = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer_config_2)\n",
        "bottleneck_output_2 = encoder_model_config_2.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19073704-89c1-4487-a7ce-2daed71ff94f",
        "id": "hOSCgDkpXtuF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions = np.array(normalized_contributions)  # Make sure this is normalized\n",
        "\n",
        "mi_scores = []\n",
        "for i in range(bottleneck_output_2.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_2[:, i], random_state=42)\n",
        "    mi_scores.append(mi)"
      ],
      "metadata": {
        "id": "hM1tOFscXtuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0a2e6c-e728-487f-a3a0-86f27ab48036",
        "id": "e-CQFFnjXtuF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_2.shape[1]))\n",
        "\n",
        "# Multiply MI scores by latent space contributions for each bottleneck dimension\n",
        "for dim in range(bottleneck_output_2.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim] * latent_contributions[dim]"
      ],
      "metadata": {
        "id": "yMHgp2RCXtuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))\n",
        "\n",
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "MpdZNuO9XtuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Excel\n",
        "df.to_excel(\"real_org_se_AUTOENCODER_best_auto_config2_1208_with_weights_mod_mm.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "hq4tvqGOXtuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_config_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "f6d46a13-f223-4075-f480-6c38a023bcb7",
        "id": "2Y5SgPPRXtuG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m525\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m110\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m126\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">525</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,137\u001b[0m (12.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,137</span> (12.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,137\u001b[0m (12.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,137</span> (12.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_config_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "ea916ccd-dd0c-4439-cb4e-d677a2d764d9",
        "id": "KXZ1-HGvXtuG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m450\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m95\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m108\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m456\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">456</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,793\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,793</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,793\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,793</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## res / only one encoding dimension - ss (method 2)"
      ],
      "metadata": {
        "id": "41F0TRZZiOIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mutual_info_score\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from itertools import product\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from kerastuner import HyperModel, RandomSearch"
      ],
      "metadata": {
        "id": "NEMaI1G2iOJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('SE_Original_(NOT SHARED) FOR USE_2020_residential.xlsx')\n",
        "X_ori = data.iloc[:, 3:27].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X_ori)\n",
        "\n",
        "# Split\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "pr2wNJRDiOJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def create_autoencoder(input_dim, encoding_dim, hidden_layers_before, hidden_layers_after, neurons_before, neurons_after):\n",
        "    # Define the input layer\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "\n",
        "    # Build the encoder part\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons_before, activation='relu', name=f'dense_encoder_{i+1}')(x)\n",
        "\n",
        "    # Bottleneck layer (encoding layer)\n",
        "    bottleneck = Dense(encoding_dim, activation='relu', name='bottleneck')(x)\n",
        "\n",
        "    # Build the decoder part\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons_after, activation='relu', name=f'dense_decoder_{i+1}')(x)\n",
        "\n",
        "    # Output layer, with the same dimension as the input\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Define the complete autoencoder model\n",
        "    autoencoder = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "vj3bPnlniOJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial tuning\n",
        "hidden_layers_options = [2, 4, 6, 8]  # Even numbers to ensure symmetry\n",
        "neurons_options = [6, 8, 10, 12, 14, 16]\n",
        "encoding_dims_options = [1]\n",
        "results = []\n",
        "\n",
        "# Iterate through each combination of hyperparameters\n",
        "for hidden_layers in hidden_layers_options:\n",
        "    hidden_layers_before = hidden_layers // 2\n",
        "    hidden_layers_after = hidden_layers // 2\n",
        "\n",
        "    for neurons in neurons_options:\n",
        "        for encoding_dim in encoding_dims_options:\n",
        "            autoencoder = create_autoencoder(\n",
        "                input_dim=X_train.shape[1],\n",
        "                encoding_dim=encoding_dim,\n",
        "                hidden_layers_before=hidden_layers_before,\n",
        "                hidden_layers_after=hidden_layers_after,\n",
        "                neurons_before=neurons,\n",
        "                neurons_after=neurons\n",
        "            )\n",
        "            autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "            history = autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, verbose=0, validation_data=(X_test, X_test))\n",
        "\n",
        "            # Calculate average loss on the test set\n",
        "            test_loss = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
        "            results.append((hidden_layers, encoding_dim, neurons, test_loss))\n",
        "\n",
        "# Sort results by the lowest test loss and select the best two configurations\n",
        "sorted_results = sorted(results, key=lambda x: x[3])\n",
        "best_configs = sorted_results[:2]\n",
        "\n",
        "# Print best configurations for reference and show model summary\n",
        "print(\"Top two configurations:\")\n",
        "for config in best_configs:\n",
        "    hidden_layers, encoding_dim, neurons, test_loss = config\n",
        "    print(f\"Hidden layers: {hidden_layers}, Encoding dimension: {encoding_dim}, Neurons: {neurons}, Test loss: {test_loss}\")\n",
        "\n",
        "    # Recreate and display the model summary for the best configurations\n",
        "    autoencoder = create_autoencoder(\n",
        "        input_dim=X_train.shape[1],\n",
        "        encoding_dim=encoding_dim,\n",
        "        hidden_layers_before=hidden_layers // 2,\n",
        "        hidden_layers_after=hidden_layers // 2,\n",
        "        neurons_before=neurons,\n",
        "        neurons_after=neurons\n",
        "    )\n",
        "    autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2653c0f2-4de0-47fa-8260-d8c7e7cce62c",
        "id": "_bQK-eG-iOJI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top two configurations:\n",
            "Hidden layers: 8, Encoding dimension: 1, Neurons: 14, Test loss: 0.6968121528625488\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m350\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m15\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │              \u001b[38;5;34m28\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m360\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,013\u001b[0m (7.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,013</span> (7.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,013\u001b[0m (7.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,013</span> (7.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden layers: 6, Encoding dimension: 1, Neurons: 12, Test loss: 0.7262334227561951\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m13\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │              \u001b[38;5;34m24\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m312\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,273\u001b[0m (4.97 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,273</span> (4.97 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,273\u001b[0m (4.97 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,273</span> (4.97 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner import Hyperband\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def build_model(hp, input_dim, hidden_layers_before, hidden_layers_after):\n",
        "    # Hyperparameters to tune\n",
        "    encoding_dim = hp.Choice('encoding_dim', [1]) # Only one encoding dimension\n",
        "    neurons = hp.Int('neurons', min_value=6, max_value=24, step=3)\n",
        "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "    batch_size = hp.Choice('batch_size', [16, 32, 64])\n",
        "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "    # Build the model structure\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_encoder_{i+1}')(x)\n",
        "    bottleneck = Dense(encoding_dim, activation=activation, name='bottleneck')(x)\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_decoder_{i+1}')(x)\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Compile model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
        "    return model"
      ],
      "metadata": {
        "id": "SCYUByEWiOJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import Hyperband\n",
        "\n",
        "# Define search space for each configuration\n",
        "tuner_config_1 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=4, hidden_layers_after=4),\n",
        "    objective='val_loss', max_epochs=50, factor=3, directory='hyperparam_tuning__1__o_n_l_y1', project_name='model_config_1'\n",
        ")\n",
        "\n",
        "tuner_config_2 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=3, hidden_layers_after=3),\n",
        "    objective='val_loss', max_epochs=50, factor=3, directory='hyperparam_tuning__2__o_n_ly_1', project_name='model_config_2'\n",
        ")"
      ],
      "metadata": {
        "id": "DhcspdsZiOJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning for configuration 1\n",
        "tuner_config_1.search(X_train, X_train, epochs=50, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get the best model for configuration 1\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be68579c-36da-4d60-f4ac-4388ba84111a",
        "id": "WmwiYCSkiOJJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 17s]\n",
            "val_loss: 0.9786759614944458\n",
            "\n",
            "Best val_loss So Far: 0.5522105693817139\n",
            "Total elapsed time: 00h 20m 02s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning for configuration 2\n",
        "tuner_config_2.search(X_train, X_train, epochs=50, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get the best model for configuration 2\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "outputId": "ec6e4495-1d7a-4ace-95b8-2e234fa59ca0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nzijg7rSiOJJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 22s]\n",
            "val_loss: 0.9045199155807495\n",
            "\n",
            "Best val_loss So Far: 0.5610660910606384\n",
            "Total elapsed time: 00h 19m 51s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy8I3XoIY9bO"
      },
      "source": [
        "#### check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7ZI8MEbY9bT"
      },
      "outputs": [],
      "source": [
        "# Get the best model\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86516e2d-d5ad-4623-eb26-88456f961d12",
        "id": "ZFS-OYeoY9bU"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 1, 'neurons': 15, 'learning_rate': 0.01, 'batch_size': 16, 'activation': 'tanh', 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0067'}\n",
            "\n",
            "Test Loss: 0.5522105693817139\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_1.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_1.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pIjaumfY9bV"
      },
      "outputs": [],
      "source": [
        "# Get the best model\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_2.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_2.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axB60fFZjq4a",
        "outputId": "6a9b02d9-a723-4a55-dfd5-a0a2afc75c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 1, 'neurons': 21, 'learning_rate': 0.01, 'batch_size': 32, 'activation': 'relu', 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0049'}\n",
            "\n",
            "Test Loss: 0.3288326859474182\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### summary"
      ],
      "metadata": {
        "id": "v6BIietlieGN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "outputId": "b503db99-2126-4e4d-a13a-34ede48f9b3c",
        "id": "Jj7QglxtY9bV"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model Structure for Configuration 1:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m375\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m16\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │              \u001b[38;5;34m30\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m384\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,245\u001b[0m (8.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,245</span> (8.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,245\u001b[0m (8.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,245</span> (8.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Model Structure for Configuration 2:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m525\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m22\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │              \u001b[38;5;34m42\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">525</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,965\u001b[0m (11.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,965</span> (11.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,965\u001b[0m (11.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,965</span> (11.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Display the structure of the best model for configuration 1\n",
        "print(\"Best Model Structure for Configuration 1:\")\n",
        "best_model_config_1.summary()\n",
        "\n",
        "# Display the structure of the best model for configuration 2\n",
        "print(\"\\nBest Model Structure for Configuration 2:\")\n",
        "best_model_config_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print details of each layer for the best model in configuration 1\n",
        "print(\"Best Model for Configuration 1:\")\n",
        "for layer in best_model_config_1.layers:\n",
        "    if hasattr(layer, 'output_shape'):\n",
        "        output_shape = layer.output_shape\n",
        "    else:\n",
        "        output_shape = layer.get_output_shape_at(0) if hasattr(layer, 'get_output_shape_at') else 'N/A'\n",
        "    print(f\"Layer: {layer.name}, Type: {layer.__class__.__name__}, Output Shape: {output_shape}, Parameters: {layer.count_params()}\")\n",
        "\n",
        "# Print details of each layer for the best model in configuration 2\n",
        "print(\"\\nBest Model for Configuration 2:\")\n",
        "for layer in best_model_config_2.layers:\n",
        "    if hasattr(layer, 'output_shape'):\n",
        "        output_shape = layer.output_shape\n",
        "    else:\n",
        "        output_shape = layer.get_output_shape_at(0) if hasattr(layer, 'get_output_shape_at') else 'N/A'\n",
        "    print(f\"Layer: {layer.name}, Type: {layer.__class__.__name__}, Output Shape: {output_shape}, Parameters: {layer.count_params()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815c802b-deab-4c46-ce66-15aa8d3888ec",
        "id": "cIv3r00ViOJK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model for Configuration 1:\n",
            "Layer: input_layer, Type: InputLayer, Output Shape: N/A, Parameters: 0\n",
            "Layer: dense_encoder_1, Type: Dense, Output Shape: N/A, Parameters: 375\n",
            "Layer: dense_encoder_2, Type: Dense, Output Shape: N/A, Parameters: 240\n",
            "Layer: dense_encoder_3, Type: Dense, Output Shape: N/A, Parameters: 240\n",
            "Layer: dense_encoder_4, Type: Dense, Output Shape: N/A, Parameters: 240\n",
            "Layer: bottleneck, Type: Dense, Output Shape: N/A, Parameters: 16\n",
            "Layer: dense_decoder_1, Type: Dense, Output Shape: N/A, Parameters: 30\n",
            "Layer: dense_decoder_2, Type: Dense, Output Shape: N/A, Parameters: 240\n",
            "Layer: dense_decoder_3, Type: Dense, Output Shape: N/A, Parameters: 240\n",
            "Layer: dense_decoder_4, Type: Dense, Output Shape: N/A, Parameters: 240\n",
            "Layer: output_layer, Type: Dense, Output Shape: N/A, Parameters: 384\n",
            "\n",
            "Best Model for Configuration 2:\n",
            "Layer: input_layer, Type: InputLayer, Output Shape: N/A, Parameters: 0\n",
            "Layer: dense_encoder_1, Type: Dense, Output Shape: N/A, Parameters: 525\n",
            "Layer: dense_encoder_2, Type: Dense, Output Shape: N/A, Parameters: 462\n",
            "Layer: dense_encoder_3, Type: Dense, Output Shape: N/A, Parameters: 462\n",
            "Layer: bottleneck, Type: Dense, Output Shape: N/A, Parameters: 22\n",
            "Layer: dense_decoder_1, Type: Dense, Output Shape: N/A, Parameters: 42\n",
            "Layer: dense_decoder_2, Type: Dense, Output Shape: N/A, Parameters: 462\n",
            "Layer: dense_decoder_3, Type: Dense, Output Shape: N/A, Parameters: 462\n",
            "Layer: output_layer, Type: Dense, Output Shape: N/A, Parameters: 528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_1 = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder_model_config_1 = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer_config_1)\n",
        "bottleneck_output_1 = encoder_model_config_1.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfdadb76-1d33-41fd-c3ea-be1e607dd6fd",
        "id": "LcNo1If9iOJL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_2 = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder_model_config_2 = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer_config_2)\n",
        "bottleneck_output_2 = encoder_model_config_2.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2e12340-ff84-4556-e1be-789bf23e6ada",
        "id": "0LzFdi9PiOJL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_output_1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c8d01d-41ea-40fc-a9a4-6a5b8f23c318",
        "id": "3MO44PDHiOJL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(197, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_output_2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa708388-e944-4042-d496-2337f494c16f",
        "id": "KjjLAj64iOJM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(197, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_regression\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "B-3RjDefiOJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = []\n",
        "for i in range(bottleneck_output_1.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_1[:, i], random_state=42)\n",
        "    mi_scores.append(mi)\n"
      ],
      "metadata": {
        "id": "zC62cK8yiOJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6002a64-ef24-4bee-d7fb-67143b6e16dc",
        "id": "4A0tQ9RmiOJM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.44647139, 0.2722489 , 0.26068733, 0.66430636, 0.22727116,\n",
              "        0.3290235 , 0.34749443, 0.77091991, 1.11296172, 0.39529593,\n",
              "        0.60572365, 0.47222822, 0.3359241 , 0.32804701, 0.62093041,\n",
              "        0.72574801, 0.48289276, 0.10986328, 0.23489059, 0.75706334,\n",
              "        0.61790683, 0.13459049, 0.20046701, 0.26493196])]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6ae8ae8-b2d9-4246-d1b8-18117aabbe2e",
        "id": "MS-eCyQTiOJM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_1.shape[1]))\n",
        "\n",
        "for dim in range(bottleneck_output_1.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim]"
      ],
      "metadata": {
        "id": "bRHVxXlxiOJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))"
      ],
      "metadata": {
        "id": "IZ-BRcE1iOJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "7Xrmu3hgiOJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "a7f29d60-4370-491b-dad1-aae2af37f623",
        "id": "Vs5yo2b9iOJN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
              "0    -1.599647   0.172556  -1.154431  -0.956162  -0.585631   0.832135   \n",
              "1    -1.794071  -0.205150  -0.943991  -0.544680  -0.444571  -0.198315   \n",
              "2    -2.024714  -0.205150   0.150299   1.401948   0.973080  -0.858740   \n",
              "3    -0.390051  -1.338270  -0.060141   0.394344  -0.194190   0.063981   \n",
              "4    -1.564282  -0.205150  -1.049211  -1.594488  -1.290930   1.661179   \n",
              "..         ...        ...        ...        ...        ...        ...   \n",
              "192  -1.530454   0.172556   0.381784  -0.966713  -0.807800  -0.235786   \n",
              "193  -1.825507   0.172556  -0.396846  -1.299064  -0.906542  -1.074198   \n",
              "194  -1.615023   0.927970   0.234476  -0.971989  -0.966492  -0.558973   \n",
              "195  -1.992766  -0.582857  -0.165361  -1.030018  -0.977072  -1.434855   \n",
              "196  -1.996524  -0.205150  -0.270582  -0.724044  -1.174556  -0.896211   \n",
              "\n",
              "     Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_16  Feature_17  \\\n",
              "0    -3.356507  -0.410742   0.905227    0.011890  ...   -1.017613   -0.148817   \n",
              "1    -2.424866  -0.684253   1.049859   -0.032068  ...    2.431666   -0.699047   \n",
              "2     0.447692   1.942893   0.543645   -4.773193  ...    2.760938    0.109103   \n",
              "3    -1.687318  -1.098118   1.070521    0.143762  ...    0.293883    0.143493   \n",
              "4    -0.406312  -0.633869   1.323629   -0.496761  ...   -1.339430   -0.991356   \n",
              "..         ...        ...        ...         ...  ...         ...         ...   \n",
              "192   0.797057   1.467848  -1.690415    0.834522  ...   -0.556943   -0.441126   \n",
              "193   0.719420   1.950091  -1.984846    1.010352  ...   -0.741460   -0.870994   \n",
              "194   0.797057   2.223602  -2.400666    1.054309  ...   -0.912308   -0.578684   \n",
              "195   0.874694   2.119236  -2.039084    0.985233  ...   -0.775629   -1.369639   \n",
              "196   0.874694   2.385549  -2.374838    0.872200  ...   -1.233504   -1.610365   \n",
              "\n",
              "     Feature_18  Feature_19  Feature_20  Feature_21  Feature_22  Feature_23  \\\n",
              "0      0.360666    0.042791   -0.379008   -0.068907    1.502159   -4.163087   \n",
              "1     -1.095301   -0.832000   -0.080621    0.054052    0.712911   -1.823570   \n",
              "2      0.360666   -0.752473   -0.407137   -0.271194    0.524487    0.250965   \n",
              "3      0.360666   -0.195788   -0.463947   -0.442543   -0.310978   -1.084408   \n",
              "4     -3.716043   -1.547737    1.602150    1.462129    0.609811    0.146367   \n",
              "..          ...         ...         ...         ...         ...         ...   \n",
              "192    0.360666    0.679002   -0.751854   -0.576608   -0.158106    0.449702   \n",
              "193    0.360666    0.679002   -0.727586   -0.561536   -0.111889    0.285832   \n",
              "194    0.360666    0.679002   -0.793220   -0.607546   -0.670050    0.425296   \n",
              "195    0.360666    0.679002   -0.793220   -0.601993   -0.321644    0.320698   \n",
              "196    0.360666    0.679002   -0.799287   -0.609926   -0.716268    0.313724   \n",
              "\n",
              "     Feature_24  Final_Index  \n",
              "0     -0.211794    -0.392761  \n",
              "1     -1.478565    -0.101165  \n",
              "2      0.641962     0.310064  \n",
              "3     -0.686137    -0.016347  \n",
              "4      0.478247    -0.232693  \n",
              "..          ...          ...  \n",
              "192    1.028725    -0.284990  \n",
              "193   -0.287298    -0.430713  \n",
              "194    0.753066    -0.367009  \n",
              "195    0.308336    -0.452352  \n",
              "196    1.264059    -0.450208  \n",
              "\n",
              "[197 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa632941-21e1-452f-82bb-41b339de03ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature_1</th>\n",
              "      <th>Feature_2</th>\n",
              "      <th>Feature_3</th>\n",
              "      <th>Feature_4</th>\n",
              "      <th>Feature_5</th>\n",
              "      <th>Feature_6</th>\n",
              "      <th>Feature_7</th>\n",
              "      <th>Feature_8</th>\n",
              "      <th>Feature_9</th>\n",
              "      <th>Feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>Feature_16</th>\n",
              "      <th>Feature_17</th>\n",
              "      <th>Feature_18</th>\n",
              "      <th>Feature_19</th>\n",
              "      <th>Feature_20</th>\n",
              "      <th>Feature_21</th>\n",
              "      <th>Feature_22</th>\n",
              "      <th>Feature_23</th>\n",
              "      <th>Feature_24</th>\n",
              "      <th>Final_Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.599647</td>\n",
              "      <td>0.172556</td>\n",
              "      <td>-1.154431</td>\n",
              "      <td>-0.956162</td>\n",
              "      <td>-0.585631</td>\n",
              "      <td>0.832135</td>\n",
              "      <td>-3.356507</td>\n",
              "      <td>-0.410742</td>\n",
              "      <td>0.905227</td>\n",
              "      <td>0.011890</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.017613</td>\n",
              "      <td>-0.148817</td>\n",
              "      <td>0.360666</td>\n",
              "      <td>0.042791</td>\n",
              "      <td>-0.379008</td>\n",
              "      <td>-0.068907</td>\n",
              "      <td>1.502159</td>\n",
              "      <td>-4.163087</td>\n",
              "      <td>-0.211794</td>\n",
              "      <td>-0.392761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.794071</td>\n",
              "      <td>-0.205150</td>\n",
              "      <td>-0.943991</td>\n",
              "      <td>-0.544680</td>\n",
              "      <td>-0.444571</td>\n",
              "      <td>-0.198315</td>\n",
              "      <td>-2.424866</td>\n",
              "      <td>-0.684253</td>\n",
              "      <td>1.049859</td>\n",
              "      <td>-0.032068</td>\n",
              "      <td>...</td>\n",
              "      <td>2.431666</td>\n",
              "      <td>-0.699047</td>\n",
              "      <td>-1.095301</td>\n",
              "      <td>-0.832000</td>\n",
              "      <td>-0.080621</td>\n",
              "      <td>0.054052</td>\n",
              "      <td>0.712911</td>\n",
              "      <td>-1.823570</td>\n",
              "      <td>-1.478565</td>\n",
              "      <td>-0.101165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.024714</td>\n",
              "      <td>-0.205150</td>\n",
              "      <td>0.150299</td>\n",
              "      <td>1.401948</td>\n",
              "      <td>0.973080</td>\n",
              "      <td>-0.858740</td>\n",
              "      <td>0.447692</td>\n",
              "      <td>1.942893</td>\n",
              "      <td>0.543645</td>\n",
              "      <td>-4.773193</td>\n",
              "      <td>...</td>\n",
              "      <td>2.760938</td>\n",
              "      <td>0.109103</td>\n",
              "      <td>0.360666</td>\n",
              "      <td>-0.752473</td>\n",
              "      <td>-0.407137</td>\n",
              "      <td>-0.271194</td>\n",
              "      <td>0.524487</td>\n",
              "      <td>0.250965</td>\n",
              "      <td>0.641962</td>\n",
              "      <td>0.310064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.390051</td>\n",
              "      <td>-1.338270</td>\n",
              "      <td>-0.060141</td>\n",
              "      <td>0.394344</td>\n",
              "      <td>-0.194190</td>\n",
              "      <td>0.063981</td>\n",
              "      <td>-1.687318</td>\n",
              "      <td>-1.098118</td>\n",
              "      <td>1.070521</td>\n",
              "      <td>0.143762</td>\n",
              "      <td>...</td>\n",
              "      <td>0.293883</td>\n",
              "      <td>0.143493</td>\n",
              "      <td>0.360666</td>\n",
              "      <td>-0.195788</td>\n",
              "      <td>-0.463947</td>\n",
              "      <td>-0.442543</td>\n",
              "      <td>-0.310978</td>\n",
              "      <td>-1.084408</td>\n",
              "      <td>-0.686137</td>\n",
              "      <td>-0.016347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.564282</td>\n",
              "      <td>-0.205150</td>\n",
              "      <td>-1.049211</td>\n",
              "      <td>-1.594488</td>\n",
              "      <td>-1.290930</td>\n",
              "      <td>1.661179</td>\n",
              "      <td>-0.406312</td>\n",
              "      <td>-0.633869</td>\n",
              "      <td>1.323629</td>\n",
              "      <td>-0.496761</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.339430</td>\n",
              "      <td>-0.991356</td>\n",
              "      <td>-3.716043</td>\n",
              "      <td>-1.547737</td>\n",
              "      <td>1.602150</td>\n",
              "      <td>1.462129</td>\n",
              "      <td>0.609811</td>\n",
              "      <td>0.146367</td>\n",
              "      <td>0.478247</td>\n",
              "      <td>-0.232693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>-1.530454</td>\n",
              "      <td>0.172556</td>\n",
              "      <td>0.381784</td>\n",
              "      <td>-0.966713</td>\n",
              "      <td>-0.807800</td>\n",
              "      <td>-0.235786</td>\n",
              "      <td>0.797057</td>\n",
              "      <td>1.467848</td>\n",
              "      <td>-1.690415</td>\n",
              "      <td>0.834522</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.556943</td>\n",
              "      <td>-0.441126</td>\n",
              "      <td>0.360666</td>\n",
              "      <td>0.679002</td>\n",
              "      <td>-0.751854</td>\n",
              "      <td>-0.576608</td>\n",
              "      <td>-0.158106</td>\n",
              "      <td>0.449702</td>\n",
              "      <td>1.028725</td>\n",
              "      <td>-0.284990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>-1.825507</td>\n",
              "      <td>0.172556</td>\n",
              "      <td>-0.396846</td>\n",
              "      <td>-1.299064</td>\n",
              "      <td>-0.906542</td>\n",
              "      <td>-1.074198</td>\n",
              "      <td>0.719420</td>\n",
              "      <td>1.950091</td>\n",
              "      <td>-1.984846</td>\n",
              "      <td>1.010352</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.741460</td>\n",
              "      <td>-0.870994</td>\n",
              "      <td>0.360666</td>\n",
              "      <td>0.679002</td>\n",
              "      <td>-0.727586</td>\n",
              "      <td>-0.561536</td>\n",
              "      <td>-0.111889</td>\n",
              "      <td>0.285832</td>\n",
              "      <td>-0.287298</td>\n",
              "      <td>-0.430713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>-1.615023</td>\n",
              "      <td>0.927970</td>\n",
              "      <td>0.234476</td>\n",
              "      <td>-0.971989</td>\n",
              "      <td>-0.966492</td>\n",
              "      <td>-0.558973</td>\n",
              "      <td>0.797057</td>\n",
              "      <td>2.223602</td>\n",
              "      <td>-2.400666</td>\n",
              "      <td>1.054309</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.912308</td>\n",
              "      <td>-0.578684</td>\n",
              "      <td>0.360666</td>\n",
              "      <td>0.679002</td>\n",
              "      <td>-0.793220</td>\n",
              "      <td>-0.607546</td>\n",
              "      <td>-0.670050</td>\n",
              "      <td>0.425296</td>\n",
              "      <td>0.753066</td>\n",
              "      <td>-0.367009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>-1.992766</td>\n",
              "      <td>-0.582857</td>\n",
              "      <td>-0.165361</td>\n",
              "      <td>-1.030018</td>\n",
              "      <td>-0.977072</td>\n",
              "      <td>-1.434855</td>\n",
              "      <td>0.874694</td>\n",
              "      <td>2.119236</td>\n",
              "      <td>-2.039084</td>\n",
              "      <td>0.985233</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.775629</td>\n",
              "      <td>-1.369639</td>\n",
              "      <td>0.360666</td>\n",
              "      <td>0.679002</td>\n",
              "      <td>-0.793220</td>\n",
              "      <td>-0.601993</td>\n",
              "      <td>-0.321644</td>\n",
              "      <td>0.320698</td>\n",
              "      <td>0.308336</td>\n",
              "      <td>-0.452352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>-1.996524</td>\n",
              "      <td>-0.205150</td>\n",
              "      <td>-0.270582</td>\n",
              "      <td>-0.724044</td>\n",
              "      <td>-1.174556</td>\n",
              "      <td>-0.896211</td>\n",
              "      <td>0.874694</td>\n",
              "      <td>2.385549</td>\n",
              "      <td>-2.374838</td>\n",
              "      <td>0.872200</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.233504</td>\n",
              "      <td>-1.610365</td>\n",
              "      <td>0.360666</td>\n",
              "      <td>0.679002</td>\n",
              "      <td>-0.799287</td>\n",
              "      <td>-0.609926</td>\n",
              "      <td>-0.716268</td>\n",
              "      <td>0.313724</td>\n",
              "      <td>1.264059</td>\n",
              "      <td>-0.450208</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>197 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa632941-21e1-452f-82bb-41b339de03ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa632941-21e1-452f-82bb-41b339de03ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa632941-21e1-452f-82bb-41b339de03ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-434f93f3-ffbb-45fc-93cd-6994f9da47fe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-434f93f3-ffbb-45fc-93cd-6994f9da47fe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-434f93f3-ffbb-45fc-93cd-6994f9da47fe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f6c3a24c-5e85-4e1c-8ec1-9e16b254ec01\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f6c3a24c-5e85-4e1c-8ec1-9e16b254ec01 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)\n",
        "df.to_excel(\"socioecon_AUTOENCODER_best_auto_config1_res_onedim_ss_1215.xlsx\", index=False)\n",
        "\n",
        "print(\"File 'socioecon_AUTOENCODER.xlsx' has been saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f202fb0-649f-4d9e-e80a-3ac57759fa10",
        "id": "CPhHK8Y3iOJN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'socioecon_AUTOENCODER.xlsx' has been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = []\n",
        "for i in range(bottleneck_output_2.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_2[:, i], random_state=42)\n",
        "    mi_scores.append(mi)\n"
      ],
      "metadata": {
        "id": "nEACM_l7iOJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19ce6981-2e08-4cc6-9317-ec1326173ca9",
        "id": "Y9LblN9tiOJN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.45192428, 0.27543286, 0.35131272, 0.66897774, 0.26529562,\n",
              "        0.26748981, 0.46601931, 0.77323608, 1.23567364, 0.41755628,\n",
              "        0.81497429, 0.60826916, 0.3553879 , 0.35670747, 0.66300461,\n",
              "        0.70071738, 0.4564292 , 0.06154863, 0.14696738, 0.7589443 ,\n",
              "        0.57723572, 0.1882379 , 0.28577697, 0.26066358])]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b9dfd1-e31c-4de4-91a6-90c4da68b5be",
        "id": "1uDFYk5LiOJN"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24, 1)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_1.shape[1]))\n",
        "\n",
        "for dim in range(bottleneck_output_1.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim]"
      ],
      "metadata": {
        "id": "oqqcDGKSiOJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))"
      ],
      "metadata": {
        "id": "Xqs9IZMiiOJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "COgP1ZCeiOJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "10ba5531-c054-4d06-bd7f-ffd27580039d",
        "id": "r4CyE7U0iOJO"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-abb46f40-2c68-4025-afd9-015c08d33fe5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature_1</th>\n",
              "      <th>Feature_2</th>\n",
              "      <th>Feature_3</th>\n",
              "      <th>Feature_4</th>\n",
              "      <th>Feature_5</th>\n",
              "      <th>Feature_6</th>\n",
              "      <th>Feature_7</th>\n",
              "      <th>Feature_8</th>\n",
              "      <th>Feature_9</th>\n",
              "      <th>Feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>Feature_16</th>\n",
              "      <th>Feature_17</th>\n",
              "      <th>Feature_18</th>\n",
              "      <th>Feature_19</th>\n",
              "      <th>Feature_20</th>\n",
              "      <th>Feature_21</th>\n",
              "      <th>Feature_22</th>\n",
              "      <th>Feature_23</th>\n",
              "      <th>Feature_24</th>\n",
              "      <th>Final_Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.599647</td>\n",
              "      <td>0.172556</td>\n",
              "      <td>-1.154431</td>\n",
              "      <td>-0.956162</td>\n",
              "      <td>-0.585631</td>\n",
              "      <td>0.832135</td>\n",
              "      <td>-3.356507</td>\n",
              "      <td>-0.410742</td>\n",
              "      <td>0.905227</td>\n",
              "      <td>0.011890</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.017613</td>\n",
              "      <td>-0.148817</td>\n",
              "      <td>0.360666</td>\n",
              "      <td>0.042791</td>\n",
              "      <td>-0.379008</td>\n",
              "      <td>-0.068907</td>\n",
              "      <td>1.502159</td>\n",
              "      <td>-4.163087</td>\n",
              "      <td>-0.211794</td>\n",
              "      <td>-0.439530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.794071</td>\n",
              "      <td>-0.205150</td>\n",
              "      <td>-0.943991</td>\n",
              "      <td>-0.544680</td>\n",
              "      <td>-0.444571</td>\n",
              "      <td>-0.198315</td>\n",
              "      <td>-2.424866</td>\n",
              "      <td>-0.684253</td>\n",
              "      <td>1.049859</td>\n",
              "      <td>-0.032068</td>\n",
              "      <td>...</td>\n",
              "      <td>2.431666</td>\n",
              "      <td>-0.699047</td>\n",
              "      <td>-1.095301</td>\n",
              "      <td>-0.832000</td>\n",
              "      <td>-0.080621</td>\n",
              "      <td>0.054052</td>\n",
              "      <td>0.712911</td>\n",
              "      <td>-1.823570</td>\n",
              "      <td>-1.478565</td>\n",
              "      <td>-0.116126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.024714</td>\n",
              "      <td>-0.205150</td>\n",
              "      <td>0.150299</td>\n",
              "      <td>1.401948</td>\n",
              "      <td>0.973080</td>\n",
              "      <td>-0.858740</td>\n",
              "      <td>0.447692</td>\n",
              "      <td>1.942893</td>\n",
              "      <td>0.543645</td>\n",
              "      <td>-4.773193</td>\n",
              "      <td>...</td>\n",
              "      <td>2.760938</td>\n",
              "      <td>0.109103</td>\n",
              "      <td>0.360666</td>\n",
              "      <td>-0.752473</td>\n",
              "      <td>-0.407137</td>\n",
              "      <td>-0.271194</td>\n",
              "      <td>0.524487</td>\n",
              "      <td>0.250965</td>\n",
              "      <td>0.641962</td>\n",
              "      <td>0.290670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.390051</td>\n",
              "      <td>-1.338270</td>\n",
              "      <td>-0.060141</td>\n",
              "      <td>0.394344</td>\n",
              "      <td>-0.194190</td>\n",
              "      <td>0.063981</td>\n",
              "      <td>-1.687318</td>\n",
              "      <td>-1.098118</td>\n",
              "      <td>1.070521</td>\n",
              "      <td>0.143762</td>\n",
              "      <td>...</td>\n",
              "      <td>0.293883</td>\n",
              "      <td>0.143493</td>\n",
              "      <td>0.360666</td>\n",
              "      <td>-0.195788</td>\n",
              "      <td>-0.463947</td>\n",
              "      <td>-0.442543</td>\n",
              "      <td>-0.310978</td>\n",
              "      <td>-1.084408</td>\n",
              "      <td>-0.686137</td>\n",
              "      <td>-0.019724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.564282</td>\n",
              "      <td>-0.205150</td>\n",
              "      <td>-1.049211</td>\n",
              "      <td>-1.594488</td>\n",
              "      <td>-1.290930</td>\n",
              "      <td>1.661179</td>\n",
              "      <td>-0.406312</td>\n",
              "      <td>-0.633869</td>\n",
              "      <td>1.323629</td>\n",
              "      <td>-0.496761</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.339430</td>\n",
              "      <td>-0.991356</td>\n",
              "      <td>-3.716043</td>\n",
              "      <td>-1.547737</td>\n",
              "      <td>1.602150</td>\n",
              "      <td>1.462129</td>\n",
              "      <td>0.609811</td>\n",
              "      <td>0.146367</td>\n",
              "      <td>0.478247</td>\n",
              "      <td>-0.222960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>-1.530454</td>\n",
              "      <td>0.172556</td>\n",
              "      <td>0.381784</td>\n",
              "      <td>-0.966713</td>\n",
              "      <td>-0.807800</td>\n",
              "      <td>-0.235786</td>\n",
              "      <td>0.797057</td>\n",
              "      <td>1.467848</td>\n",
              "      <td>-1.690415</td>\n",
              "      <td>0.834522</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.556943</td>\n",
              "      <td>-0.441126</td>\n",
              "      <td>0.360666</td>\n",
              "      <td>0.679002</td>\n",
              "      <td>-0.751854</td>\n",
              "      <td>-0.576608</td>\n",
              "      <td>-0.158106</td>\n",
              "      <td>0.449702</td>\n",
              "      <td>1.028725</td>\n",
              "      <td>-0.270772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>-1.825507</td>\n",
              "      <td>0.172556</td>\n",
              "      <td>-0.396846</td>\n",
              "      <td>-1.299064</td>\n",
              "      <td>-0.906542</td>\n",
              "      <td>-1.074198</td>\n",
              "      <td>0.719420</td>\n",
              "      <td>1.950091</td>\n",
              "      <td>-1.984846</td>\n",
              "      <td>1.010352</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.741460</td>\n",
              "      <td>-0.870994</td>\n",
              "      <td>0.360666</td>\n",
              "      <td>0.679002</td>\n",
              "      <td>-0.727586</td>\n",
              "      <td>-0.561536</td>\n",
              "      <td>-0.111889</td>\n",
              "      <td>0.285832</td>\n",
              "      <td>-0.287298</td>\n",
              "      <td>-0.413305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>-1.615023</td>\n",
              "      <td>0.927970</td>\n",
              "      <td>0.234476</td>\n",
              "      <td>-0.971989</td>\n",
              "      <td>-0.966492</td>\n",
              "      <td>-0.558973</td>\n",
              "      <td>0.797057</td>\n",
              "      <td>2.223602</td>\n",
              "      <td>-2.400666</td>\n",
              "      <td>1.054309</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.912308</td>\n",
              "      <td>-0.578684</td>\n",
              "      <td>0.360666</td>\n",
              "      <td>0.679002</td>\n",
              "      <td>-0.793220</td>\n",
              "      <td>-0.607546</td>\n",
              "      <td>-0.670050</td>\n",
              "      <td>0.425296</td>\n",
              "      <td>0.753066</td>\n",
              "      <td>-0.357296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>-1.992766</td>\n",
              "      <td>-0.582857</td>\n",
              "      <td>-0.165361</td>\n",
              "      <td>-1.030018</td>\n",
              "      <td>-0.977072</td>\n",
              "      <td>-1.434855</td>\n",
              "      <td>0.874694</td>\n",
              "      <td>2.119236</td>\n",
              "      <td>-2.039084</td>\n",
              "      <td>0.985233</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.775629</td>\n",
              "      <td>-1.369639</td>\n",
              "      <td>0.360666</td>\n",
              "      <td>0.679002</td>\n",
              "      <td>-0.793220</td>\n",
              "      <td>-0.601993</td>\n",
              "      <td>-0.321644</td>\n",
              "      <td>0.320698</td>\n",
              "      <td>0.308336</td>\n",
              "      <td>-0.428658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>-1.996524</td>\n",
              "      <td>-0.205150</td>\n",
              "      <td>-0.270582</td>\n",
              "      <td>-0.724044</td>\n",
              "      <td>-1.174556</td>\n",
              "      <td>-0.896211</td>\n",
              "      <td>0.874694</td>\n",
              "      <td>2.385549</td>\n",
              "      <td>-2.374838</td>\n",
              "      <td>0.872200</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.233504</td>\n",
              "      <td>-1.610365</td>\n",
              "      <td>0.360666</td>\n",
              "      <td>0.679002</td>\n",
              "      <td>-0.799287</td>\n",
              "      <td>-0.609926</td>\n",
              "      <td>-0.716268</td>\n",
              "      <td>0.313724</td>\n",
              "      <td>1.264059</td>\n",
              "      <td>-0.434806</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>197 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abb46f40-2c68-4025-afd9-015c08d33fe5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-abb46f40-2c68-4025-afd9-015c08d33fe5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-abb46f40-2c68-4025-afd9-015c08d33fe5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3dc9ef47-171d-4ab4-864c-4d2af5693fd3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3dc9ef47-171d-4ab4-864c-4d2af5693fd3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3dc9ef47-171d-4ab4-864c-4d2af5693fd3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a7337af6-40c6-4d05-810f-cd7ba8388c98\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a7337af6-40c6-4d05-810f-cd7ba8388c98 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
              "0    -1.599647   0.172556  -1.154431  -0.956162  -0.585631   0.832135   \n",
              "1    -1.794071  -0.205150  -0.943991  -0.544680  -0.444571  -0.198315   \n",
              "2    -2.024714  -0.205150   0.150299   1.401948   0.973080  -0.858740   \n",
              "3    -0.390051  -1.338270  -0.060141   0.394344  -0.194190   0.063981   \n",
              "4    -1.564282  -0.205150  -1.049211  -1.594488  -1.290930   1.661179   \n",
              "..         ...        ...        ...        ...        ...        ...   \n",
              "192  -1.530454   0.172556   0.381784  -0.966713  -0.807800  -0.235786   \n",
              "193  -1.825507   0.172556  -0.396846  -1.299064  -0.906542  -1.074198   \n",
              "194  -1.615023   0.927970   0.234476  -0.971989  -0.966492  -0.558973   \n",
              "195  -1.992766  -0.582857  -0.165361  -1.030018  -0.977072  -1.434855   \n",
              "196  -1.996524  -0.205150  -0.270582  -0.724044  -1.174556  -0.896211   \n",
              "\n",
              "     Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_16  Feature_17  \\\n",
              "0    -3.356507  -0.410742   0.905227    0.011890  ...   -1.017613   -0.148817   \n",
              "1    -2.424866  -0.684253   1.049859   -0.032068  ...    2.431666   -0.699047   \n",
              "2     0.447692   1.942893   0.543645   -4.773193  ...    2.760938    0.109103   \n",
              "3    -1.687318  -1.098118   1.070521    0.143762  ...    0.293883    0.143493   \n",
              "4    -0.406312  -0.633869   1.323629   -0.496761  ...   -1.339430   -0.991356   \n",
              "..         ...        ...        ...         ...  ...         ...         ...   \n",
              "192   0.797057   1.467848  -1.690415    0.834522  ...   -0.556943   -0.441126   \n",
              "193   0.719420   1.950091  -1.984846    1.010352  ...   -0.741460   -0.870994   \n",
              "194   0.797057   2.223602  -2.400666    1.054309  ...   -0.912308   -0.578684   \n",
              "195   0.874694   2.119236  -2.039084    0.985233  ...   -0.775629   -1.369639   \n",
              "196   0.874694   2.385549  -2.374838    0.872200  ...   -1.233504   -1.610365   \n",
              "\n",
              "     Feature_18  Feature_19  Feature_20  Feature_21  Feature_22  Feature_23  \\\n",
              "0      0.360666    0.042791   -0.379008   -0.068907    1.502159   -4.163087   \n",
              "1     -1.095301   -0.832000   -0.080621    0.054052    0.712911   -1.823570   \n",
              "2      0.360666   -0.752473   -0.407137   -0.271194    0.524487    0.250965   \n",
              "3      0.360666   -0.195788   -0.463947   -0.442543   -0.310978   -1.084408   \n",
              "4     -3.716043   -1.547737    1.602150    1.462129    0.609811    0.146367   \n",
              "..          ...         ...         ...         ...         ...         ...   \n",
              "192    0.360666    0.679002   -0.751854   -0.576608   -0.158106    0.449702   \n",
              "193    0.360666    0.679002   -0.727586   -0.561536   -0.111889    0.285832   \n",
              "194    0.360666    0.679002   -0.793220   -0.607546   -0.670050    0.425296   \n",
              "195    0.360666    0.679002   -0.793220   -0.601993   -0.321644    0.320698   \n",
              "196    0.360666    0.679002   -0.799287   -0.609926   -0.716268    0.313724   \n",
              "\n",
              "     Feature_24  Final_Index  \n",
              "0     -0.211794    -0.439530  \n",
              "1     -1.478565    -0.116126  \n",
              "2      0.641962     0.290670  \n",
              "3     -0.686137    -0.019724  \n",
              "4      0.478247    -0.222960  \n",
              "..          ...          ...  \n",
              "192    1.028725    -0.270772  \n",
              "193   -0.287298    -0.413305  \n",
              "194    0.753066    -0.357296  \n",
              "195    0.308336    -0.428658  \n",
              "196    1.264059    -0.434806  \n",
              "\n",
              "[197 rows x 25 columns]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)\n",
        "df.to_excel(\"socioecon_AUTOENCODER_best_auto_config2_res_onedim_ss_1215.xlsx\", index=False)\n",
        "\n",
        "print(\"File 'socioecon_AUTOENCODER.xlsx' has been saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a53a95b-e092-427f-8fb4-47f77ef5a7a0",
        "id": "hpj_39AAiOJO"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File 'socioecon_AUTOENCODER.xlsx' has been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## res / only one encoding dimension - minmax (method 2)"
      ],
      "metadata": {
        "id": "BlbvPT8ziUaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mutual_info_score\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from itertools import product\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from kerastuner import HyperModel, RandomSearch"
      ],
      "metadata": {
        "id": "fOYA-7leiUaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('SE_Original_(NOT SHARED) FOR USE_2020_residential.xlsx')\n",
        "X_ori = data.iloc[:, 3:27].values\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X_ori)\n",
        "\n",
        "# Split\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ImdB3EgpiUaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def create_autoencoder(input_dim, encoding_dim, hidden_layers_before, hidden_layers_after, neurons_before, neurons_after):\n",
        "    # Define the input layer\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "\n",
        "    # Build the encoder part\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons_before, activation='relu', name=f'dense_encoder_{i+1}')(x)\n",
        "\n",
        "    # Bottleneck layer (encoding layer)\n",
        "    bottleneck = Dense(encoding_dim, activation='relu', name='bottleneck')(x)\n",
        "\n",
        "    # Build the decoder part\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons_after, activation='relu', name=f'dense_decoder_{i+1}')(x)\n",
        "\n",
        "    # Output layer, with the same dimension as the input\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Define the complete autoencoder model\n",
        "    autoencoder = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "xqh7kWiEiUaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial tuning\n",
        "hidden_layers_options = [2, 4, 6, 8]  # Even numbers to ensure symmetry\n",
        "neurons_options = [6, 8, 10, 12, 14, 16]\n",
        "encoding_dims_options = [1]\n",
        "results = []\n",
        "\n",
        "# Iterate through each combination of hyperparameters\n",
        "for hidden_layers in hidden_layers_options:\n",
        "    hidden_layers_before = hidden_layers // 2\n",
        "    hidden_layers_after = hidden_layers // 2\n",
        "\n",
        "    for neurons in neurons_options:\n",
        "        for encoding_dim in encoding_dims_options:\n",
        "            autoencoder = create_autoencoder(\n",
        "                input_dim=X_train.shape[1],\n",
        "                encoding_dim=encoding_dim,\n",
        "                hidden_layers_before=hidden_layers_before,\n",
        "                hidden_layers_after=hidden_layers_after,\n",
        "                neurons_before=neurons,\n",
        "                neurons_after=neurons\n",
        "            )\n",
        "            autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "            history = autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, verbose=0, validation_data=(X_test, X_test))\n",
        "\n",
        "            # Calculate average loss on the test set\n",
        "            test_loss = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
        "            results.append((hidden_layers, encoding_dim, neurons, test_loss))\n",
        "\n",
        "# Sort results by the lowest test loss and select the best two configurations\n",
        "sorted_results = sorted(results, key=lambda x: x[3])\n",
        "best_configs = sorted_results[:2]\n",
        "\n",
        "# Print best configurations for reference and show model summary\n",
        "print(\"Top two configurations:\")\n",
        "for config in best_configs:\n",
        "    hidden_layers, encoding_dim, neurons, test_loss = config\n",
        "    print(f\"Hidden layers: {hidden_layers}, Encoding dimension: {encoding_dim}, Neurons: {neurons}, Test loss: {test_loss}\")\n",
        "\n",
        "    # Recreate and display the model summary for the best configurations\n",
        "    autoencoder = create_autoencoder(\n",
        "        input_dim=X_train.shape[1],\n",
        "        encoding_dim=encoding_dim,\n",
        "        hidden_layers_before=hidden_layers // 2,\n",
        "        hidden_layers_after=hidden_layers // 2,\n",
        "        neurons_before=neurons,\n",
        "        neurons_after=neurons\n",
        "    )\n",
        "    autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "outputId": "42bf0787-65fa-41a2-d582-f98a50ba1b71",
        "id": "uBC-4X6QiUaR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top two configurations:\n",
            "Hidden layers: 6, Encoding dimension: 1, Neurons: 12, Test loss: 0.03908932954072952\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m13\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │              \u001b[38;5;34m24\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m312\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,273\u001b[0m (4.97 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,273</span> (4.97 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,273\u001b[0m (4.97 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,273</span> (4.97 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden layers: 4, Encoding dimension: 1, Neurons: 14, Test loss: 0.03944898396730423\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m350\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m15\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │              \u001b[38;5;34m28\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m360\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,173\u001b[0m (4.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,173</span> (4.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,173\u001b[0m (4.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,173</span> (4.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner import Hyperband\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def build_model(hp, input_dim, hidden_layers_before, hidden_layers_after):\n",
        "    # Hyperparameters to tune\n",
        "    encoding_dim = hp.Choice('encoding_dim', [1]) # 1D encoding dimension\n",
        "    neurons = hp.Int('neurons', min_value=6, max_value=24, step=3)\n",
        "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "    batch_size = hp.Choice('batch_size', [16, 32, 64])\n",
        "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "    # Build the model structure\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_encoder_{i+1}')(x)\n",
        "    bottleneck = Dense(encoding_dim, activation=activation, name='bottleneck')(x)\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_decoder_{i+1}')(x)\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Compile model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
        "    return model"
      ],
      "metadata": {
        "id": "xCx-oKU7iUaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import Hyperband\n",
        "\n",
        "tuner_config_1 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=3, hidden_layers_after=3),\n",
        "    objective='val_loss', max_epochs=50, factor=3, directory='hyperparam_tuning_1_only1___minma__x', project_name='model_config_1'\n",
        ")\n",
        "\n",
        "tuner_config_2 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=2, hidden_layers_after=2),\n",
        "    objective='val_loss', max_epochs=50, factor=3, directory='hyperparam_tuning_2_only1___minma__x', project_name='model_config_2'\n",
        ")"
      ],
      "metadata": {
        "id": "wSbBrE1ViUaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning for configuration 1\n",
        "tuner_config_1.search(X_train, X_train, epochs=50, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get the best model for configuration 1\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9af54dc1-5657-491a-a5f7-b4939f4a4b92",
        "id": "8mRMR6DaiUaT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 12s]\n",
            "val_loss: 0.04257829114794731\n",
            "\n",
            "Best val_loss So Far: 0.024443302303552628\n",
            "Total elapsed time: 00h 09m 28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning for configuration 2\n",
        "tuner_config_2.search(X_train, X_train, epochs=50, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get the best model for configuration 2\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "outputId": "537eb538-14b2-48a2-c80d-eee7c97f8af8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaZ7SypEiUaU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 14s]\n",
            "val_loss: 0.24080458283424377\n",
            "\n",
            "Best val_loss So Far: 0.02636290155351162\n",
            "Total elapsed time: 00h 10m 56s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C57fXlncijHe"
      },
      "source": [
        "#### check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJVwmeIuijHg"
      },
      "outputs": [],
      "source": [
        "# Get the best model\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e21P0F3BijHg",
        "outputId": "bb054055-59e1-4f63-abb9-5574ccab8a03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 1, 'neurons': 18, 'learning_rate': 0.01, 'batch_size': 32, 'activation': 'tanh', 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0067'}\n",
            "\n",
            "Test Loss: 0.024443302303552628\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_1.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_1.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTtXY9s4ijHg"
      },
      "outputs": [],
      "source": [
        "# Get the best model\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_3lbBHJijHg",
        "outputId": "ade00e1a-5708-47ca-d941-3b7164f7e761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 1, 'neurons': 12, 'learning_rate': 0.01, 'batch_size': 16, 'activation': 'tanh', 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0068'}\n",
            "\n",
            "Test Loss: 0.02636290155351162\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_2.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_2.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### past"
      ],
      "metadata": {
        "id": "7twSG2B4imTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# best model for configuration 1\n",
        "print(\"Best Model Structure for Configuration 1:\")\n",
        "best_model_config_1.summary()\n",
        "\n",
        "# best model for configuration 2\n",
        "print(\"\\nBest Model Structure for Configuration 2:\")\n",
        "best_model_config_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "outputId": "ae866cb1-b4f9-40b0-cbf1-083c2879cabd",
        "id": "9qg2fSWriUaV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model Structure for Configuration 1:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m450\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m19\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │              \u001b[38;5;34m36\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m456\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">456</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,329\u001b[0m (9.10 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,329</span> (9.10 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,329\u001b[0m (9.10 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,329</span> (9.10 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Model Structure for Configuration 2:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m13\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │              \u001b[38;5;34m24\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m312\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m961\u001b[0m (3.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">961</span> (3.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m961\u001b[0m (3.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">961</span> (3.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the best model in configuration 1\n",
        "print(\"Best Model for Configuration 1:\")\n",
        "for layer in best_model_config_1.layers:\n",
        "    if hasattr(layer, 'output_shape'):\n",
        "        output_shape = layer.output_shape\n",
        "    else:\n",
        "        output_shape = layer.get_output_shape_at(0) if hasattr(layer, 'get_output_shape_at') else 'N/A'\n",
        "    print(f\"Layer: {layer.name}, Type: {layer.__class__.__name__}, Output Shape: {output_shape}, Parameters: {layer.count_params()}\")\n",
        "\n",
        "# best model in configuration 2\n",
        "print(\"\\nBest Model for Configuration 2:\")\n",
        "for layer in best_model_config_2.layers:\n",
        "    if hasattr(layer, 'output_shape'):\n",
        "        output_shape = layer.output_shape\n",
        "    else:\n",
        "        output_shape = layer.get_output_shape_at(0) if hasattr(layer, 'get_output_shape_at') else 'N/A'\n",
        "    print(f\"Layer: {layer.name}, Type: {layer.__class__.__name__}, Output Shape: {output_shape}, Parameters: {layer.count_params()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20e91e77-1c81-44c5-e38a-dd4a213c5d4d",
        "id": "YCphy2KaiUaX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model for Configuration 1:\n",
            "Layer: input_layer, Type: InputLayer, Output Shape: N/A, Parameters: 0\n",
            "Layer: dense_encoder_1, Type: Dense, Output Shape: N/A, Parameters: 450\n",
            "Layer: dense_encoder_2, Type: Dense, Output Shape: N/A, Parameters: 342\n",
            "Layer: dense_encoder_3, Type: Dense, Output Shape: N/A, Parameters: 342\n",
            "Layer: bottleneck, Type: Dense, Output Shape: N/A, Parameters: 19\n",
            "Layer: dense_decoder_1, Type: Dense, Output Shape: N/A, Parameters: 36\n",
            "Layer: dense_decoder_2, Type: Dense, Output Shape: N/A, Parameters: 342\n",
            "Layer: dense_decoder_3, Type: Dense, Output Shape: N/A, Parameters: 342\n",
            "Layer: output_layer, Type: Dense, Output Shape: N/A, Parameters: 456\n",
            "\n",
            "Best Model for Configuration 2:\n",
            "Layer: input_layer, Type: InputLayer, Output Shape: N/A, Parameters: 0\n",
            "Layer: dense_encoder_1, Type: Dense, Output Shape: N/A, Parameters: 300\n",
            "Layer: dense_encoder_2, Type: Dense, Output Shape: N/A, Parameters: 156\n",
            "Layer: bottleneck, Type: Dense, Output Shape: N/A, Parameters: 13\n",
            "Layer: dense_decoder_1, Type: Dense, Output Shape: N/A, Parameters: 24\n",
            "Layer: dense_decoder_2, Type: Dense, Output Shape: N/A, Parameters: 156\n",
            "Layer: output_layer, Type: Dense, Output Shape: N/A, Parameters: 312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_1 = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder_model_config_1 = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer_config_1)\n",
        "bottleneck_output_1 = encoder_model_config_1.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ebcc1e-7cfa-4414-bee4-2c5b12325ed7",
        "id": "gy7yx0eeiUaY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f88aab50f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f88aab50f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_2 = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder_model_config_2 = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer_config_2)\n",
        "bottleneck_output_2 = encoder_model_config_2.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06cae794-50eb-4740-a0f5-a93d66672712",
        "id": "I2EQhvHxiUaZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_output_1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e2c118-a106-414e-c3f7-f059459f186e",
        "id": "mejkfj8jiUaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(197, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_output_2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c56a5cca-5187-4720-97a3-5368d3591217",
        "id": "eK-VF7lBiUab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(197, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_regression\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "3KXs4B2ZiUab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = []\n",
        "for i in range(bottleneck_output_1.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_1[:, i], random_state=42)\n",
        "    mi_scores.append(mi)\n"
      ],
      "metadata": {
        "id": "ZmBlD814iUac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c09de45-40db-440e-ed33-e5875a993ab5",
        "id": "UNvIFCbniUac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.45808009, 0.16703029, 0.18016476, 0.52806386, 0.22005145,\n",
              "        0.23444151, 0.43214195, 0.91923872, 1.48457639, 0.44000686,\n",
              "        0.97619557, 0.75268892, 0.32334002, 0.37013004, 0.49771532,\n",
              "        0.60622577, 0.41354815, 0.08761954, 0.15684266, 0.69981308,\n",
              "        0.57170542, 0.07656843, 0.14610777, 0.1472826 ])]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a91dba5f-4557-4069-d8a6-55dc1b37b0ab",
        "id": "ES1bUjWniUad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_1.shape[1]))\n",
        "\n",
        "for dim in range(bottleneck_output_1.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim]"
      ],
      "metadata": {
        "id": "uYsY2wHZiUae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))"
      ],
      "metadata": {
        "id": "eMM5eFOeiUae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "KY-BrYNaiUaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "1a8db9b4-28ef-4cae-bcd1-bddee4b82696",
        "id": "DKrkJvntiUaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
              "0     0.131654     0.8750   0.120482   0.154095   0.182022   0.674157   \n",
              "1     0.071436     0.8125   0.150602   0.238147   0.211985   0.449438   \n",
              "2     0.000000     0.8125   0.307229   0.635776   0.513109   0.305414   \n",
              "3     0.506297     0.6250   0.277108   0.429957   0.265169   0.506639   \n",
              "4     0.142608     0.8125   0.135542   0.023707   0.032210   0.854954   \n",
              "..         ...        ...        ...        ...        ...        ...   \n",
              "192   0.153085     0.8750   0.340361   0.151940   0.134831   0.441267   \n",
              "193   0.061700     0.8750   0.228916   0.084052   0.113858   0.258427   \n",
              "194   0.126892     1.0000   0.319277   0.150862   0.101124   0.370787   \n",
              "195   0.009895     0.7500   0.262048   0.139009   0.098876   0.179775   \n",
              "196   0.008731     0.8125   0.246988   0.201509   0.056929   0.297242   \n",
              "\n",
              "     Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_16  Feature_17  \\\n",
              "0     0.192593   0.291705   0.877313    0.821121  ...    0.090142    0.274691   \n",
              "1     0.370370   0.222425   0.915696    0.813578  ...    0.800026    0.175926   \n",
              "2     0.918519   0.887876   0.781357    0.000000  ...    0.867792    0.320988   \n",
              "3     0.511111   0.117593   0.921179    0.843750  ...    0.360056    0.327160   \n",
              "4     0.755556   0.235187   0.988348    0.733836  ...    0.023910    0.123457   \n",
              "..         ...        ...        ...         ...  ...         ...         ...   \n",
              "192   0.985185   0.767548   0.188485    0.962284  ...    0.184951    0.222222   \n",
              "193   0.970370   0.889699   0.110350    0.992457  ...    0.146976    0.145062   \n",
              "194   0.985185   0.958979   0.000000    1.000000  ...    0.111814    0.197531   \n",
              "195   1.000000   0.932543   0.095956    0.988147  ...    0.139944    0.055556   \n",
              "196   1.000000   1.000000   0.006854    0.968750  ...    0.045710    0.012346   \n",
              "\n",
              "     Feature_18  Feature_19  Feature_20  Feature_21  Feature_22  Feature_23  \\\n",
              "0      1.000000    0.873016    0.097033    0.108458       0.846    0.409878   \n",
              "1      0.761905    0.698413    0.160974    0.132647       0.624    0.693119   \n",
              "2      1.000000    0.714286    0.091006    0.068664       0.571    0.944280   \n",
              "3      1.000000    0.825397    0.078832    0.034956       0.336    0.782609   \n",
              "4      0.333333    0.555556    0.521570    0.409644       0.595    0.931617   \n",
              "..          ...         ...         ...         ...         ...         ...   \n",
              "192    1.000000    1.000000    0.017137    0.008583       0.379    0.968341   \n",
              "193    1.000000    1.000000    0.022338    0.011548       0.392    0.948501   \n",
              "194    1.000000    1.000000    0.008273    0.002497       0.235    0.965386   \n",
              "195    1.000000    1.000000    0.008273    0.003589       0.333    0.952723   \n",
              "196    1.000000    1.000000    0.006973    0.002029       0.222    0.951878   \n",
              "\n",
              "     Feature_24  Final_Index  \n",
              "0      0.706241     0.402076  \n",
              "1      0.472230     0.457849  \n",
              "2      0.863955     0.516496  \n",
              "3      0.618615     0.478956  \n",
              "4      0.833712     0.436697  \n",
              "..          ...          ...  \n",
              "192    0.935401     0.413225  \n",
              "193    0.692293     0.390596  \n",
              "194    0.884479     0.392526  \n",
              "195    0.802324     0.386895  \n",
              "196    0.978874     0.380861  \n",
              "\n",
              "[197 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-372d245d-6cce-4bac-b39b-67c41e86fb31\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature_1</th>\n",
              "      <th>Feature_2</th>\n",
              "      <th>Feature_3</th>\n",
              "      <th>Feature_4</th>\n",
              "      <th>Feature_5</th>\n",
              "      <th>Feature_6</th>\n",
              "      <th>Feature_7</th>\n",
              "      <th>Feature_8</th>\n",
              "      <th>Feature_9</th>\n",
              "      <th>Feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>Feature_16</th>\n",
              "      <th>Feature_17</th>\n",
              "      <th>Feature_18</th>\n",
              "      <th>Feature_19</th>\n",
              "      <th>Feature_20</th>\n",
              "      <th>Feature_21</th>\n",
              "      <th>Feature_22</th>\n",
              "      <th>Feature_23</th>\n",
              "      <th>Feature_24</th>\n",
              "      <th>Final_Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.131654</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.120482</td>\n",
              "      <td>0.154095</td>\n",
              "      <td>0.182022</td>\n",
              "      <td>0.674157</td>\n",
              "      <td>0.192593</td>\n",
              "      <td>0.291705</td>\n",
              "      <td>0.877313</td>\n",
              "      <td>0.821121</td>\n",
              "      <td>...</td>\n",
              "      <td>0.090142</td>\n",
              "      <td>0.274691</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.873016</td>\n",
              "      <td>0.097033</td>\n",
              "      <td>0.108458</td>\n",
              "      <td>0.846</td>\n",
              "      <td>0.409878</td>\n",
              "      <td>0.706241</td>\n",
              "      <td>0.402076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.071436</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.150602</td>\n",
              "      <td>0.238147</td>\n",
              "      <td>0.211985</td>\n",
              "      <td>0.449438</td>\n",
              "      <td>0.370370</td>\n",
              "      <td>0.222425</td>\n",
              "      <td>0.915696</td>\n",
              "      <td>0.813578</td>\n",
              "      <td>...</td>\n",
              "      <td>0.800026</td>\n",
              "      <td>0.175926</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.698413</td>\n",
              "      <td>0.160974</td>\n",
              "      <td>0.132647</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.693119</td>\n",
              "      <td>0.472230</td>\n",
              "      <td>0.457849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.307229</td>\n",
              "      <td>0.635776</td>\n",
              "      <td>0.513109</td>\n",
              "      <td>0.305414</td>\n",
              "      <td>0.918519</td>\n",
              "      <td>0.887876</td>\n",
              "      <td>0.781357</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.867792</td>\n",
              "      <td>0.320988</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.091006</td>\n",
              "      <td>0.068664</td>\n",
              "      <td>0.571</td>\n",
              "      <td>0.944280</td>\n",
              "      <td>0.863955</td>\n",
              "      <td>0.516496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.506297</td>\n",
              "      <td>0.6250</td>\n",
              "      <td>0.277108</td>\n",
              "      <td>0.429957</td>\n",
              "      <td>0.265169</td>\n",
              "      <td>0.506639</td>\n",
              "      <td>0.511111</td>\n",
              "      <td>0.117593</td>\n",
              "      <td>0.921179</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>...</td>\n",
              "      <td>0.360056</td>\n",
              "      <td>0.327160</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.825397</td>\n",
              "      <td>0.078832</td>\n",
              "      <td>0.034956</td>\n",
              "      <td>0.336</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.618615</td>\n",
              "      <td>0.478956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.142608</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.135542</td>\n",
              "      <td>0.023707</td>\n",
              "      <td>0.032210</td>\n",
              "      <td>0.854954</td>\n",
              "      <td>0.755556</td>\n",
              "      <td>0.235187</td>\n",
              "      <td>0.988348</td>\n",
              "      <td>0.733836</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023910</td>\n",
              "      <td>0.123457</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.521570</td>\n",
              "      <td>0.409644</td>\n",
              "      <td>0.595</td>\n",
              "      <td>0.931617</td>\n",
              "      <td>0.833712</td>\n",
              "      <td>0.436697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>0.153085</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.340361</td>\n",
              "      <td>0.151940</td>\n",
              "      <td>0.134831</td>\n",
              "      <td>0.441267</td>\n",
              "      <td>0.985185</td>\n",
              "      <td>0.767548</td>\n",
              "      <td>0.188485</td>\n",
              "      <td>0.962284</td>\n",
              "      <td>...</td>\n",
              "      <td>0.184951</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.017137</td>\n",
              "      <td>0.008583</td>\n",
              "      <td>0.379</td>\n",
              "      <td>0.968341</td>\n",
              "      <td>0.935401</td>\n",
              "      <td>0.413225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>0.061700</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.228916</td>\n",
              "      <td>0.084052</td>\n",
              "      <td>0.113858</td>\n",
              "      <td>0.258427</td>\n",
              "      <td>0.970370</td>\n",
              "      <td>0.889699</td>\n",
              "      <td>0.110350</td>\n",
              "      <td>0.992457</td>\n",
              "      <td>...</td>\n",
              "      <td>0.146976</td>\n",
              "      <td>0.145062</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.022338</td>\n",
              "      <td>0.011548</td>\n",
              "      <td>0.392</td>\n",
              "      <td>0.948501</td>\n",
              "      <td>0.692293</td>\n",
              "      <td>0.390596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>0.126892</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.319277</td>\n",
              "      <td>0.150862</td>\n",
              "      <td>0.101124</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.985185</td>\n",
              "      <td>0.958979</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.111814</td>\n",
              "      <td>0.197531</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.008273</td>\n",
              "      <td>0.002497</td>\n",
              "      <td>0.235</td>\n",
              "      <td>0.965386</td>\n",
              "      <td>0.884479</td>\n",
              "      <td>0.392526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>0.009895</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.262048</td>\n",
              "      <td>0.139009</td>\n",
              "      <td>0.098876</td>\n",
              "      <td>0.179775</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.932543</td>\n",
              "      <td>0.095956</td>\n",
              "      <td>0.988147</td>\n",
              "      <td>...</td>\n",
              "      <td>0.139944</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.008273</td>\n",
              "      <td>0.003589</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0.952723</td>\n",
              "      <td>0.802324</td>\n",
              "      <td>0.386895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>0.008731</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.246988</td>\n",
              "      <td>0.201509</td>\n",
              "      <td>0.056929</td>\n",
              "      <td>0.297242</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.006854</td>\n",
              "      <td>0.968750</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045710</td>\n",
              "      <td>0.012346</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.006973</td>\n",
              "      <td>0.002029</td>\n",
              "      <td>0.222</td>\n",
              "      <td>0.951878</td>\n",
              "      <td>0.978874</td>\n",
              "      <td>0.380861</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>197 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-372d245d-6cce-4bac-b39b-67c41e86fb31')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-372d245d-6cce-4bac-b39b-67c41e86fb31 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-372d245d-6cce-4bac-b39b-67c41e86fb31');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-87b58571-85d0-45ff-9a6b-3cea0c229c57\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-87b58571-85d0-45ff-9a6b-3cea0c229c57')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-87b58571-85d0-45ff-9a6b-3cea0c229c57 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d783266d-4250-46cf-9317-88fa89fd66a4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d783266d-4250-46cf-9317-88fa89fd66a4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)\n",
        "df.to_excel(\"socioecon_AUTOENCODER_best_auto_config1_res_onedim_minmax_1214.xlsx\", index=False)\n",
        "\n",
        "print(\"File 'socioecon_AUTOENCODER.xlsx' has been saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4a1d0fc-2b29-4b71-bab1-d7af712c0eb8",
        "id": "R26G1pnciUag"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'socioecon_AUTOENCODER.xlsx' has been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Bottleneckoutptu2\n",
        "# Assuming X and bottleneck_output are defined\n",
        "mi_scores = []\n",
        "for i in range(bottleneck_output_2.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_2[:, i], random_state=42)\n",
        "    mi_scores.append(mi)\n"
      ],
      "metadata": {
        "id": "11m_baFriUag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a37a9845-4641-4e7f-f578-88b7b9dd59ca",
        "id": "St9ZjjEFiUah"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.30704494, 0.24233307, 0.15630951, 0.39416776, 0.17011601,\n",
              "        0.29315746, 0.44271335, 0.83639234, 1.49782745, 0.4992256 ,\n",
              "        0.88166262, 0.67910652, 0.30196234, 0.3594874 , 0.51056676,\n",
              "        0.50107978, 0.34023062, 0.10819891, 0.22398809, 0.78150078,\n",
              "        0.67750546, 0.18444399, 0.0884831 , 0.12193709])]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f76fe31-39dc-4bad-daa7-d235bf1c03b6",
        "id": "aZNu9VlyiUai"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_1.shape[1]))\n",
        "\n",
        "for dim in range(bottleneck_output_1.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim]"
      ],
      "metadata": {
        "id": "BRt1LyTxiUai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))"
      ],
      "metadata": {
        "id": "zOzIfumbiUaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "dtv1jBAniUak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "70f6c035-f857-41f1-be14-9dfebca830de",
        "id": "tpD8QOCKiUak"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
              "0     0.131654     0.8750   0.120482   0.154095   0.182022   0.674157   \n",
              "1     0.071436     0.8125   0.150602   0.238147   0.211985   0.449438   \n",
              "2     0.000000     0.8125   0.307229   0.635776   0.513109   0.305414   \n",
              "3     0.506297     0.6250   0.277108   0.429957   0.265169   0.506639   \n",
              "4     0.142608     0.8125   0.135542   0.023707   0.032210   0.854954   \n",
              "..         ...        ...        ...        ...        ...        ...   \n",
              "192   0.153085     0.8750   0.340361   0.151940   0.134831   0.441267   \n",
              "193   0.061700     0.8750   0.228916   0.084052   0.113858   0.258427   \n",
              "194   0.126892     1.0000   0.319277   0.150862   0.101124   0.370787   \n",
              "195   0.009895     0.7500   0.262048   0.139009   0.098876   0.179775   \n",
              "196   0.008731     0.8125   0.246988   0.201509   0.056929   0.297242   \n",
              "\n",
              "     Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_16  Feature_17  \\\n",
              "0     0.192593   0.291705   0.877313    0.821121  ...    0.090142    0.274691   \n",
              "1     0.370370   0.222425   0.915696    0.813578  ...    0.800026    0.175926   \n",
              "2     0.918519   0.887876   0.781357    0.000000  ...    0.867792    0.320988   \n",
              "3     0.511111   0.117593   0.921179    0.843750  ...    0.360056    0.327160   \n",
              "4     0.755556   0.235187   0.988348    0.733836  ...    0.023910    0.123457   \n",
              "..         ...        ...        ...         ...  ...         ...         ...   \n",
              "192   0.985185   0.767548   0.188485    0.962284  ...    0.184951    0.222222   \n",
              "193   0.970370   0.889699   0.110350    0.992457  ...    0.146976    0.145062   \n",
              "194   0.985185   0.958979   0.000000    1.000000  ...    0.111814    0.197531   \n",
              "195   1.000000   0.932543   0.095956    0.988147  ...    0.139944    0.055556   \n",
              "196   1.000000   1.000000   0.006854    0.968750  ...    0.045710    0.012346   \n",
              "\n",
              "     Feature_18  Feature_19  Feature_20  Feature_21  Feature_22  Feature_23  \\\n",
              "0      1.000000    0.873016    0.097033    0.108458       0.846    0.409878   \n",
              "1      0.761905    0.698413    0.160974    0.132647       0.624    0.693119   \n",
              "2      1.000000    0.714286    0.091006    0.068664       0.571    0.944280   \n",
              "3      1.000000    0.825397    0.078832    0.034956       0.336    0.782609   \n",
              "4      0.333333    0.555556    0.521570    0.409644       0.595    0.931617   \n",
              "..          ...         ...         ...         ...         ...         ...   \n",
              "192    1.000000    1.000000    0.017137    0.008583       0.379    0.968341   \n",
              "193    1.000000    1.000000    0.022338    0.011548       0.392    0.948501   \n",
              "194    1.000000    1.000000    0.008273    0.002497       0.235    0.965386   \n",
              "195    1.000000    1.000000    0.008273    0.003589       0.333    0.952723   \n",
              "196    1.000000    1.000000    0.006973    0.002029       0.222    0.951878   \n",
              "\n",
              "     Feature_24  Final_Index  \n",
              "0      0.706241     0.425867  \n",
              "1      0.472230     0.470448  \n",
              "2      0.863955     0.514145  \n",
              "3      0.618615     0.481875  \n",
              "4      0.833712     0.465191  \n",
              "..          ...          ...  \n",
              "192    0.935401     0.419950  \n",
              "193    0.692293     0.399011  \n",
              "194    0.884479     0.397563  \n",
              "195    0.802324     0.393167  \n",
              "196    0.978874     0.386389  \n",
              "\n",
              "[197 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f079f40-9bc4-48d0-a62f-7dd31bb70d15\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature_1</th>\n",
              "      <th>Feature_2</th>\n",
              "      <th>Feature_3</th>\n",
              "      <th>Feature_4</th>\n",
              "      <th>Feature_5</th>\n",
              "      <th>Feature_6</th>\n",
              "      <th>Feature_7</th>\n",
              "      <th>Feature_8</th>\n",
              "      <th>Feature_9</th>\n",
              "      <th>Feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>Feature_16</th>\n",
              "      <th>Feature_17</th>\n",
              "      <th>Feature_18</th>\n",
              "      <th>Feature_19</th>\n",
              "      <th>Feature_20</th>\n",
              "      <th>Feature_21</th>\n",
              "      <th>Feature_22</th>\n",
              "      <th>Feature_23</th>\n",
              "      <th>Feature_24</th>\n",
              "      <th>Final_Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.131654</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.120482</td>\n",
              "      <td>0.154095</td>\n",
              "      <td>0.182022</td>\n",
              "      <td>0.674157</td>\n",
              "      <td>0.192593</td>\n",
              "      <td>0.291705</td>\n",
              "      <td>0.877313</td>\n",
              "      <td>0.821121</td>\n",
              "      <td>...</td>\n",
              "      <td>0.090142</td>\n",
              "      <td>0.274691</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.873016</td>\n",
              "      <td>0.097033</td>\n",
              "      <td>0.108458</td>\n",
              "      <td>0.846</td>\n",
              "      <td>0.409878</td>\n",
              "      <td>0.706241</td>\n",
              "      <td>0.425867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.071436</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.150602</td>\n",
              "      <td>0.238147</td>\n",
              "      <td>0.211985</td>\n",
              "      <td>0.449438</td>\n",
              "      <td>0.370370</td>\n",
              "      <td>0.222425</td>\n",
              "      <td>0.915696</td>\n",
              "      <td>0.813578</td>\n",
              "      <td>...</td>\n",
              "      <td>0.800026</td>\n",
              "      <td>0.175926</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.698413</td>\n",
              "      <td>0.160974</td>\n",
              "      <td>0.132647</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.693119</td>\n",
              "      <td>0.472230</td>\n",
              "      <td>0.470448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.307229</td>\n",
              "      <td>0.635776</td>\n",
              "      <td>0.513109</td>\n",
              "      <td>0.305414</td>\n",
              "      <td>0.918519</td>\n",
              "      <td>0.887876</td>\n",
              "      <td>0.781357</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.867792</td>\n",
              "      <td>0.320988</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.091006</td>\n",
              "      <td>0.068664</td>\n",
              "      <td>0.571</td>\n",
              "      <td>0.944280</td>\n",
              "      <td>0.863955</td>\n",
              "      <td>0.514145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.506297</td>\n",
              "      <td>0.6250</td>\n",
              "      <td>0.277108</td>\n",
              "      <td>0.429957</td>\n",
              "      <td>0.265169</td>\n",
              "      <td>0.506639</td>\n",
              "      <td>0.511111</td>\n",
              "      <td>0.117593</td>\n",
              "      <td>0.921179</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>...</td>\n",
              "      <td>0.360056</td>\n",
              "      <td>0.327160</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.825397</td>\n",
              "      <td>0.078832</td>\n",
              "      <td>0.034956</td>\n",
              "      <td>0.336</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.618615</td>\n",
              "      <td>0.481875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.142608</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.135542</td>\n",
              "      <td>0.023707</td>\n",
              "      <td>0.032210</td>\n",
              "      <td>0.854954</td>\n",
              "      <td>0.755556</td>\n",
              "      <td>0.235187</td>\n",
              "      <td>0.988348</td>\n",
              "      <td>0.733836</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023910</td>\n",
              "      <td>0.123457</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.521570</td>\n",
              "      <td>0.409644</td>\n",
              "      <td>0.595</td>\n",
              "      <td>0.931617</td>\n",
              "      <td>0.833712</td>\n",
              "      <td>0.465191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>0.153085</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.340361</td>\n",
              "      <td>0.151940</td>\n",
              "      <td>0.134831</td>\n",
              "      <td>0.441267</td>\n",
              "      <td>0.985185</td>\n",
              "      <td>0.767548</td>\n",
              "      <td>0.188485</td>\n",
              "      <td>0.962284</td>\n",
              "      <td>...</td>\n",
              "      <td>0.184951</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.017137</td>\n",
              "      <td>0.008583</td>\n",
              "      <td>0.379</td>\n",
              "      <td>0.968341</td>\n",
              "      <td>0.935401</td>\n",
              "      <td>0.419950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>0.061700</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.228916</td>\n",
              "      <td>0.084052</td>\n",
              "      <td>0.113858</td>\n",
              "      <td>0.258427</td>\n",
              "      <td>0.970370</td>\n",
              "      <td>0.889699</td>\n",
              "      <td>0.110350</td>\n",
              "      <td>0.992457</td>\n",
              "      <td>...</td>\n",
              "      <td>0.146976</td>\n",
              "      <td>0.145062</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.022338</td>\n",
              "      <td>0.011548</td>\n",
              "      <td>0.392</td>\n",
              "      <td>0.948501</td>\n",
              "      <td>0.692293</td>\n",
              "      <td>0.399011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>0.126892</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.319277</td>\n",
              "      <td>0.150862</td>\n",
              "      <td>0.101124</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.985185</td>\n",
              "      <td>0.958979</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.111814</td>\n",
              "      <td>0.197531</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.008273</td>\n",
              "      <td>0.002497</td>\n",
              "      <td>0.235</td>\n",
              "      <td>0.965386</td>\n",
              "      <td>0.884479</td>\n",
              "      <td>0.397563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>0.009895</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.262048</td>\n",
              "      <td>0.139009</td>\n",
              "      <td>0.098876</td>\n",
              "      <td>0.179775</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.932543</td>\n",
              "      <td>0.095956</td>\n",
              "      <td>0.988147</td>\n",
              "      <td>...</td>\n",
              "      <td>0.139944</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.008273</td>\n",
              "      <td>0.003589</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0.952723</td>\n",
              "      <td>0.802324</td>\n",
              "      <td>0.393167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>0.008731</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.246988</td>\n",
              "      <td>0.201509</td>\n",
              "      <td>0.056929</td>\n",
              "      <td>0.297242</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.006854</td>\n",
              "      <td>0.968750</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045710</td>\n",
              "      <td>0.012346</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.006973</td>\n",
              "      <td>0.002029</td>\n",
              "      <td>0.222</td>\n",
              "      <td>0.951878</td>\n",
              "      <td>0.978874</td>\n",
              "      <td>0.386389</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>197 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f079f40-9bc4-48d0-a62f-7dd31bb70d15')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7f079f40-9bc4-48d0-a62f-7dd31bb70d15 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7f079f40-9bc4-48d0-a62f-7dd31bb70d15');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fef95495-a8d0-4f80-8598-42c5c080b501\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fef95495-a8d0-4f80-8598-42c5c080b501')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fef95495-a8d0-4f80-8598-42c5c080b501 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f5280152-1353-42b1-8979-f9b871e1d16f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f5280152-1353-42b1-8979-f9b871e1d16f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)\n",
        "df.to_excel(\"socioecon_AUTOENCODER_best_auto_config2_res_onedim_minmax_1214.xlsx\", index=False)\n",
        "\n",
        "print(\"File 'socioecon_AUTOENCODER.xlsx' has been saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c927aac-689d-4034-db9d-f5c8c1a6ccc5",
        "id": "U4bilZ-wiUal"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'socioecon_AUTOENCODER.xlsx' has been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mod / only one encoding dimension (method 2)"
      ],
      "metadata": {
        "id": "QIGEVe7r4EVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mutual_info_score\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from itertools import product\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from kerastuner import HyperModel, RandomSearch"
      ],
      "metadata": {
        "id": "Zq5Pcytx4EVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('SE_Original_(NOT SHARED) FOR USE_2020_mod.xlsx')\n",
        "X_ori = data.iloc[:, 3:27].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X_ori)\n",
        "\n",
        "# Split\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Kdj5gFnW4EVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def create_autoencoder(input_dim, encoding_dim, hidden_layers_before, hidden_layers_after, neurons_before, neurons_after):\n",
        "    # Define the input layer\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "\n",
        "    # Build the encoder part\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons_before, activation='relu', name=f'dense_encoder_{i+1}')(x)\n",
        "\n",
        "    # Bottleneck layer (encoding layer)\n",
        "    bottleneck = Dense(encoding_dim, activation='relu', name='bottleneck')(x)\n",
        "\n",
        "    # Build the decoder part\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons_after, activation='relu', name=f'dense_decoder_{i+1}')(x)\n",
        "\n",
        "    # Output layer, with the same dimension as the input\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Define the complete autoencoder model\n",
        "    autoencoder = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "P6eikyoG4EVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial tuning\n",
        "hidden_layers_options = [2, 4, 6, 8]  # Even numbers to ensure symmetry\n",
        "neurons_options = [6, 8, 10, 12, 14, 16]\n",
        "encoding_dims_options = [1]\n",
        "results = []\n",
        "\n",
        "# Iterate through each combination of hyperparameters\n",
        "for hidden_layers in hidden_layers_options:\n",
        "    hidden_layers_before = hidden_layers // 2\n",
        "    hidden_layers_after = hidden_layers // 2\n",
        "\n",
        "    for neurons in neurons_options:\n",
        "        for encoding_dim in encoding_dims_options:\n",
        "            autoencoder = create_autoencoder(\n",
        "                input_dim=X_train.shape[1],\n",
        "                encoding_dim=encoding_dim,\n",
        "                hidden_layers_before=hidden_layers_before,\n",
        "                hidden_layers_after=hidden_layers_after,\n",
        "                neurons_before=neurons,\n",
        "                neurons_after=neurons\n",
        "            )\n",
        "            autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "            history = autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, verbose=0, validation_data=(X_test, X_test))\n",
        "\n",
        "            # Calculate average loss on the test set\n",
        "            test_loss = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
        "            results.append((hidden_layers, encoding_dim, neurons, test_loss))\n",
        "\n",
        "# Sort results by the lowest test loss and select the best two configurations\n",
        "sorted_results = sorted(results, key=lambda x: x[3])\n",
        "best_configs = sorted_results[:2]\n",
        "\n",
        "# Print best configurations for reference and show model summary\n",
        "print(\"Top two configurations:\")\n",
        "for config in best_configs:\n",
        "    hidden_layers, encoding_dim, neurons, test_loss = config\n",
        "    print(f\"Hidden layers: {hidden_layers}, Encoding dimension: {encoding_dim}, Neurons: {neurons}, Test loss: {test_loss}\")\n",
        "\n",
        "    # Recreate and display the model summary for the best configurations\n",
        "    autoencoder = create_autoencoder(\n",
        "        input_dim=X_train.shape[1],\n",
        "        encoding_dim=encoding_dim,\n",
        "        hidden_layers_before=hidden_layers // 2,\n",
        "        hidden_layers_after=hidden_layers // 2,\n",
        "        neurons_before=neurons,\n",
        "        neurons_after=neurons\n",
        "    )\n",
        "    autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e6d11824-d38c-4e30-ac67-a171c86c0e19",
        "id": "3OxxpYqq4EVh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top two configurations:\n",
            "Hidden layers: 6, Encoding dimension: 1, Neurons: 16, Test loss: 0.31799641251564026\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m32\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m408\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,945\u001b[0m (7.60 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,945</span> (7.60 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,945\u001b[0m (7.60 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,945</span> (7.60 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden layers: 8, Encoding dimension: 1, Neurons: 16, Test loss: 0.33045417070388794\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m32\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m408\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,489\u001b[0m (9.72 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,489</span> (9.72 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,489\u001b[0m (9.72 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,489</span> (9.72 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner import Hyperband\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def build_model(hp, input_dim, hidden_layers_before, hidden_layers_after):\n",
        "    # Hyperparameters to tune\n",
        "    encoding_dim = hp.Choice('encoding_dim', [1]) # 1D encoding dimension\n",
        "    neurons = hp.Int('neurons', min_value=6, max_value=24, step=3)\n",
        "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "    batch_size = hp.Choice('batch_size', [16, 32, 64])\n",
        "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "    # Build the model structure\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_encoder_{i+1}')(x)\n",
        "    bottleneck = Dense(encoding_dim, activation=activation, name='bottleneck')(x)\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_decoder_{i+1}')(x)\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Compile model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
        "    return model"
      ],
      "metadata": {
        "id": "JDE1e-Mb4EVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import Hyperband\n",
        "\n",
        "tuner_config_1 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=3, hidden_layers_after=3),\n",
        "    objective='val_loss', max_epochs=50, factor=3, directory='hyperparam_tuning_1__only1____mod', project_name='model_config_1'\n",
        ")\n",
        "\n",
        "tuner_config_2 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=4, hidden_layers_after=4),\n",
        "    objective='val_loss', max_epochs=50, factor=3, directory='hyperparam_tuning_2__only1____mod', project_name='model_config_2'\n",
        ")"
      ],
      "metadata": {
        "id": "A4OjP3OO4EVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning for configuration 1\n",
        "tuner_config_1.search(X_train, X_train, epochs=50, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get the best model for configuration 1\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfa7325c-8d1e-40f7-aa8a-6e107a1d0bec",
        "id": "mz5JiKnI4EVi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 10s]\n",
            "val_loss: 1.1033384799957275\n",
            "\n",
            "Best val_loss So Far: 0.21279674768447876\n",
            "Total elapsed time: 00h 09m 50s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning for configuration 2\n",
        "tuner_config_2.search(X_train, X_train, epochs=50, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get the best model for configuration 2\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "outputId": "35907877-a8fc-400d-997b-973bb2338516",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO7HYt-C4EVi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 14s]\n",
            "val_loss: 0.5080286860466003\n",
            "\n",
            "Best val_loss So Far: 0.20329490303993225\n",
            "Total elapsed time: 00h 13m 23s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JwXvmNxwAAN"
      },
      "source": [
        "#### check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pirlsUe-wAAb"
      },
      "outputs": [],
      "source": [
        "# Get the best model\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f352038-27ed-49ac-a970-23fb05c7d026",
        "id": "G-FEviTbwAAc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 1, 'neurons': 21, 'learning_rate': 0.01, 'batch_size': 64, 'activation': 'relu', 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0046'}\n",
            "\n",
            "Test Loss: 0.21279674768447876\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_1.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_1.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OryJJH7CwAAe"
      },
      "outputs": [],
      "source": [
        "# Get the best model\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b0082df-1131-4713-96c9-7405fe4b58a3",
        "id": "j2eaaLtdwAAe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 1, 'neurons': 12, 'learning_rate': 0.01, 'batch_size': 32, 'activation': 'tanh', 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0069'}\n",
            "\n",
            "Test Loss: 0.20329490303993225\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_2.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_2.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the structure of the best model for configuration 1\n",
        "print(\"Best Model Structure for Configuration 1:\")\n",
        "best_model_config_1.summary()\n",
        "\n",
        "# Display the structure of the best model for configuration 2\n",
        "print(\"\\nBest Model Structure for Configuration 2:\")\n",
        "best_model_config_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "outputId": "bfb5b710-97e7-471f-f763-8167cd1e4b61",
        "id": "MhLNPDMd4EVi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model Structure for Configuration 1:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m525\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m22\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │              \u001b[38;5;34m42\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">525</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,965\u001b[0m (11.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,965</span> (11.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,965\u001b[0m (11.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,965</span> (11.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Model Structure for Configuration 2:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m13\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │              \u001b[38;5;34m24\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m156\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m312\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,585\u001b[0m (6.19 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,585</span> (6.19 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,585\u001b[0m (6.19 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,585</span> (6.19 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### past"
      ],
      "metadata": {
        "id": "FTd8ESKhfSeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print details of each layer for the best model in configuration 1\n",
        "print(\"Best Model for Configuration 1:\")\n",
        "for layer in best_model_config_1.layers:\n",
        "    if hasattr(layer, 'output_shape'):\n",
        "        output_shape = layer.output_shape\n",
        "    else:\n",
        "        output_shape = layer.get_output_shape_at(0) if hasattr(layer, 'get_output_shape_at') else 'N/A'\n",
        "    print(f\"Layer: {layer.name}, Type: {layer.__class__.__name__}, Output Shape: {output_shape}, Parameters: {layer.count_params()}\")\n",
        "\n",
        "# Print details of each layer for the best model in configuration 2\n",
        "print(\"\\nBest Model for Configuration 2:\")\n",
        "for layer in best_model_config_2.layers:\n",
        "    if hasattr(layer, 'output_shape'):\n",
        "        output_shape = layer.output_shape\n",
        "    else:\n",
        "        output_shape = layer.get_output_shape_at(0) if hasattr(layer, 'get_output_shape_at') else 'N/A'\n",
        "    print(f\"Layer: {layer.name}, Type: {layer.__class__.__name__}, Output Shape: {output_shape}, Parameters: {layer.count_params()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc96aa7-ac67-41a0-b970-6a64f22b5d0c",
        "id": "u0CwSoNb4EVi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model for Configuration 1:\n",
            "Layer: input_layer, Type: InputLayer, Output Shape: N/A, Parameters: 0\n",
            "Layer: dense_encoder_1, Type: Dense, Output Shape: N/A, Parameters: 525\n",
            "Layer: dense_encoder_2, Type: Dense, Output Shape: N/A, Parameters: 462\n",
            "Layer: dense_encoder_3, Type: Dense, Output Shape: N/A, Parameters: 462\n",
            "Layer: bottleneck, Type: Dense, Output Shape: N/A, Parameters: 22\n",
            "Layer: dense_decoder_1, Type: Dense, Output Shape: N/A, Parameters: 42\n",
            "Layer: dense_decoder_2, Type: Dense, Output Shape: N/A, Parameters: 462\n",
            "Layer: dense_decoder_3, Type: Dense, Output Shape: N/A, Parameters: 462\n",
            "Layer: output_layer, Type: Dense, Output Shape: N/A, Parameters: 528\n",
            "\n",
            "Best Model for Configuration 2:\n",
            "Layer: input_layer, Type: InputLayer, Output Shape: N/A, Parameters: 0\n",
            "Layer: dense_encoder_1, Type: Dense, Output Shape: N/A, Parameters: 300\n",
            "Layer: dense_encoder_2, Type: Dense, Output Shape: N/A, Parameters: 156\n",
            "Layer: dense_encoder_3, Type: Dense, Output Shape: N/A, Parameters: 156\n",
            "Layer: dense_encoder_4, Type: Dense, Output Shape: N/A, Parameters: 156\n",
            "Layer: bottleneck, Type: Dense, Output Shape: N/A, Parameters: 13\n",
            "Layer: dense_decoder_1, Type: Dense, Output Shape: N/A, Parameters: 24\n",
            "Layer: dense_decoder_2, Type: Dense, Output Shape: N/A, Parameters: 156\n",
            "Layer: dense_decoder_3, Type: Dense, Output Shape: N/A, Parameters: 156\n",
            "Layer: dense_decoder_4, Type: Dense, Output Shape: N/A, Parameters: 156\n",
            "Layer: output_layer, Type: Dense, Output Shape: N/A, Parameters: 312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_1 = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder_model_config_1 = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer_config_1)\n",
        "bottleneck_output_1 = encoder_model_config_1.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a89116-02d7-446b-9c6a-d1d62232c846",
        "id": "dIay1Q8h4EVj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ec2aab1d3f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_2 = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder_model_config_2 = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer_config_2)\n",
        "bottleneck_output_2 = encoder_model_config_2.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "450edd37-054a-496b-8430-5e81e6b53102",
        "id": "UlOzdXov4EVj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_output_1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcedaf66-0003-49f7-be81-0f943eb759bf",
        "id": "KXR5lbm84EVj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(262, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_output_2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a2bcc6d-7790-46dd-9a03-3b0540837bed",
        "id": "d9KeU_qp4EVj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(262, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_regression\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "hFtofsga4EVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = []\n",
        "for i in range(bottleneck_output_1.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_1[:, i], random_state=42)\n",
        "    mi_scores.append(mi)\n"
      ],
      "metadata": {
        "id": "6qT4m4664EVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "705b6b52-0f73-4cbe-b980-a3b1891ead94",
        "id": "R6SL08lf4EVj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.84952326, 0.73110931, 0.72687123, 1.14945   , 0.73138349,\n",
              "        0.79717025, 0.71058062, 0.88761242, 1.13779121, 0.86185777,\n",
              "        0.99076894, 0.41458153, 0.70845884, 0.78328307, 1.164205  ,\n",
              "        1.12770526, 0.87781595, 0.60395874, 0.63380565, 0.89272986,\n",
              "        0.73549511, 0.54699236, 0.60108138, 0.6055076 ])]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7874d30-d6e3-4bf6-9262-85cd90bbfb9b",
        "id": "fVrIgPrd4EVj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_1.shape[1]))\n",
        "\n",
        "for dim in range(bottleneck_output_1.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim]"
      ],
      "metadata": {
        "id": "aPo7G-eq4EVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))"
      ],
      "metadata": {
        "id": "3jOXDNVo4EVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "ZzjCbyZP4EVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "1ec52f16-a156-4ad7-b0ce-e5ac918ef4c5",
        "id": "ps6OKw4K4EVk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
              "0    -0.698641   0.607407  -0.385408  -0.466819  -0.188799   1.028644   \n",
              "1    -0.838198   0.448266  -0.233494  -0.105609  -0.059436   0.330437   \n",
              "2    -1.003754   0.448266   0.556455   1.603193   1.240668  -0.117050   \n",
              "3     0.169605  -0.029156   0.404542   0.718691   0.170185   0.508162   \n",
              "4    -0.673256   0.448266  -0.309451  -1.027158  -0.835617   1.590383   \n",
              "..         ...        ...        ...        ...        ...        ...   \n",
              "257  -1.362580  -1.620562  -1.357653  -1.129038  -1.055535  -1.408733   \n",
              "258  -1.362580  -1.620562  -1.357653  -1.129038  -1.055535  -1.408733   \n",
              "259  -1.362580  -1.620562  -1.357653  -1.129038  -1.055535  -1.408733   \n",
              "260  -1.362580  -1.620562  -1.357653  -1.129038  -1.055535  -1.408733   \n",
              "261  -1.362580  -1.620562  -1.357653  -1.129038  -1.055535  -1.408733   \n",
              "\n",
              "     Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_16  Feature_17  \\\n",
              "0    -1.095383  -0.021052   1.110346    0.534798  ...   -0.612939    0.339178   \n",
              "1    -0.646493  -0.269981   1.217350    0.515143  ...    2.607521   -0.059374   \n",
              "2     0.737585   2.121046   0.842837   -1.604736  ...    2.914949    0.526000   \n",
              "3    -0.291122  -0.646650   1.232636    0.593761  ...    0.611555    0.550909   \n",
              "4     0.326102  -0.224126   1.419893    0.307367  ...   -0.913407   -0.271105   \n",
              "..         ...        ...        ...         ...  ...         ...         ...   \n",
              "257  -1.581681  -1.069174  -1.335454   -1.604736  ...   -1.021877   -1.354669   \n",
              "258  -1.581681  -1.069174  -1.335454   -1.604736  ...   -1.021877   -1.354669   \n",
              "259  -1.581681  -1.069174  -1.335454   -1.604736  ...   -1.021877   -1.354669   \n",
              "260  -1.581681  -1.069174  -1.335454   -1.604736  ...   -1.021877   -1.354669   \n",
              "261  -1.581681  -1.069174  -1.335454   -1.604736  ...   -1.021877   -1.354669   \n",
              "\n",
              "     Feature_18  Feature_19  Feature_20  Feature_21  Feature_22  Feature_23  \\\n",
              "0      0.679367    0.541898   -0.183930    0.093623    1.730565   -0.678899   \n",
              "1      0.126247    0.117625    0.133974    0.229106    1.002373    0.014575   \n",
              "2      0.679367    0.156195   -0.213899   -0.129267    0.828525    0.629504   \n",
              "3      0.679367    0.426187   -0.274424   -0.318069    0.057691    0.233676   \n",
              "4     -0.869370   -0.229508    1.926811    1.780599    0.907248    0.598499   \n",
              "..          ...         ...         ...         ...         ...         ...   \n",
              "257   -1.643739   -1.579469   -0.666369   -0.513863   -1.044439   -1.682421   \n",
              "258   -1.643739   -1.579469   -0.666369   -0.513863   -1.044439   -1.682421   \n",
              "259   -1.643739   -1.579469   -0.666369   -0.513863   -1.044439   -1.682421   \n",
              "260   -1.643739   -1.579469   -0.666369   -0.513863   -1.044439   -1.682421   \n",
              "261   -1.643739   -1.579469   -0.666369   -0.513863   -1.044439   -1.682421   \n",
              "\n",
              "     Feature_24  Final_Index  \n",
              "0      0.405460     0.110698  \n",
              "1     -0.245333     0.320261  \n",
              "2      0.844069     0.706837  \n",
              "3      0.161770     0.389243  \n",
              "4      0.759962     0.126579  \n",
              "..          ...          ...  \n",
              "257   -1.558624    -1.250455  \n",
              "258   -1.558624    -1.250455  \n",
              "259   -1.558624    -1.250455  \n",
              "260   -1.558624    -1.250455  \n",
              "261   -1.558624    -1.250455  \n",
              "\n",
              "[262 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc70918c-7482-4f54-9258-6651a55a70b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature_1</th>\n",
              "      <th>Feature_2</th>\n",
              "      <th>Feature_3</th>\n",
              "      <th>Feature_4</th>\n",
              "      <th>Feature_5</th>\n",
              "      <th>Feature_6</th>\n",
              "      <th>Feature_7</th>\n",
              "      <th>Feature_8</th>\n",
              "      <th>Feature_9</th>\n",
              "      <th>Feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>Feature_16</th>\n",
              "      <th>Feature_17</th>\n",
              "      <th>Feature_18</th>\n",
              "      <th>Feature_19</th>\n",
              "      <th>Feature_20</th>\n",
              "      <th>Feature_21</th>\n",
              "      <th>Feature_22</th>\n",
              "      <th>Feature_23</th>\n",
              "      <th>Feature_24</th>\n",
              "      <th>Final_Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.698641</td>\n",
              "      <td>0.607407</td>\n",
              "      <td>-0.385408</td>\n",
              "      <td>-0.466819</td>\n",
              "      <td>-0.188799</td>\n",
              "      <td>1.028644</td>\n",
              "      <td>-1.095383</td>\n",
              "      <td>-0.021052</td>\n",
              "      <td>1.110346</td>\n",
              "      <td>0.534798</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.612939</td>\n",
              "      <td>0.339178</td>\n",
              "      <td>0.679367</td>\n",
              "      <td>0.541898</td>\n",
              "      <td>-0.183930</td>\n",
              "      <td>0.093623</td>\n",
              "      <td>1.730565</td>\n",
              "      <td>-0.678899</td>\n",
              "      <td>0.405460</td>\n",
              "      <td>0.110698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.838198</td>\n",
              "      <td>0.448266</td>\n",
              "      <td>-0.233494</td>\n",
              "      <td>-0.105609</td>\n",
              "      <td>-0.059436</td>\n",
              "      <td>0.330437</td>\n",
              "      <td>-0.646493</td>\n",
              "      <td>-0.269981</td>\n",
              "      <td>1.217350</td>\n",
              "      <td>0.515143</td>\n",
              "      <td>...</td>\n",
              "      <td>2.607521</td>\n",
              "      <td>-0.059374</td>\n",
              "      <td>0.126247</td>\n",
              "      <td>0.117625</td>\n",
              "      <td>0.133974</td>\n",
              "      <td>0.229106</td>\n",
              "      <td>1.002373</td>\n",
              "      <td>0.014575</td>\n",
              "      <td>-0.245333</td>\n",
              "      <td>0.320261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.003754</td>\n",
              "      <td>0.448266</td>\n",
              "      <td>0.556455</td>\n",
              "      <td>1.603193</td>\n",
              "      <td>1.240668</td>\n",
              "      <td>-0.117050</td>\n",
              "      <td>0.737585</td>\n",
              "      <td>2.121046</td>\n",
              "      <td>0.842837</td>\n",
              "      <td>-1.604736</td>\n",
              "      <td>...</td>\n",
              "      <td>2.914949</td>\n",
              "      <td>0.526000</td>\n",
              "      <td>0.679367</td>\n",
              "      <td>0.156195</td>\n",
              "      <td>-0.213899</td>\n",
              "      <td>-0.129267</td>\n",
              "      <td>0.828525</td>\n",
              "      <td>0.629504</td>\n",
              "      <td>0.844069</td>\n",
              "      <td>0.706837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.169605</td>\n",
              "      <td>-0.029156</td>\n",
              "      <td>0.404542</td>\n",
              "      <td>0.718691</td>\n",
              "      <td>0.170185</td>\n",
              "      <td>0.508162</td>\n",
              "      <td>-0.291122</td>\n",
              "      <td>-0.646650</td>\n",
              "      <td>1.232636</td>\n",
              "      <td>0.593761</td>\n",
              "      <td>...</td>\n",
              "      <td>0.611555</td>\n",
              "      <td>0.550909</td>\n",
              "      <td>0.679367</td>\n",
              "      <td>0.426187</td>\n",
              "      <td>-0.274424</td>\n",
              "      <td>-0.318069</td>\n",
              "      <td>0.057691</td>\n",
              "      <td>0.233676</td>\n",
              "      <td>0.161770</td>\n",
              "      <td>0.389243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.673256</td>\n",
              "      <td>0.448266</td>\n",
              "      <td>-0.309451</td>\n",
              "      <td>-1.027158</td>\n",
              "      <td>-0.835617</td>\n",
              "      <td>1.590383</td>\n",
              "      <td>0.326102</td>\n",
              "      <td>-0.224126</td>\n",
              "      <td>1.419893</td>\n",
              "      <td>0.307367</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.913407</td>\n",
              "      <td>-0.271105</td>\n",
              "      <td>-0.869370</td>\n",
              "      <td>-0.229508</td>\n",
              "      <td>1.926811</td>\n",
              "      <td>1.780599</td>\n",
              "      <td>0.907248</td>\n",
              "      <td>0.598499</td>\n",
              "      <td>0.759962</td>\n",
              "      <td>0.126579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>-1.362580</td>\n",
              "      <td>-1.620562</td>\n",
              "      <td>-1.357653</td>\n",
              "      <td>-1.129038</td>\n",
              "      <td>-1.055535</td>\n",
              "      <td>-1.408733</td>\n",
              "      <td>-1.581681</td>\n",
              "      <td>-1.069174</td>\n",
              "      <td>-1.335454</td>\n",
              "      <td>-1.604736</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.021877</td>\n",
              "      <td>-1.354669</td>\n",
              "      <td>-1.643739</td>\n",
              "      <td>-1.579469</td>\n",
              "      <td>-0.666369</td>\n",
              "      <td>-0.513863</td>\n",
              "      <td>-1.044439</td>\n",
              "      <td>-1.682421</td>\n",
              "      <td>-1.558624</td>\n",
              "      <td>-1.250455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>-1.362580</td>\n",
              "      <td>-1.620562</td>\n",
              "      <td>-1.357653</td>\n",
              "      <td>-1.129038</td>\n",
              "      <td>-1.055535</td>\n",
              "      <td>-1.408733</td>\n",
              "      <td>-1.581681</td>\n",
              "      <td>-1.069174</td>\n",
              "      <td>-1.335454</td>\n",
              "      <td>-1.604736</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.021877</td>\n",
              "      <td>-1.354669</td>\n",
              "      <td>-1.643739</td>\n",
              "      <td>-1.579469</td>\n",
              "      <td>-0.666369</td>\n",
              "      <td>-0.513863</td>\n",
              "      <td>-1.044439</td>\n",
              "      <td>-1.682421</td>\n",
              "      <td>-1.558624</td>\n",
              "      <td>-1.250455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>-1.362580</td>\n",
              "      <td>-1.620562</td>\n",
              "      <td>-1.357653</td>\n",
              "      <td>-1.129038</td>\n",
              "      <td>-1.055535</td>\n",
              "      <td>-1.408733</td>\n",
              "      <td>-1.581681</td>\n",
              "      <td>-1.069174</td>\n",
              "      <td>-1.335454</td>\n",
              "      <td>-1.604736</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.021877</td>\n",
              "      <td>-1.354669</td>\n",
              "      <td>-1.643739</td>\n",
              "      <td>-1.579469</td>\n",
              "      <td>-0.666369</td>\n",
              "      <td>-0.513863</td>\n",
              "      <td>-1.044439</td>\n",
              "      <td>-1.682421</td>\n",
              "      <td>-1.558624</td>\n",
              "      <td>-1.250455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>-1.362580</td>\n",
              "      <td>-1.620562</td>\n",
              "      <td>-1.357653</td>\n",
              "      <td>-1.129038</td>\n",
              "      <td>-1.055535</td>\n",
              "      <td>-1.408733</td>\n",
              "      <td>-1.581681</td>\n",
              "      <td>-1.069174</td>\n",
              "      <td>-1.335454</td>\n",
              "      <td>-1.604736</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.021877</td>\n",
              "      <td>-1.354669</td>\n",
              "      <td>-1.643739</td>\n",
              "      <td>-1.579469</td>\n",
              "      <td>-0.666369</td>\n",
              "      <td>-0.513863</td>\n",
              "      <td>-1.044439</td>\n",
              "      <td>-1.682421</td>\n",
              "      <td>-1.558624</td>\n",
              "      <td>-1.250455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>-1.362580</td>\n",
              "      <td>-1.620562</td>\n",
              "      <td>-1.357653</td>\n",
              "      <td>-1.129038</td>\n",
              "      <td>-1.055535</td>\n",
              "      <td>-1.408733</td>\n",
              "      <td>-1.581681</td>\n",
              "      <td>-1.069174</td>\n",
              "      <td>-1.335454</td>\n",
              "      <td>-1.604736</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.021877</td>\n",
              "      <td>-1.354669</td>\n",
              "      <td>-1.643739</td>\n",
              "      <td>-1.579469</td>\n",
              "      <td>-0.666369</td>\n",
              "      <td>-0.513863</td>\n",
              "      <td>-1.044439</td>\n",
              "      <td>-1.682421</td>\n",
              "      <td>-1.558624</td>\n",
              "      <td>-1.250455</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc70918c-7482-4f54-9258-6651a55a70b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc70918c-7482-4f54-9258-6651a55a70b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc70918c-7482-4f54-9258-6651a55a70b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a2213045-5878-4a98-8703-b4a47c86de3c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a2213045-5878-4a98-8703-b4a47c86de3c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a2213045-5878-4a98-8703-b4a47c86de3c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_fb34350a-9a59-48e1-8520-1fddf006787a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fb34350a-9a59-48e1-8520-1fddf006787a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)\n",
        "df.to_excel(\"socioecon_AUTOENCODER_best_auto_config1_mod_onedim_ss_1214.xlsx\", index=False)\n",
        "\n",
        "print(\"File 'socioecon_AUTOENCODER.xlsx' has been saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39aee8bf-a4ed-49d0-ff5c-caed9f1c5237",
        "id": "ZzMHQiaX4EVk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'socioecon_AUTOENCODER.xlsx' has been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = []\n",
        "for i in range(bottleneck_output_2.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_2[:, i], random_state=42)\n",
        "    mi_scores.append(mi)\n"
      ],
      "metadata": {
        "id": "AaimIpVq4EVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a89ca6-e430-4746-f176-a7b14f964fc3",
        "id": "jQ8g7V1E4EVk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.80419601, 0.75870985, 0.70746058, 1.00504558, 0.68500398,\n",
              "        0.76005704, 0.79645461, 1.04300549, 1.34467144, 0.89908894,\n",
              "        1.03654113, 0.49677047, 0.85969651, 0.76210342, 1.02600914,\n",
              "        1.04302316, 0.85520862, 0.63570287, 0.75063914, 1.04950837,\n",
              "        0.86517841, 0.54550157, 0.71169999, 0.71938289])]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66104cd-5d1f-44ce-db53-eb3a8ada1296",
        "id": "D5BKW_eH4EVk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_1.shape[1]))\n",
        "\n",
        "for dim in range(bottleneck_output_1.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim]"
      ],
      "metadata": {
        "id": "6Dg5L6rZ4EVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))"
      ],
      "metadata": {
        "id": "qNvQIQhY4EVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "24VdR1mi4EVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "8270f383-604c-4c46-e2c9-6374ac6276d6",
        "id": "G_Hm-n_-4EVl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
              "0    -0.698641   0.607407  -0.385408  -0.466819  -0.188799   1.028644   \n",
              "1    -0.838198   0.448266  -0.233494  -0.105609  -0.059436   0.330437   \n",
              "2    -1.003754   0.448266   0.556455   1.603193   1.240668  -0.117050   \n",
              "3     0.169605  -0.029156   0.404542   0.718691   0.170185   0.508162   \n",
              "4    -0.673256   0.448266  -0.309451  -1.027158  -0.835617   1.590383   \n",
              "..         ...        ...        ...        ...        ...        ...   \n",
              "257  -1.362580  -1.620562  -1.357653  -1.129038  -1.055535  -1.408733   \n",
              "258  -1.362580  -1.620562  -1.357653  -1.129038  -1.055535  -1.408733   \n",
              "259  -1.362580  -1.620562  -1.357653  -1.129038  -1.055535  -1.408733   \n",
              "260  -1.362580  -1.620562  -1.357653  -1.129038  -1.055535  -1.408733   \n",
              "261  -1.362580  -1.620562  -1.357653  -1.129038  -1.055535  -1.408733   \n",
              "\n",
              "     Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_16  Feature_17  \\\n",
              "0    -1.095383  -0.021052   1.110346    0.534798  ...   -0.612939    0.339178   \n",
              "1    -0.646493  -0.269981   1.217350    0.515143  ...    2.607521   -0.059374   \n",
              "2     0.737585   2.121046   0.842837   -1.604736  ...    2.914949    0.526000   \n",
              "3    -0.291122  -0.646650   1.232636    0.593761  ...    0.611555    0.550909   \n",
              "4     0.326102  -0.224126   1.419893    0.307367  ...   -0.913407   -0.271105   \n",
              "..         ...        ...        ...         ...  ...         ...         ...   \n",
              "257  -1.581681  -1.069174  -1.335454   -1.604736  ...   -1.021877   -1.354669   \n",
              "258  -1.581681  -1.069174  -1.335454   -1.604736  ...   -1.021877   -1.354669   \n",
              "259  -1.581681  -1.069174  -1.335454   -1.604736  ...   -1.021877   -1.354669   \n",
              "260  -1.581681  -1.069174  -1.335454   -1.604736  ...   -1.021877   -1.354669   \n",
              "261  -1.581681  -1.069174  -1.335454   -1.604736  ...   -1.021877   -1.354669   \n",
              "\n",
              "     Feature_18  Feature_19  Feature_20  Feature_21  Feature_22  Feature_23  \\\n",
              "0      0.679367    0.541898   -0.183930    0.093623    1.730565   -0.678899   \n",
              "1      0.126247    0.117625    0.133974    0.229106    1.002373    0.014575   \n",
              "2      0.679367    0.156195   -0.213899   -0.129267    0.828525    0.629504   \n",
              "3      0.679367    0.426187   -0.274424   -0.318069    0.057691    0.233676   \n",
              "4     -0.869370   -0.229508    1.926811    1.780599    0.907248    0.598499   \n",
              "..          ...         ...         ...         ...         ...         ...   \n",
              "257   -1.643739   -1.579469   -0.666369   -0.513863   -1.044439   -1.682421   \n",
              "258   -1.643739   -1.579469   -0.666369   -0.513863   -1.044439   -1.682421   \n",
              "259   -1.643739   -1.579469   -0.666369   -0.513863   -1.044439   -1.682421   \n",
              "260   -1.643739   -1.579469   -0.666369   -0.513863   -1.044439   -1.682421   \n",
              "261   -1.643739   -1.579469   -0.666369   -0.513863   -1.044439   -1.682421   \n",
              "\n",
              "     Feature_24  Final_Index  \n",
              "0      0.405460     0.129234  \n",
              "1     -0.245333     0.319165  \n",
              "2      0.844069     0.655169  \n",
              "3      0.161770     0.372522  \n",
              "4      0.759962     0.181098  \n",
              "..          ...          ...  \n",
              "257   -1.558624    -1.245670  \n",
              "258   -1.558624    -1.245670  \n",
              "259   -1.558624    -1.245670  \n",
              "260   -1.558624    -1.245670  \n",
              "261   -1.558624    -1.245670  \n",
              "\n",
              "[262 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12597f34-7ac9-48f2-9441-28ecb0b3220e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature_1</th>\n",
              "      <th>Feature_2</th>\n",
              "      <th>Feature_3</th>\n",
              "      <th>Feature_4</th>\n",
              "      <th>Feature_5</th>\n",
              "      <th>Feature_6</th>\n",
              "      <th>Feature_7</th>\n",
              "      <th>Feature_8</th>\n",
              "      <th>Feature_9</th>\n",
              "      <th>Feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>Feature_16</th>\n",
              "      <th>Feature_17</th>\n",
              "      <th>Feature_18</th>\n",
              "      <th>Feature_19</th>\n",
              "      <th>Feature_20</th>\n",
              "      <th>Feature_21</th>\n",
              "      <th>Feature_22</th>\n",
              "      <th>Feature_23</th>\n",
              "      <th>Feature_24</th>\n",
              "      <th>Final_Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.698641</td>\n",
              "      <td>0.607407</td>\n",
              "      <td>-0.385408</td>\n",
              "      <td>-0.466819</td>\n",
              "      <td>-0.188799</td>\n",
              "      <td>1.028644</td>\n",
              "      <td>-1.095383</td>\n",
              "      <td>-0.021052</td>\n",
              "      <td>1.110346</td>\n",
              "      <td>0.534798</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.612939</td>\n",
              "      <td>0.339178</td>\n",
              "      <td>0.679367</td>\n",
              "      <td>0.541898</td>\n",
              "      <td>-0.183930</td>\n",
              "      <td>0.093623</td>\n",
              "      <td>1.730565</td>\n",
              "      <td>-0.678899</td>\n",
              "      <td>0.405460</td>\n",
              "      <td>0.129234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.838198</td>\n",
              "      <td>0.448266</td>\n",
              "      <td>-0.233494</td>\n",
              "      <td>-0.105609</td>\n",
              "      <td>-0.059436</td>\n",
              "      <td>0.330437</td>\n",
              "      <td>-0.646493</td>\n",
              "      <td>-0.269981</td>\n",
              "      <td>1.217350</td>\n",
              "      <td>0.515143</td>\n",
              "      <td>...</td>\n",
              "      <td>2.607521</td>\n",
              "      <td>-0.059374</td>\n",
              "      <td>0.126247</td>\n",
              "      <td>0.117625</td>\n",
              "      <td>0.133974</td>\n",
              "      <td>0.229106</td>\n",
              "      <td>1.002373</td>\n",
              "      <td>0.014575</td>\n",
              "      <td>-0.245333</td>\n",
              "      <td>0.319165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.003754</td>\n",
              "      <td>0.448266</td>\n",
              "      <td>0.556455</td>\n",
              "      <td>1.603193</td>\n",
              "      <td>1.240668</td>\n",
              "      <td>-0.117050</td>\n",
              "      <td>0.737585</td>\n",
              "      <td>2.121046</td>\n",
              "      <td>0.842837</td>\n",
              "      <td>-1.604736</td>\n",
              "      <td>...</td>\n",
              "      <td>2.914949</td>\n",
              "      <td>0.526000</td>\n",
              "      <td>0.679367</td>\n",
              "      <td>0.156195</td>\n",
              "      <td>-0.213899</td>\n",
              "      <td>-0.129267</td>\n",
              "      <td>0.828525</td>\n",
              "      <td>0.629504</td>\n",
              "      <td>0.844069</td>\n",
              "      <td>0.655169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.169605</td>\n",
              "      <td>-0.029156</td>\n",
              "      <td>0.404542</td>\n",
              "      <td>0.718691</td>\n",
              "      <td>0.170185</td>\n",
              "      <td>0.508162</td>\n",
              "      <td>-0.291122</td>\n",
              "      <td>-0.646650</td>\n",
              "      <td>1.232636</td>\n",
              "      <td>0.593761</td>\n",
              "      <td>...</td>\n",
              "      <td>0.611555</td>\n",
              "      <td>0.550909</td>\n",
              "      <td>0.679367</td>\n",
              "      <td>0.426187</td>\n",
              "      <td>-0.274424</td>\n",
              "      <td>-0.318069</td>\n",
              "      <td>0.057691</td>\n",
              "      <td>0.233676</td>\n",
              "      <td>0.161770</td>\n",
              "      <td>0.372522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.673256</td>\n",
              "      <td>0.448266</td>\n",
              "      <td>-0.309451</td>\n",
              "      <td>-1.027158</td>\n",
              "      <td>-0.835617</td>\n",
              "      <td>1.590383</td>\n",
              "      <td>0.326102</td>\n",
              "      <td>-0.224126</td>\n",
              "      <td>1.419893</td>\n",
              "      <td>0.307367</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.913407</td>\n",
              "      <td>-0.271105</td>\n",
              "      <td>-0.869370</td>\n",
              "      <td>-0.229508</td>\n",
              "      <td>1.926811</td>\n",
              "      <td>1.780599</td>\n",
              "      <td>0.907248</td>\n",
              "      <td>0.598499</td>\n",
              "      <td>0.759962</td>\n",
              "      <td>0.181098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>-1.362580</td>\n",
              "      <td>-1.620562</td>\n",
              "      <td>-1.357653</td>\n",
              "      <td>-1.129038</td>\n",
              "      <td>-1.055535</td>\n",
              "      <td>-1.408733</td>\n",
              "      <td>-1.581681</td>\n",
              "      <td>-1.069174</td>\n",
              "      <td>-1.335454</td>\n",
              "      <td>-1.604736</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.021877</td>\n",
              "      <td>-1.354669</td>\n",
              "      <td>-1.643739</td>\n",
              "      <td>-1.579469</td>\n",
              "      <td>-0.666369</td>\n",
              "      <td>-0.513863</td>\n",
              "      <td>-1.044439</td>\n",
              "      <td>-1.682421</td>\n",
              "      <td>-1.558624</td>\n",
              "      <td>-1.245670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>-1.362580</td>\n",
              "      <td>-1.620562</td>\n",
              "      <td>-1.357653</td>\n",
              "      <td>-1.129038</td>\n",
              "      <td>-1.055535</td>\n",
              "      <td>-1.408733</td>\n",
              "      <td>-1.581681</td>\n",
              "      <td>-1.069174</td>\n",
              "      <td>-1.335454</td>\n",
              "      <td>-1.604736</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.021877</td>\n",
              "      <td>-1.354669</td>\n",
              "      <td>-1.643739</td>\n",
              "      <td>-1.579469</td>\n",
              "      <td>-0.666369</td>\n",
              "      <td>-0.513863</td>\n",
              "      <td>-1.044439</td>\n",
              "      <td>-1.682421</td>\n",
              "      <td>-1.558624</td>\n",
              "      <td>-1.245670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>-1.362580</td>\n",
              "      <td>-1.620562</td>\n",
              "      <td>-1.357653</td>\n",
              "      <td>-1.129038</td>\n",
              "      <td>-1.055535</td>\n",
              "      <td>-1.408733</td>\n",
              "      <td>-1.581681</td>\n",
              "      <td>-1.069174</td>\n",
              "      <td>-1.335454</td>\n",
              "      <td>-1.604736</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.021877</td>\n",
              "      <td>-1.354669</td>\n",
              "      <td>-1.643739</td>\n",
              "      <td>-1.579469</td>\n",
              "      <td>-0.666369</td>\n",
              "      <td>-0.513863</td>\n",
              "      <td>-1.044439</td>\n",
              "      <td>-1.682421</td>\n",
              "      <td>-1.558624</td>\n",
              "      <td>-1.245670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>-1.362580</td>\n",
              "      <td>-1.620562</td>\n",
              "      <td>-1.357653</td>\n",
              "      <td>-1.129038</td>\n",
              "      <td>-1.055535</td>\n",
              "      <td>-1.408733</td>\n",
              "      <td>-1.581681</td>\n",
              "      <td>-1.069174</td>\n",
              "      <td>-1.335454</td>\n",
              "      <td>-1.604736</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.021877</td>\n",
              "      <td>-1.354669</td>\n",
              "      <td>-1.643739</td>\n",
              "      <td>-1.579469</td>\n",
              "      <td>-0.666369</td>\n",
              "      <td>-0.513863</td>\n",
              "      <td>-1.044439</td>\n",
              "      <td>-1.682421</td>\n",
              "      <td>-1.558624</td>\n",
              "      <td>-1.245670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>-1.362580</td>\n",
              "      <td>-1.620562</td>\n",
              "      <td>-1.357653</td>\n",
              "      <td>-1.129038</td>\n",
              "      <td>-1.055535</td>\n",
              "      <td>-1.408733</td>\n",
              "      <td>-1.581681</td>\n",
              "      <td>-1.069174</td>\n",
              "      <td>-1.335454</td>\n",
              "      <td>-1.604736</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.021877</td>\n",
              "      <td>-1.354669</td>\n",
              "      <td>-1.643739</td>\n",
              "      <td>-1.579469</td>\n",
              "      <td>-0.666369</td>\n",
              "      <td>-0.513863</td>\n",
              "      <td>-1.044439</td>\n",
              "      <td>-1.682421</td>\n",
              "      <td>-1.558624</td>\n",
              "      <td>-1.245670</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12597f34-7ac9-48f2-9441-28ecb0b3220e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-12597f34-7ac9-48f2-9441-28ecb0b3220e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-12597f34-7ac9-48f2-9441-28ecb0b3220e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-11dced47-3b52-4f56-bced-7f4a02b4484e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11dced47-3b52-4f56-bced-7f4a02b4484e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-11dced47-3b52-4f56-bced-7f4a02b4484e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a1b60cfb-31eb-4cae-b064-68805fb60903\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a1b60cfb-31eb-4cae-b064-68805fb60903 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)\n",
        "df.to_excel(\"socioecon_AUTOENCODER_best_auto_config2_mod_onedim_ss_1214.xlsx\", index=False)\n",
        "\n",
        "print(\"File 'socioecon_AUTOENCODER.xlsx' has been saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02054436-cdc1-4a53-c1cc-29023c2028f9",
        "id": "q7Qktueh4EVl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'socioecon_AUTOENCODER.xlsx' has been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mod / only one encoding dimension - minmax (method 2)"
      ],
      "metadata": {
        "id": "kcyYwO35qQ3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mutual_info_score\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from itertools import product\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from kerastuner import HyperModel, RandomSearch"
      ],
      "metadata": {
        "id": "64U1hZaoqQ3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('SE_Original_(NOT SHARED) FOR USE_2020_mod.xlsx')\n",
        "X_ori = data.iloc[:, 3:27].values\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X_ori)\n",
        "\n",
        "# Split\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "KIO1eLCTqQ3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def create_autoencoder(input_dim, encoding_dim, hidden_layers_before, hidden_layers_after, neurons_before, neurons_after):\n",
        "    # Define the input layer\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "\n",
        "    # Build the encoder part\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons_before, activation='relu', name=f'dense_encoder_{i+1}')(x)\n",
        "\n",
        "    # Bottleneck layer (encoding layer)\n",
        "    bottleneck = Dense(encoding_dim, activation='relu', name='bottleneck')(x)\n",
        "\n",
        "    # Build the decoder part\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons_after, activation='relu', name=f'dense_decoder_{i+1}')(x)\n",
        "\n",
        "    # Output layer, with the same dimension as the input\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Define the complete autoencoder model\n",
        "    autoencoder = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "K7hi5XnxqQ3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial tuning\n",
        "hidden_layers_options = [2, 4, 6, 8]  # Even numbers to ensure symmetry\n",
        "neurons_options = [6, 8, 10, 12, 14, 16]\n",
        "encoding_dims_options = [1]\n",
        "results = []\n",
        "\n",
        "\n",
        "# Iterate through each combination of hyperparameters\n",
        "for hidden_layers in hidden_layers_options:\n",
        "    hidden_layers_before = hidden_layers // 2\n",
        "    hidden_layers_after = hidden_layers // 2\n",
        "\n",
        "    for neurons in neurons_options:\n",
        "        for encoding_dim in encoding_dims_options:\n",
        "            autoencoder = create_autoencoder(\n",
        "                input_dim=X_train.shape[1],\n",
        "                encoding_dim=encoding_dim,\n",
        "                hidden_layers_before=hidden_layers_before,\n",
        "                hidden_layers_after=hidden_layers_after,\n",
        "                neurons_before=neurons,\n",
        "                neurons_after=neurons\n",
        "            )\n",
        "            autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "            history = autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, verbose=0, validation_data=(X_test, X_test))\n",
        "\n",
        "            # Calculate average loss on the test set\n",
        "            test_loss = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
        "            results.append((hidden_layers, encoding_dim, neurons, test_loss))\n",
        "\n",
        "# Sort results by the lowest test loss and select the best two configurations\n",
        "sorted_results = sorted(results, key=lambda x: x[3])\n",
        "best_configs = sorted_results[:2]\n",
        "\n",
        "# Print best configurations for reference and show model summary\n",
        "print(\"Top two configurations:\")\n",
        "for config in best_configs:\n",
        "    hidden_layers, encoding_dim, neurons, test_loss = config\n",
        "    print(f\"Hidden layers: {hidden_layers}, Encoding dimension: {encoding_dim}, Neurons: {neurons}, Test loss: {test_loss}\")\n",
        "\n",
        "    # Recreate and display the model summary for the best configurations\n",
        "    autoencoder = create_autoencoder(\n",
        "        input_dim=X_train.shape[1],\n",
        "        encoding_dim=encoding_dim,\n",
        "        hidden_layers_before=hidden_layers // 2,\n",
        "        hidden_layers_after=hidden_layers // 2,\n",
        "        neurons_before=neurons,\n",
        "        neurons_after=neurons\n",
        "    )\n",
        "    autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f80bb9b4-9a8a-4e46-ad8c-bf8acc6b4d47",
        "id": "4ZewzXwKqQ3q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top two configurations:\n",
            "Hidden layers: 6, Encoding dimension: 1, Neurons: 14, Test loss: 0.024151155725121498\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m350\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m15\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │              \u001b[38;5;34m28\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m360\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,593\u001b[0m (6.22 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,593</span> (6.22 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,593\u001b[0m (6.22 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,593</span> (6.22 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden layers: 8, Encoding dimension: 1, Neurons: 10, Test loss: 0.02516746148467064\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m250\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m110\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m110\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m110\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m11\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │              \u001b[38;5;34m20\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m110\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m110\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m110\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m264\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,205\u001b[0m (4.71 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,205</span> (4.71 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,205\u001b[0m (4.71 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,205</span> (4.71 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner import Hyperband\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def build_model(hp, input_dim, hidden_layers_before, hidden_layers_after):\n",
        "    # Hyperparameters to tune\n",
        "    encoding_dim = hp.Choice('encoding_dim', [1]) # 1D encoding dimension\n",
        "    neurons = hp.Int('neurons', min_value=6, max_value=24, step=3)\n",
        "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "    batch_size = hp.Choice('batch_size', [16, 32, 64])\n",
        "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "    # Build the model structure\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_encoder_{i+1}')(x)\n",
        "    bottleneck = Dense(encoding_dim, activation=activation, name='bottleneck')(x)\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_decoder_{i+1}')(x)\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Compile model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
        "    return model"
      ],
      "metadata": {
        "id": "tYLfCnOSqQ3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import Hyperband\n",
        "\n",
        "tuner_config_1 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=3, hidden_layers_after=3),\n",
        "    objective='val_loss', max_epochs=50, factor=3, directory='hyperparam_tuning_1_only1__modm___m_mx', project_name='model_config_1'\n",
        ")\n",
        "\n",
        "tuner_config_2 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=4, hidden_layers_after=4),\n",
        "    objective='val_loss', max_epochs=50, factor=3, directory='hyperparam_tuning_2_only1__modm___m_mx', project_name='model_config_2'\n",
        ")"
      ],
      "metadata": {
        "id": "LA8L1jWDqQ3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning for configuration 1\n",
        "tuner_config_1.search(X_train, X_train, epochs=50, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get the best model for configuration 1\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e856b5-96f8-489a-9b84-e2a770def0ad",
        "id": "Iu0OnY92qQ3t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 20s]\n",
            "val_loss: 0.11143441498279572\n",
            "\n",
            "Best val_loss So Far: 0.019558779895305634\n",
            "Total elapsed time: 00h 24m 13s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning for configuration 2\n",
        "tuner_config_2.search(X_train, X_train, epochs=50, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get the best model for configuration 2\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "outputId": "15f52c90-e690-429a-c124-cff69b7be028",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY2EA_9CqQ3t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 26s]\n",
            "val_loss: 0.2485501766204834\n",
            "\n",
            "Best val_loss So Far: 0.014420676045119762\n",
            "Total elapsed time: 00h 27m 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHuPwB_Zfij_"
      },
      "source": [
        "#### check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8SDLtM-fikE"
      },
      "outputs": [],
      "source": [
        "# Get the best model\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212f1cde-0a5d-4a15-e1d5-3bde59ac832e",
        "id": "ukW5J3-FfikE"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 1, 'neurons': 6, 'learning_rate': 0.01, 'batch_size': 16, 'activation': 'tanh', 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0074'}\n",
            "\n",
            "Test Loss: 0.019558779895305634\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_1.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_1.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nC7TBY5EfikE"
      },
      "outputs": [],
      "source": [
        "# Get the best model\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e83763-f2f2-4868-fc5d-18e8f630ac4c",
        "id": "5w1UqwCdfikF"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 1, 'neurons': 9, 'learning_rate': 0.01, 'batch_size': 32, 'activation': 'tanh', 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0047'}\n",
            "\n",
            "Test Loss: 0.014420676045119762\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_2.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_2.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the structure of the best model for configuration 1\n",
        "print(\"Best Model Structure for Configuration 1:\")\n",
        "best_model_config_1.summary()\n",
        "\n",
        "# Display the structure of the best model for configuration 2\n",
        "print(\"\\nBest Model Structure for Configuration 2:\")\n",
        "best_model_config_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "outputId": "80b551b3-fad6-4bcc-da45-a72349a4f281",
        "id": "Qa5qlF-6qQ3u"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model Structure for Configuration 1:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m150\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │              \u001b[38;5;34m42\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │              \u001b[38;5;34m42\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m7\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │              \u001b[38;5;34m12\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │              \u001b[38;5;34m42\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │              \u001b[38;5;34m42\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m168\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m505\u001b[0m (1.97 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">505</span> (1.97 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m505\u001b[0m (1.97 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">505</span> (1.97 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Model Structure for Configuration 2:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │             \u001b[38;5;34m225\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │              \u001b[38;5;34m90\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │              \u001b[38;5;34m90\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │              \u001b[38;5;34m90\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m10\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │              \u001b[38;5;34m18\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │              \u001b[38;5;34m90\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │              \u001b[38;5;34m90\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │              \u001b[38;5;34m90\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">225</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,033\u001b[0m (4.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,033</span> (4.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,033\u001b[0m (4.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,033</span> (4.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print details of each layer for the best model in configuration 1\n",
        "print(\"Best Model for Configuration 1:\")\n",
        "for layer in best_model_config_1.layers:\n",
        "    if hasattr(layer, 'output_shape'):\n",
        "        output_shape = layer.output_shape\n",
        "    else:\n",
        "        output_shape = layer.get_output_shape_at(0) if hasattr(layer, 'get_output_shape_at') else 'N/A'\n",
        "    print(f\"Layer: {layer.name}, Type: {layer.__class__.__name__}, Output Shape: {output_shape}, Parameters: {layer.count_params()}\")\n",
        "\n",
        "# Print details of each layer for the best model in configuration 2\n",
        "print(\"\\nBest Model for Configuration 2:\")\n",
        "for layer in best_model_config_2.layers:\n",
        "    if hasattr(layer, 'output_shape'):\n",
        "        output_shape = layer.output_shape\n",
        "    else:\n",
        "        output_shape = layer.get_output_shape_at(0) if hasattr(layer, 'get_output_shape_at') else 'N/A'\n",
        "    print(f\"Layer: {layer.name}, Type: {layer.__class__.__name__}, Output Shape: {output_shape}, Parameters: {layer.count_params()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab9bd72-883f-4364-f68f-3b315f023d64",
        "id": "Bg2MADs9qQ3w"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model for Configuration 1:\n",
            "Layer: input_layer, Type: InputLayer, Output Shape: N/A, Parameters: 0\n",
            "Layer: dense_encoder_1, Type: Dense, Output Shape: N/A, Parameters: 150\n",
            "Layer: dense_encoder_2, Type: Dense, Output Shape: N/A, Parameters: 42\n",
            "Layer: dense_encoder_3, Type: Dense, Output Shape: N/A, Parameters: 42\n",
            "Layer: bottleneck, Type: Dense, Output Shape: N/A, Parameters: 7\n",
            "Layer: dense_decoder_1, Type: Dense, Output Shape: N/A, Parameters: 12\n",
            "Layer: dense_decoder_2, Type: Dense, Output Shape: N/A, Parameters: 42\n",
            "Layer: dense_decoder_3, Type: Dense, Output Shape: N/A, Parameters: 42\n",
            "Layer: output_layer, Type: Dense, Output Shape: N/A, Parameters: 168\n",
            "\n",
            "Best Model for Configuration 2:\n",
            "Layer: input_layer, Type: InputLayer, Output Shape: N/A, Parameters: 0\n",
            "Layer: dense_encoder_1, Type: Dense, Output Shape: N/A, Parameters: 225\n",
            "Layer: dense_encoder_2, Type: Dense, Output Shape: N/A, Parameters: 90\n",
            "Layer: dense_encoder_3, Type: Dense, Output Shape: N/A, Parameters: 90\n",
            "Layer: dense_encoder_4, Type: Dense, Output Shape: N/A, Parameters: 90\n",
            "Layer: bottleneck, Type: Dense, Output Shape: N/A, Parameters: 10\n",
            "Layer: dense_decoder_1, Type: Dense, Output Shape: N/A, Parameters: 18\n",
            "Layer: dense_decoder_2, Type: Dense, Output Shape: N/A, Parameters: 90\n",
            "Layer: dense_decoder_3, Type: Dense, Output Shape: N/A, Parameters: 90\n",
            "Layer: dense_decoder_4, Type: Dense, Output Shape: N/A, Parameters: 90\n",
            "Layer: output_layer, Type: Dense, Output Shape: N/A, Parameters: 240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_1 = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder_model_config_1 = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer_config_1)\n",
        "bottleneck_output_1 = encoder_model_config_1.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c88e877d-a593-42af-aeee-17f9a3b7d54c",
        "id": "_Nhzjv07qQ3y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_2 = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder_model_config_2 = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer_config_2)\n",
        "bottleneck_output_2 = encoder_model_config_2.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "345fdf94-3d56-4365-a8d1-9801a4d1c387",
        "id": "eMJX3kPeqQ3y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_output_1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeaad332-05c1-43bc-c055-6c60d13c177a",
        "id": "9MRSRBL0qQ3z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(262, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_output_2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994271cc-1e97-43fb-c137-17bf0bac92c0",
        "id": "1Ore5o-vqQ3z"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(262, 1)"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_regression\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "AtQtHBFlqQ30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = []\n",
        "for i in range(bottleneck_output_1.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_1[:, i], random_state=42)\n",
        "    mi_scores.append(mi)\n"
      ],
      "metadata": {
        "id": "DMKEO2txqQ30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2fe089c-c8d4-4822-84de-5ac21d99dd68",
        "id": "wWhQlUXiqQ31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.62668436, 0.72630959, 0.6436562 , 0.78745763, 0.66476808,\n",
              "        0.77796662, 0.85742204, 0.92875388, 1.41374823, 0.87191872,\n",
              "        1.20623266, 0.61214267, 0.658503  , 0.77998096, 0.74869513,\n",
              "        0.74466675, 0.76392034, 0.63487119, 0.72160316, 1.03331348,\n",
              "        1.01346991, 0.53937368, 0.66744976, 0.67125691])]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc5ca0c-ed30-4f9d-d7d3-60c6726d0a23",
        "id": "t07b0ryOqQ32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_1.shape[1]))\n",
        "\n",
        "for dim in range(bottleneck_output_1.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim]"
      ],
      "metadata": {
        "id": "thdX2vi-qQ33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))"
      ],
      "metadata": {
        "id": "Xx1CRUjiqQ34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "yHu0fYQ-qQ34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "9369ad65-0af9-478c-c749-1febbe6099df",
        "id": "8Ht7g9s9qQ35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
              "0     0.248076     0.8750   0.179775   0.154095   0.197059   0.706532   \n",
              "1     0.195931     0.8125   0.207865   0.238147   0.226471   0.504140   \n",
              "2     0.134073     0.8125   0.353933   0.635776   0.522059   0.374425   \n",
              "3     0.572489     0.6250   0.325843   0.429957   0.278676   0.555658   \n",
              "4     0.257560     0.8125   0.193820   0.023707   0.050000   0.869365   \n",
              "..         ...        ...        ...        ...        ...        ...   \n",
              "257   0.000000     0.0000   0.000000   0.000000   0.000000   0.000000   \n",
              "258   0.000000     0.0000   0.000000   0.000000   0.000000   0.000000   \n",
              "259   0.000000     0.0000   0.000000   0.000000   0.000000   0.000000   \n",
              "260   0.000000     0.0000   0.000000   0.000000   0.000000   0.000000   \n",
              "261   0.000000     0.0000   0.000000   0.000000   0.000000   0.000000   \n",
              "\n",
              "     Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_16  Feature_17  \\\n",
              "0     0.192593   0.291705   0.877313    0.821121  ...    0.090142    0.366577   \n",
              "1     0.370370   0.222425   0.915696    0.813578  ...    0.800026    0.280323   \n",
              "2     0.918519   0.887876   0.781357    0.000000  ...    0.867792    0.407008   \n",
              "3     0.511111   0.117593   0.921179    0.843750  ...    0.360056    0.412399   \n",
              "4     0.755556   0.235187   0.988348    0.733836  ...    0.023910    0.234501   \n",
              "..         ...        ...        ...         ...  ...         ...         ...   \n",
              "257   0.000000   0.000000   0.000000    0.000000  ...    0.000000    0.000000   \n",
              "258   0.000000   0.000000   0.000000    0.000000  ...    0.000000    0.000000   \n",
              "259   0.000000   0.000000   0.000000    0.000000  ...    0.000000    0.000000   \n",
              "260   0.000000   0.000000   0.000000    0.000000  ...    0.000000    0.000000   \n",
              "261   0.000000   0.000000   0.000000    0.000000  ...    0.000000    0.000000   \n",
              "\n",
              "     Feature_18  Feature_19  Feature_20  Feature_21  Feature_22  Feature_23  \\\n",
              "0      1.000000    0.873016    0.097033    0.108458       0.846    0.409878   \n",
              "1      0.761905    0.698413    0.160974    0.132647       0.624    0.693119   \n",
              "2      1.000000    0.714286    0.091006    0.068664       0.571    0.944280   \n",
              "3      1.000000    0.825397    0.078832    0.034956       0.336    0.782609   \n",
              "4      0.333333    0.555556    0.521570    0.409644       0.595    0.931617   \n",
              "..          ...         ...         ...         ...         ...         ...   \n",
              "257    0.000000    0.000000    0.000000    0.000000       0.000    0.000000   \n",
              "258    0.000000    0.000000    0.000000    0.000000       0.000    0.000000   \n",
              "259    0.000000    0.000000    0.000000    0.000000       0.000    0.000000   \n",
              "260    0.000000    0.000000    0.000000    0.000000       0.000    0.000000   \n",
              "261    0.000000    0.000000    0.000000    0.000000       0.000    0.000000   \n",
              "\n",
              "     Feature_24  Final_Index  \n",
              "0      0.706241     0.458588  \n",
              "1      0.472230     0.481695  \n",
              "2      0.863955     0.553711  \n",
              "3      0.618615     0.511829  \n",
              "4      0.833712     0.481893  \n",
              "..          ...          ...  \n",
              "257    0.000000     0.000000  \n",
              "258    0.000000     0.000000  \n",
              "259    0.000000     0.000000  \n",
              "260    0.000000     0.000000  \n",
              "261    0.000000     0.000000  \n",
              "\n",
              "[262 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef1d8923-a365-49bc-bdb8-08190bb1189a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature_1</th>\n",
              "      <th>Feature_2</th>\n",
              "      <th>Feature_3</th>\n",
              "      <th>Feature_4</th>\n",
              "      <th>Feature_5</th>\n",
              "      <th>Feature_6</th>\n",
              "      <th>Feature_7</th>\n",
              "      <th>Feature_8</th>\n",
              "      <th>Feature_9</th>\n",
              "      <th>Feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>Feature_16</th>\n",
              "      <th>Feature_17</th>\n",
              "      <th>Feature_18</th>\n",
              "      <th>Feature_19</th>\n",
              "      <th>Feature_20</th>\n",
              "      <th>Feature_21</th>\n",
              "      <th>Feature_22</th>\n",
              "      <th>Feature_23</th>\n",
              "      <th>Feature_24</th>\n",
              "      <th>Final_Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.248076</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.179775</td>\n",
              "      <td>0.154095</td>\n",
              "      <td>0.197059</td>\n",
              "      <td>0.706532</td>\n",
              "      <td>0.192593</td>\n",
              "      <td>0.291705</td>\n",
              "      <td>0.877313</td>\n",
              "      <td>0.821121</td>\n",
              "      <td>...</td>\n",
              "      <td>0.090142</td>\n",
              "      <td>0.366577</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.873016</td>\n",
              "      <td>0.097033</td>\n",
              "      <td>0.108458</td>\n",
              "      <td>0.846</td>\n",
              "      <td>0.409878</td>\n",
              "      <td>0.706241</td>\n",
              "      <td>0.458588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.195931</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.207865</td>\n",
              "      <td>0.238147</td>\n",
              "      <td>0.226471</td>\n",
              "      <td>0.504140</td>\n",
              "      <td>0.370370</td>\n",
              "      <td>0.222425</td>\n",
              "      <td>0.915696</td>\n",
              "      <td>0.813578</td>\n",
              "      <td>...</td>\n",
              "      <td>0.800026</td>\n",
              "      <td>0.280323</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.698413</td>\n",
              "      <td>0.160974</td>\n",
              "      <td>0.132647</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.693119</td>\n",
              "      <td>0.472230</td>\n",
              "      <td>0.481695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.134073</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.353933</td>\n",
              "      <td>0.635776</td>\n",
              "      <td>0.522059</td>\n",
              "      <td>0.374425</td>\n",
              "      <td>0.918519</td>\n",
              "      <td>0.887876</td>\n",
              "      <td>0.781357</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.867792</td>\n",
              "      <td>0.407008</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.091006</td>\n",
              "      <td>0.068664</td>\n",
              "      <td>0.571</td>\n",
              "      <td>0.944280</td>\n",
              "      <td>0.863955</td>\n",
              "      <td>0.553711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.572489</td>\n",
              "      <td>0.6250</td>\n",
              "      <td>0.325843</td>\n",
              "      <td>0.429957</td>\n",
              "      <td>0.278676</td>\n",
              "      <td>0.555658</td>\n",
              "      <td>0.511111</td>\n",
              "      <td>0.117593</td>\n",
              "      <td>0.921179</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>...</td>\n",
              "      <td>0.360056</td>\n",
              "      <td>0.412399</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.825397</td>\n",
              "      <td>0.078832</td>\n",
              "      <td>0.034956</td>\n",
              "      <td>0.336</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.618615</td>\n",
              "      <td>0.511829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.257560</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.193820</td>\n",
              "      <td>0.023707</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.869365</td>\n",
              "      <td>0.755556</td>\n",
              "      <td>0.235187</td>\n",
              "      <td>0.988348</td>\n",
              "      <td>0.733836</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023910</td>\n",
              "      <td>0.234501</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.521570</td>\n",
              "      <td>0.409644</td>\n",
              "      <td>0.595</td>\n",
              "      <td>0.931617</td>\n",
              "      <td>0.833712</td>\n",
              "      <td>0.481893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef1d8923-a365-49bc-bdb8-08190bb1189a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ef1d8923-a365-49bc-bdb8-08190bb1189a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ef1d8923-a365-49bc-bdb8-08190bb1189a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7d0a942a-0413-471f-955d-8a5d24d7d25b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d0a942a-0413-471f-955d-8a5d24d7d25b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7d0a942a-0413-471f-955d-8a5d24d7d25b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2f52e002-fdb1-4ab2-9405-0329be6684e9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2f52e002-fdb1-4ab2-9405-0329be6684e9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)\n",
        "df.to_excel(\"socioecon_AUTOENCODER_best_auto_config1_mod_onedim_minmax_1215.xlsx\", index=False)\n",
        "\n",
        "print(\"File 'socioecon_AUTOENCODER.xlsx' has been saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07eaca60-5394-4f2a-8076-9bde3a1702a2",
        "id": "QpNa4zoVqQ36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'socioecon_AUTOENCODER.xlsx' has been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = []\n",
        "for i in range(bottleneck_output_2.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_2[:, i], random_state=42)\n",
        "    mi_scores.append(mi)\n"
      ],
      "metadata": {
        "id": "1_mNL8bsqQ37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e978360-3673-4771-a0f0-d152fd16c190",
        "id": "Qi_LEV2NqQ37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.77212208, 0.69667059, 0.65517043, 0.87591643, 0.72094857,\n",
              "        0.79021404, 0.83306905, 1.15837827, 1.69266304, 0.86424479,\n",
              "        1.22445411, 0.6276208 , 0.72470217, 0.82754034, 0.95700406,\n",
              "        0.94438236, 0.86803076, 0.63589015, 0.68953472, 1.07586588,\n",
              "        0.91541699, 0.5601476 , 0.66470421, 0.6598256 ])]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3da16bc9-cd66-4cf4-e7f6-fd71c7ece1e7",
        "id": "cVIPwEkDqQ38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_1.shape[1]))\n",
        "\n",
        "for dim in range(bottleneck_output_1.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim]"
      ],
      "metadata": {
        "id": "A32BfvTDqQ39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))"
      ],
      "metadata": {
        "id": "Fdxf-AZeqQ39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "J2OZZZb-qQ3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "b0cee901-9bc5-4bb3-ea25-93bd1a9c1370",
        "id": "LiBrE3aiqQ3-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
              "0     0.248076     0.8750   0.179775   0.154095   0.197059   0.706532   \n",
              "1     0.195931     0.8125   0.207865   0.238147   0.226471   0.504140   \n",
              "2     0.134073     0.8125   0.353933   0.635776   0.522059   0.374425   \n",
              "3     0.572489     0.6250   0.325843   0.429957   0.278676   0.555658   \n",
              "4     0.257560     0.8125   0.193820   0.023707   0.050000   0.869365   \n",
              "..         ...        ...        ...        ...        ...        ...   \n",
              "257   0.000000     0.0000   0.000000   0.000000   0.000000   0.000000   \n",
              "258   0.000000     0.0000   0.000000   0.000000   0.000000   0.000000   \n",
              "259   0.000000     0.0000   0.000000   0.000000   0.000000   0.000000   \n",
              "260   0.000000     0.0000   0.000000   0.000000   0.000000   0.000000   \n",
              "261   0.000000     0.0000   0.000000   0.000000   0.000000   0.000000   \n",
              "\n",
              "     Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_16  Feature_17  \\\n",
              "0     0.192593   0.291705   0.877313    0.821121  ...    0.090142    0.366577   \n",
              "1     0.370370   0.222425   0.915696    0.813578  ...    0.800026    0.280323   \n",
              "2     0.918519   0.887876   0.781357    0.000000  ...    0.867792    0.407008   \n",
              "3     0.511111   0.117593   0.921179    0.843750  ...    0.360056    0.412399   \n",
              "4     0.755556   0.235187   0.988348    0.733836  ...    0.023910    0.234501   \n",
              "..         ...        ...        ...         ...  ...         ...         ...   \n",
              "257   0.000000   0.000000   0.000000    0.000000  ...    0.000000    0.000000   \n",
              "258   0.000000   0.000000   0.000000    0.000000  ...    0.000000    0.000000   \n",
              "259   0.000000   0.000000   0.000000    0.000000  ...    0.000000    0.000000   \n",
              "260   0.000000   0.000000   0.000000    0.000000  ...    0.000000    0.000000   \n",
              "261   0.000000   0.000000   0.000000    0.000000  ...    0.000000    0.000000   \n",
              "\n",
              "     Feature_18  Feature_19  Feature_20  Feature_21  Feature_22  Feature_23  \\\n",
              "0      1.000000    0.873016    0.097033    0.108458       0.846    0.409878   \n",
              "1      0.761905    0.698413    0.160974    0.132647       0.624    0.693119   \n",
              "2      1.000000    0.714286    0.091006    0.068664       0.571    0.944280   \n",
              "3      1.000000    0.825397    0.078832    0.034956       0.336    0.782609   \n",
              "4      0.333333    0.555556    0.521570    0.409644       0.595    0.931617   \n",
              "..          ...         ...         ...         ...         ...         ...   \n",
              "257    0.000000    0.000000    0.000000    0.000000       0.000    0.000000   \n",
              "258    0.000000    0.000000    0.000000    0.000000       0.000    0.000000   \n",
              "259    0.000000    0.000000    0.000000    0.000000       0.000    0.000000   \n",
              "260    0.000000    0.000000    0.000000    0.000000       0.000    0.000000   \n",
              "261    0.000000    0.000000    0.000000    0.000000       0.000    0.000000   \n",
              "\n",
              "     Feature_24  Final_Index  \n",
              "0      0.706241     0.452091  \n",
              "1      0.472230     0.481493  \n",
              "2      0.863955     0.563761  \n",
              "3      0.618615     0.510631  \n",
              "4      0.833712     0.470268  \n",
              "..          ...          ...  \n",
              "257    0.000000     0.000000  \n",
              "258    0.000000     0.000000  \n",
              "259    0.000000     0.000000  \n",
              "260    0.000000     0.000000  \n",
              "261    0.000000     0.000000  \n",
              "\n",
              "[262 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad2abc6d-d784-4505-89ba-898fb95a504f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature_1</th>\n",
              "      <th>Feature_2</th>\n",
              "      <th>Feature_3</th>\n",
              "      <th>Feature_4</th>\n",
              "      <th>Feature_5</th>\n",
              "      <th>Feature_6</th>\n",
              "      <th>Feature_7</th>\n",
              "      <th>Feature_8</th>\n",
              "      <th>Feature_9</th>\n",
              "      <th>Feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>Feature_16</th>\n",
              "      <th>Feature_17</th>\n",
              "      <th>Feature_18</th>\n",
              "      <th>Feature_19</th>\n",
              "      <th>Feature_20</th>\n",
              "      <th>Feature_21</th>\n",
              "      <th>Feature_22</th>\n",
              "      <th>Feature_23</th>\n",
              "      <th>Feature_24</th>\n",
              "      <th>Final_Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.248076</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.179775</td>\n",
              "      <td>0.154095</td>\n",
              "      <td>0.197059</td>\n",
              "      <td>0.706532</td>\n",
              "      <td>0.192593</td>\n",
              "      <td>0.291705</td>\n",
              "      <td>0.877313</td>\n",
              "      <td>0.821121</td>\n",
              "      <td>...</td>\n",
              "      <td>0.090142</td>\n",
              "      <td>0.366577</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.873016</td>\n",
              "      <td>0.097033</td>\n",
              "      <td>0.108458</td>\n",
              "      <td>0.846</td>\n",
              "      <td>0.409878</td>\n",
              "      <td>0.706241</td>\n",
              "      <td>0.452091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.195931</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.207865</td>\n",
              "      <td>0.238147</td>\n",
              "      <td>0.226471</td>\n",
              "      <td>0.504140</td>\n",
              "      <td>0.370370</td>\n",
              "      <td>0.222425</td>\n",
              "      <td>0.915696</td>\n",
              "      <td>0.813578</td>\n",
              "      <td>...</td>\n",
              "      <td>0.800026</td>\n",
              "      <td>0.280323</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.698413</td>\n",
              "      <td>0.160974</td>\n",
              "      <td>0.132647</td>\n",
              "      <td>0.624</td>\n",
              "      <td>0.693119</td>\n",
              "      <td>0.472230</td>\n",
              "      <td>0.481493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.134073</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.353933</td>\n",
              "      <td>0.635776</td>\n",
              "      <td>0.522059</td>\n",
              "      <td>0.374425</td>\n",
              "      <td>0.918519</td>\n",
              "      <td>0.887876</td>\n",
              "      <td>0.781357</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.867792</td>\n",
              "      <td>0.407008</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.091006</td>\n",
              "      <td>0.068664</td>\n",
              "      <td>0.571</td>\n",
              "      <td>0.944280</td>\n",
              "      <td>0.863955</td>\n",
              "      <td>0.563761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.572489</td>\n",
              "      <td>0.6250</td>\n",
              "      <td>0.325843</td>\n",
              "      <td>0.429957</td>\n",
              "      <td>0.278676</td>\n",
              "      <td>0.555658</td>\n",
              "      <td>0.511111</td>\n",
              "      <td>0.117593</td>\n",
              "      <td>0.921179</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>...</td>\n",
              "      <td>0.360056</td>\n",
              "      <td>0.412399</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.825397</td>\n",
              "      <td>0.078832</td>\n",
              "      <td>0.034956</td>\n",
              "      <td>0.336</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.618615</td>\n",
              "      <td>0.510631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.257560</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.193820</td>\n",
              "      <td>0.023707</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.869365</td>\n",
              "      <td>0.755556</td>\n",
              "      <td>0.235187</td>\n",
              "      <td>0.988348</td>\n",
              "      <td>0.733836</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023910</td>\n",
              "      <td>0.234501</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.521570</td>\n",
              "      <td>0.409644</td>\n",
              "      <td>0.595</td>\n",
              "      <td>0.931617</td>\n",
              "      <td>0.833712</td>\n",
              "      <td>0.470268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad2abc6d-d784-4505-89ba-898fb95a504f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad2abc6d-d784-4505-89ba-898fb95a504f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad2abc6d-d784-4505-89ba-898fb95a504f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-493157f7-82b2-4c80-9f6d-bf84418374ae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-493157f7-82b2-4c80-9f6d-bf84418374ae')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-493157f7-82b2-4c80-9f6d-bf84418374ae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e9986dea-6ea7-4cf8-8989-ff27552c4649\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e9986dea-6ea7-4cf8-8989-ff27552c4649 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)\n",
        "df.to_excel(\"socioecon_AUTOENCODER_best_auto_config2_mod_onedim_minmax_1215.xlsx\", index=False)\n",
        "\n",
        "print(\"File 'socioecon_AUTOENCODER.xlsx' has been saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "226631ef-d11e-4e23-b03a-b36af60c3b6d",
        "id": "oMf93h5bqQ3_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'socioecon_AUTOENCODER.xlsx' has been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mod - different numbers of nerons with regularization techiniques (alpha tuned) - corr standard (method 3)"
      ],
      "metadata": {
        "id": "a9IgyB7oIdOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('SE_Original_(NOT SHARED) FOR USE_2020_mod.xlsx')\n",
        "X_ori = data.iloc[:, 3:27].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X_ori)\n",
        "\n",
        "# Split\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "fr98-HHUIdOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def create_autoencoder(input_dim, encoding_dim, hidden_layers_before, hidden_layers_after, neurons_before, neurons_after):\n",
        "    # Define the input layer\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "\n",
        "    # Build the encoder part\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons_before, activation='relu', name=f'dense_encoder_{i+1}')(x)\n",
        "\n",
        "    # Bottleneck layer (encoding layer)\n",
        "    bottleneck = Dense(encoding_dim, activation='relu', name='bottleneck')(x)\n",
        "\n",
        "    # Build the decoder part\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons_after, activation='relu', name=f'dense_decoder_{i+1}')(x)\n",
        "\n",
        "    # Output layer, with the same dimension as the input\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Define the complete autoencoder model\n",
        "    autoencoder = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "2P4vy4FFIdOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial tuning\n",
        "hidden_layers_options = [2, 4, 6, 8]  # Even numbers to ensure symmetry\n",
        "neurons_options = [8, 12, 16]\n",
        "encoding_dims_options = [1, 2, 3, 4, 5]\n",
        "results = []\n",
        "\n",
        "# Iterate through each combination of hyperparameters\n",
        "for hidden_layers in hidden_layers_options:\n",
        "    hidden_layers_before = hidden_layers // 2\n",
        "    hidden_layers_after = hidden_layers // 2\n",
        "\n",
        "    for neurons in neurons_options:\n",
        "        for encoding_dim in encoding_dims_options:\n",
        "            autoencoder = create_autoencoder(\n",
        "                input_dim=X_train.shape[1],\n",
        "                encoding_dim=encoding_dim,\n",
        "                hidden_layers_before=hidden_layers_before,\n",
        "                hidden_layers_after=hidden_layers_after,\n",
        "                neurons_before=neurons,\n",
        "                neurons_after=neurons\n",
        "            )\n",
        "            autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "            history = autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, verbose=0, validation_data=(X_test, X_test))\n",
        "\n",
        "            # Calculate average loss on the test set\n",
        "            test_loss = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
        "            results.append((hidden_layers, encoding_dim, neurons, test_loss))\n",
        "\n",
        "# Sort results by the lowest test loss and select the best two configurations\n",
        "sorted_results = sorted(results, key=lambda x: x[3])\n",
        "best_configs = sorted_results[:2]\n",
        "\n",
        "# Print best configurations for reference and show model summary\n",
        "print(\"Top two configurations:\")\n",
        "for config in best_configs:\n",
        "    hidden_layers, encoding_dim, neurons, test_loss = config\n",
        "    print(f\"Hidden layers: {hidden_layers}, Encoding dimension: {encoding_dim}, Neurons: {neurons}, Test loss: {test_loss}\")\n",
        "\n",
        "    # Recreate and display the model summary for the best configurations\n",
        "    autoencoder = create_autoencoder(\n",
        "        input_dim=X_train.shape[1],\n",
        "        encoding_dim=encoding_dim,\n",
        "        hidden_layers_before=hidden_layers // 2,\n",
        "        hidden_layers_after=hidden_layers // 2,\n",
        "        neurons_before=neurons,\n",
        "        neurons_after=neurons\n",
        "    )\n",
        "    autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "outputId": "fb8489ce-dc1f-4781-f5a0-2a9d2c4a857e",
        "id": "0UU5tw9bIdOq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top two configurations:\n",
            "Hidden layers: 6, Encoding dimension: 4, Neurons: 16, Test loss: 0.17452606558799744\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │              \u001b[38;5;34m68\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m80\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m408\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,044\u001b[0m (7.98 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,044</span> (7.98 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,044\u001b[0m (7.98 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,044</span> (7.98 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden layers: 8, Encoding dimension: 2, Neurons: 16, Test loss: 0.17812329530715942\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m34\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m48\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m408\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,522\u001b[0m (9.85 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,522</span> (9.85 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,522\u001b[0m (9.85 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,522</span> (9.85 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " add orthogonal regularization (w/ alpha tuned)"
      ],
      "metadata": {
        "id": "rBgsub2EIdOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "# Custom layer for orthogonal regularization\n",
        "class OrthogonalRegularization(Layer):\n",
        "    def __init__(self, alpha=1e-2, **kwargs):\n",
        "        super(OrthogonalRegularization, self).__init__(**kwargs)\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def call(self, bottleneck_output):\n",
        "        # Get the batch size\n",
        "        batch_size = tf.cast(tf.shape(bottleneck_output)[0], tf.float32)\n",
        "\n",
        "        # Normalize the bottleneck outputs\n",
        "        normalized_output = bottleneck_output / tf.sqrt(batch_size)\n",
        "\n",
        "        # Compute correlation matrix\n",
        "        correlation = tf.matmul(\n",
        "            tf.transpose(normalized_output),\n",
        "            normalized_output\n",
        "        )\n",
        "\n",
        "        # Create identity matrix of the correct shape\n",
        "        shape = tf.shape(correlation)[0]\n",
        "        identity = tf.eye(shape)\n",
        "\n",
        "        # Calculate loss (excluding diagonal elements)\n",
        "        mask = tf.ones_like(correlation) - tf.eye(shape)\n",
        "        loss = tf.reduce_sum(tf.square(correlation * mask))\n",
        "\n",
        "        # Add loss to the layer\n",
        "        self.add_loss(self.alpha * loss)\n",
        "\n",
        "        return bottleneck_output\n"
      ],
      "metadata": {
        "id": "Ji4pdvjfIdOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp, input_dim, hidden_layers_before, hidden_layers_after):\n",
        "    # Hyperparameters to tune\n",
        "    encoding_dim = hp.Int('encoding_dim', min_value=2, max_value=5, step=1)\n",
        "    neurons = hp.Int('neurons', min_value=6, max_value=24, step=3)\n",
        "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "    batch_size = hp.Choice('batch_size', [16, 32, 64])\n",
        "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "    # alpha tuned\n",
        "    alpha = hp.Choice('alpha', [1e-3, 1e-2, 1e-1, 1.0])\n",
        "\n",
        "    # Build the model structure\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "    x = input_layer\n",
        "\n",
        "    # Encoder layers\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_encoder_{i+1}')(x)\n",
        "\n",
        "    # Bottleneck layer with orthogonal regularization\n",
        "    bottleneck = Dense(\n",
        "        encoding_dim,\n",
        "        activation=activation,\n",
        "        kernel_constraint=tf.keras.constraints.UnitNorm(axis=0),\n",
        "        name='bottleneck'\n",
        "    )(x)\n",
        "\n",
        "    # Apply orthogonal regularization\n",
        "    bottleneck = OrthogonalRegularization(alpha=alpha)(bottleneck) #modified alpha for tuning\n",
        "\n",
        "    # Decoder layers\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_decoder_{i+1}')(x)\n",
        "\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Create and compile model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        loss='mse'  # Using standard MSE loss now\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "NNLu4xTTIdOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import Hyperband\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "b22Tdyt5IdOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        min_delta=1e-4\n",
        "    )\n",
        "]\n"
      ],
      "metadata": {
        "id": "W9c0LbZRIdOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define search space for each configuration\n",
        "tuner_config_1 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=3, hidden_layers_after=3),\n",
        "    objective='val_loss',\n",
        "    max_epochs=50,\n",
        "    factor=3,\n",
        "    directory='hyperpara_tuning_1_ortho_al',\n",
        "    project_name='model_config_1'\n",
        ")\n",
        "\n",
        "# Define search space for each configuration\n",
        "tuner_config_2 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=4, hidden_layers_after=4),\n",
        "    objective='val_loss',\n",
        "    max_epochs=50,\n",
        "    factor=3,\n",
        "    directory='hyperpara_tuning_2_ortho_al',\n",
        "    project_name='model_config_2',\n",
        "    overwrite=True\n",
        ")"
      ],
      "metadata": {
        "id": "_P6E6oO_IdOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning\n",
        "tuner_config_1.search(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs=50,\n",
        "    validation_data=(X_test, X_test),\n",
        "    callbacks=callbacks,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e5a516-56d3-4ef7-e7b9-392361e080d8",
        "id": "EeyouekMIdOr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 21s]\n",
            "val_loss: 0.6056467294692993\n",
            "\n",
            "Best val_loss So Far: 0.12343984097242355\n",
            "Total elapsed time: 00h 14m 50s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning\n",
        "tuner_config_2.search(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs=50,\n",
        "    validation_data=(X_test, X_test),\n",
        "    callbacks=callbacks,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afb385a9-1219-4c6a-bc38-fcb7c515428d",
        "id": "UDX5xAfwIdOs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 23s]\n",
            "val_loss: 0.1205180212855339\n",
            "\n",
            "Best val_loss So Far: 0.1205180212855339\n",
            "Total elapsed time: 00h 21m 10s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### regularization"
      ],
      "metadata": {
        "id": "K_F0lhp56tVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "id": "w3gsGrDS6tVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_1.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_1.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT23Gq5PgC9a",
        "outputId": "fd36c9df-b59f-4a24-c0fd-c4a6ca657676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 5, 'neurons': 15, 'learning_rate': 0.01, 'batch_size': 32, 'activation': 'tanh', 'alpha': 0.001, 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0047'}\n",
            "\n",
            "Test Loss: 0.12343984097242355\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "[[ 1.          0.01563735  0.08845119  0.47797774  0.23262205]\n",
            " [ 0.01563735  1.          0.00298947  0.36033671 -0.02047094]\n",
            " [ 0.08845119  0.00298947  1.          0.46411566  0.40291995]\n",
            " [ 0.47797774  0.36033671  0.46411566  1.          0.39900081]\n",
            " [ 0.23262205 -0.02047094  0.40291995  0.39900081  1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer"
      ],
      "metadata": {
        "id": "kc15klzZ6tVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract encoder and decoder from the trained autoencoder\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=best_model_config_1.get_layer('bottleneck').output)\n",
        "\n",
        "# Create a decoder model (assuming symmetric architecture)\n",
        "bottleneck_input = tf.keras.Input(shape=(encoder.output.shape[1],))\n",
        "x = bottleneck_input\n",
        "for layer_name in [l.name for l in best_model_config_1.layers if 'dense_decoder' in l.name]:\n",
        "    x = best_model_config_1.get_layer(layer_name)(x)\n",
        "decoder_output = best_model_config_1.get_layer('output_layer')(x)\n",
        "decoder = Model(inputs=bottleneck_input, outputs=decoder_output)\n"
      ],
      "metadata": {
        "id": "LVXHgaQY6tVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "bB-63Zqm6tVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate bottleneck contributions\n",
        "def calculate_bottleneck_contributions(autoencoder, encoder, decoder, X):\n",
        "    bottleneck_output = encoder.predict(X)\n",
        "    contributions = []\n",
        "\n",
        "    for dim in range(bottleneck_output.shape[1]):\n",
        "        # Isolate one dimension at a time\n",
        "        isolated_latent = np.zeros_like(bottleneck_output)\n",
        "        isolated_latent[:, dim] = bottleneck_output[:, dim]\n",
        "\n",
        "        # Reconstruct input using only the isolated latent dimension\n",
        "        reconstructed = decoder.predict(isolated_latent)\n",
        "\n",
        "        # Compute reconstruction loss (e.g., MSE)\n",
        "        loss = mean_squared_error(X, reconstructed)\n",
        "        contributions.append(loss)\n",
        "\n",
        "    # Normalize contributions\n",
        "    contributions = np.array(contributions)\n",
        "    normalized_contributions = 1 - (contributions / np.sum(contributions))\n",
        "\n",
        "    return normalized_contributions"
      ],
      "metadata": {
        "id": "AUD19kLG6tVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contributions\n",
        "contributions = calculate_bottleneck_contributions(best_model_config_1, encoder, decoder, X_train)\n",
        "\n",
        "# Print contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbaf1708-ed9b-4367-92ff-b55f205884b4",
        "id": "Yb7qtJbY6tVo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.7715\n",
            "Latent Dimension 2: 0.8025\n",
            "Latent Dimension 3: 0.8015\n",
            "Latent Dimension 4: 0.8500\n",
            "Latent Dimension 5: 0.7745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the contributions so they sum to 1\n",
        "def normalize_contributions(contributions):\n",
        "    total = sum(contributions)\n",
        "    return [c / total for c in contributions]\n",
        "\n",
        "# Calculate contributions\n",
        "#contributions = calculate_bottleneck_contributions(best_model_config_1, encoder, decoder, X_train)\n",
        "\n",
        "# Normalize contributions\n",
        "normalized_contributions = normalize_contributions(contributions)\n",
        "\n",
        "# Print normalized contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(normalized_contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")\n",
        "\n",
        "# Verify sum to 1\n",
        "print(\"Sum of Normalized Contributions:\", sum(normalized_contributions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "152cea14-22e2-4658-8ce3-2a38e19999de",
        "id": "GWTC-KTx6tVp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.1929\n",
            "Latent Dimension 2: 0.2006\n",
            "Latent Dimension 3: 0.2004\n",
            "Latent Dimension 4: 0.2125\n",
            "Latent Dimension 5: 0.1936\n",
            "Sum of Normalized Contributions: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_contributions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b28ccc-7057-4b21-9afa-d7413bfb9d50",
        "id": "JGW-_CYy6tVp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19287748087616946,\n",
              " 0.2006155725229849,\n",
              " 0.20037139989913172,\n",
              " 0.21249984188748264,\n",
              " 0.19363570481423134]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_1 = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder_model_config_1 = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer_config_1)\n",
        "bottleneck_output_1 = encoder_model_config_1.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4a37de-70b6-4906-9cda-db6a6768381a",
        "id": "RQgtRP2C6tVp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions = np.array(normalized_contributions)\n",
        "\n",
        "# Calculate MI scores\n",
        "mi_scores = []\n",
        "for i in range(bottleneck_output_1.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_1[:, i], random_state=42)\n",
        "    mi_scores.append(mi)"
      ],
      "metadata": {
        "id": "PeKor7cX6tVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf56475-26fd-41e7-e31c-c4ca1792c4a8",
        "id": "QbxdKe0I6tVp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_1.shape[1]))\n",
        "\n",
        "# Multiply MI scores by latent space contributions for each bottleneck dimension\n",
        "for dim in range(bottleneck_output_1.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim] * latent_contributions[dim]"
      ],
      "metadata": {
        "id": "sHYpL0lU6tVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1481a74a-3eec-4e56-f66e-5aa35def862b",
        "id": "QlP3SZi26tVp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.19287748, 0.20061557, 0.2003714 , 0.21249984, 0.1936357 ])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_mi_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a9a851-c3da-4bb9-bf93-0f8cbfa0d301",
        "id": "4xGwsr4Z6tVp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04117537, 0.03661376, 0.04762047, 0.05211858, 0.04430519],\n",
              "       [0.0374096 , 0.03951889, 0.03817171, 0.04215191, 0.04252005],\n",
              "       [0.0376609 , 0.03813338, 0.04456891, 0.04262956, 0.04319346],\n",
              "       [0.0388838 , 0.04136329, 0.06207811, 0.04506302, 0.0465928 ],\n",
              "       [0.03731962, 0.03425157, 0.04977827, 0.04231396, 0.07552758],\n",
              "       [0.03806196, 0.0471533 , 0.03949431, 0.04218331, 0.04390402],\n",
              "       [0.03983413, 0.03670959, 0.04209999, 0.04360557, 0.03874607],\n",
              "       [0.07326825, 0.03882458, 0.03642964, 0.04425371, 0.03839183],\n",
              "       [0.07412343, 0.04385386, 0.0541308 , 0.04619805, 0.03857748],\n",
              "       [0.04199613, 0.05598852, 0.0491157 , 0.04860385, 0.04425008],\n",
              "       [0.04486089, 0.05391211, 0.05265754, 0.0432962 , 0.04089556],\n",
              "       [0.01497383, 0.01761521, 0.0171469 , 0.01323896, 0.01853321],\n",
              "       [0.04410983, 0.03629658, 0.0332491 , 0.04987715, 0.03840498],\n",
              "       [0.04115252, 0.04092669, 0.03956933, 0.0399911 , 0.0433269 ],\n",
              "       [0.05142686, 0.04841149, 0.05115013, 0.04661149, 0.04886835],\n",
              "       [0.04335868, 0.04540042, 0.04817424, 0.04354086, 0.03534984],\n",
              "       [0.04041577, 0.04606064, 0.04632381, 0.04779224, 0.04031217],\n",
              "       [0.04014421, 0.04114769, 0.0344886 , 0.03742331, 0.0427136 ],\n",
              "       [0.03878347, 0.04126779, 0.03264821, 0.04119817, 0.04005172],\n",
              "       [0.04670712, 0.05135035, 0.04018811, 0.03862171, 0.03976705],\n",
              "       [0.03341577, 0.05327891, 0.03623729, 0.03502755, 0.03027256],\n",
              "       [0.02538616, 0.04137915, 0.03080924, 0.03230073, 0.0400117 ],\n",
              "       [0.04471896, 0.03520024, 0.03418051, 0.04215404, 0.04456393],\n",
              "       [0.03081275, 0.03534199, 0.03968909, 0.03980496, 0.04091985]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))\n",
        "\n",
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "7AjqVIMg6tVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Excel\n",
        "df.to_excel(\"real_se_AUTOENCODER_best_auto_config1_1207_with_weights_mod_ss.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "tYe9Nur96tVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "config 2"
      ],
      "metadata": {
        "id": "WXe-QhZS6tVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e06679-3753-4f1e-a5df-a6cde2b00b78",
        "id": "BxLpVZ626tVq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 42 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_2.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_2.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d80a94-9f38-4f01-c2ef-205c6c3d2f03",
        "id": "vAJoz3LY6tVq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 5, 'neurons': 15, 'learning_rate': 0.01, 'batch_size': 64, 'activation': 'tanh', 'alpha': 0.1, 'tuner/epochs': 50, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
            "\n",
            "Test Loss: 0.1205180212855339\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "[[ 1.         -0.47074008 -0.08920948 -0.08574593 -0.23235335]\n",
            " [-0.47074008  1.         -0.28753228 -0.02662083  0.47915895]\n",
            " [-0.08920948 -0.28753228  1.         -0.26569227 -0.06627331]\n",
            " [-0.08574593 -0.02662083 -0.26569227  1.          0.02860696]\n",
            " [-0.23235335  0.47915895 -0.06627331  0.02860696  1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract encoder and decoder from the trained autoencoder\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=best_model_config_2.get_layer('bottleneck').output)\n",
        "\n",
        "# Create a decoder model (assuming symmetric architecture)\n",
        "bottleneck_input = tf.keras.Input(shape=(encoder.output.shape[1],))\n",
        "x = bottleneck_input\n",
        "for layer_name in [l.name for l in best_model_config_2.layers if 'dense_decoder' in l.name]:\n",
        "    x = best_model_config_2.get_layer(layer_name)(x)\n",
        "decoder_output = best_model_config_2.get_layer('output_layer')(x)\n",
        "decoder = Model(inputs=bottleneck_input, outputs=decoder_output)"
      ],
      "metadata": {
        "id": "8ClSvzal6tVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contributions\n",
        "contributions = calculate_bottleneck_contributions(best_model_config_2, encoder, decoder, X_train)\n",
        "\n",
        "# Print contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ac4261-72ff-420d-88a9-3ab1686f3df5",
        "id": "WNzEdfuK6tVq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.8620\n",
            "Latent Dimension 2: 0.8399\n",
            "Latent Dimension 3: 0.7687\n",
            "Latent Dimension 4: 0.7589\n",
            "Latent Dimension 5: 0.7705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize contributions\n",
        "normalized_contributions = normalize_contributions(contributions)\n",
        "\n",
        "# Print normalized contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(normalized_contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")\n",
        "\n",
        "# Verify they sum to 1\n",
        "print(\"Sum of Normalized Contributions:\", sum(normalized_contributions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f34c8d-f03a-40e9-89d2-35e2c1d9505b",
        "id": "Q5ZA8Tm86tVq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.2155\n",
            "Latent Dimension 2: 0.2100\n",
            "Latent Dimension 3: 0.1922\n",
            "Latent Dimension 4: 0.1897\n",
            "Latent Dimension 5: 0.1926\n",
            "Sum of Normalized Contributions: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_2 = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder_model_config_2 = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer_config_2)\n",
        "bottleneck_output_2 = encoder_model_config_2.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b604a021-8a8c-420d-df68-f9a415495295",
        "id": "VfVYaE8L6tVq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions = np.array(normalized_contributions)  # Make sure this is normalized\n",
        "\n",
        "mi_scores = []\n",
        "for i in range(bottleneck_output_2.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_2[:, i], random_state=42)\n",
        "    mi_scores.append(mi)"
      ],
      "metadata": {
        "id": "wmIj4nA16tVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "608d8b89-c294-4b8f-939f-63dda3e53645",
        "id": "BV2Dbvpi6tVr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_2.shape[1]))\n",
        "\n",
        "# Multiply MI scores by latent space contributions for each bottleneck dimension\n",
        "for dim in range(bottleneck_output_2.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim] * latent_contributions[dim]"
      ],
      "metadata": {
        "id": "OrdREYro6tVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))\n",
        "\n",
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "480kcHEN6tVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Excel\n",
        "df.to_excel(\"real_se_AUTOENCODER_best_auto_config2_1207_with_weights_mod_ss.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "fSPy3Ky46tVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_config_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "892803cb-ea8b-4678-fab5-c7909ec4245b",
        "id": "U0F99m4d6tVr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m375\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m80\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ orthogonal_regularization            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mOrthogonalRegularization\u001b[0m)           │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │              \u001b[38;5;34m90\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m384\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ orthogonal_regularization            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OrthogonalRegularization</span>)           │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,889\u001b[0m (7.38 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,889</span> (7.38 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,889\u001b[0m (7.38 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,889</span> (7.38 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_config_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "cbc98367-e3f1-4010-9e53-d3bbcdc6f2c0",
        "id": "sa5K3O5V6tVr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m375\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m80\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ orthogonal_regularization            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mOrthogonalRegularization\u001b[0m)           │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │              \u001b[38;5;34m90\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m384\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ orthogonal_regularization            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OrthogonalRegularization</span>)           │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,369\u001b[0m (9.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,369</span> (9.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,369\u001b[0m (9.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,369</span> (9.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pgXT8BKW6tVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mod - different numbers of nerons with regularization techiniques (alpha tuned) - corr MinMax (method 3)"
      ],
      "metadata": {
        "id": "5LokeyVaXy7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('SE_Original_(NOT SHARED) FOR USE_2020_mod.xlsx')\n",
        "X_ori = data.iloc[:, 3:27].values\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X_ori)\n",
        "\n",
        "# Split\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "n7mkKDdmXy7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def create_autoencoder(input_dim, encoding_dim, hidden_layers_before, hidden_layers_after, neurons_before, neurons_after):\n",
        "    # Define the input layer\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "\n",
        "    # Build the encoder part\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons_before, activation='relu', name=f'dense_encoder_{i+1}')(x)\n",
        "\n",
        "    # Bottleneck layer (encoding layer)\n",
        "    bottleneck = Dense(encoding_dim, activation='relu', name='bottleneck')(x)\n",
        "\n",
        "    # Build the decoder part\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons_after, activation='relu', name=f'dense_decoder_{i+1}')(x)\n",
        "\n",
        "    # Output layer, with the same dimension as the input\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Define the complete autoencoder model\n",
        "    autoencoder = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "eoyyfQcIXy7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial tuning\n",
        "hidden_layers_options = [2, 4, 6, 8]  # Even numbers to ensure symmetry\n",
        "neurons_options = [8, 12, 16]\n",
        "encoding_dims_options = [1, 2, 3, 4, 5]\n",
        "results = []\n",
        "\n",
        "# Iterate through each combination of hyperparameters\n",
        "for hidden_layers in hidden_layers_options:\n",
        "    hidden_layers_before = hidden_layers // 2\n",
        "    hidden_layers_after = hidden_layers // 2\n",
        "\n",
        "    for neurons in neurons_options:\n",
        "        for encoding_dim in encoding_dims_options:\n",
        "            autoencoder = create_autoencoder(\n",
        "                input_dim=X_train.shape[1],\n",
        "                encoding_dim=encoding_dim,\n",
        "                hidden_layers_before=hidden_layers_before,\n",
        "                hidden_layers_after=hidden_layers_after,\n",
        "                neurons_before=neurons,\n",
        "                neurons_after=neurons\n",
        "            )\n",
        "            autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "            history = autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, verbose=0, validation_data=(X_test, X_test))\n",
        "\n",
        "            # Calculate average loss on the test set\n",
        "            test_loss = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
        "            results.append((hidden_layers, encoding_dim, neurons, test_loss))\n",
        "\n",
        "# Sort results by the lowest test loss and select the best two configurations\n",
        "sorted_results = sorted(results, key=lambda x: x[3])\n",
        "best_configs = sorted_results[:2]\n",
        "\n",
        "# Print best configurations for reference and show model summary\n",
        "print(\"Top two configurations:\")\n",
        "for config in best_configs:\n",
        "    hidden_layers, encoding_dim, neurons, test_loss = config\n",
        "    print(f\"Hidden layers: {hidden_layers}, Encoding dimension: {encoding_dim}, Neurons: {neurons}, Test loss: {test_loss}\")\n",
        "\n",
        "    # Recreate and display the model summary for the best configurations\n",
        "    autoencoder = create_autoencoder(\n",
        "        input_dim=X_train.shape[1],\n",
        "        encoding_dim=encoding_dim,\n",
        "        hidden_layers_before=hidden_layers // 2,\n",
        "        hidden_layers_after=hidden_layers // 2,\n",
        "        neurons_before=neurons,\n",
        "        neurons_after=neurons\n",
        "    )\n",
        "    autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "outputId": "7caba983-9f7c-4855-f517-2c12498b89c9",
        "id": "YJZNFRQMXy7M"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top two configurations:\n",
            "Hidden layers: 6, Encoding dimension: 5, Neurons: 16, Test loss: 0.01743723452091217\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m96\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m408\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,077\u001b[0m (8.11 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,077</span> (8.11 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,077\u001b[0m (8.11 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,077</span> (8.11 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden layers: 8, Encoding dimension: 3, Neurons: 16, Test loss: 0.01776418834924698\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m408\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,555\u001b[0m (9.98 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,555</span> (9.98 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,555\u001b[0m (9.98 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,555</span> (9.98 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " add orthogonal regularization (w/ alpha tuned)"
      ],
      "metadata": {
        "id": "qb9y80QuXy7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "# Custom layer for orthogonal regularization\n",
        "class OrthogonalRegularization(Layer):\n",
        "    def __init__(self, alpha=1e-2, **kwargs):\n",
        "        super(OrthogonalRegularization, self).__init__(**kwargs)\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def call(self, bottleneck_output):\n",
        "        # Get the batch size\n",
        "        batch_size = tf.cast(tf.shape(bottleneck_output)[0], tf.float32)\n",
        "\n",
        "        # Normalize the bottleneck outputs\n",
        "        normalized_output = bottleneck_output / tf.sqrt(batch_size)\n",
        "\n",
        "        # Compute correlation matrix\n",
        "        correlation = tf.matmul(\n",
        "            tf.transpose(normalized_output),\n",
        "            normalized_output\n",
        "        )\n",
        "\n",
        "        # Create identity matrix of the correct shape\n",
        "        shape = tf.shape(correlation)[0]\n",
        "        identity = tf.eye(shape)\n",
        "\n",
        "        # Calculate loss (excluding diagonal elements)\n",
        "        mask = tf.ones_like(correlation) - tf.eye(shape)\n",
        "        loss = tf.reduce_sum(tf.square(correlation * mask))\n",
        "\n",
        "        # Add loss to the layer\n",
        "        self.add_loss(self.alpha * loss)\n",
        "\n",
        "        return bottleneck_output\n"
      ],
      "metadata": {
        "id": "QIMsR-eKXy7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp, input_dim, hidden_layers_before, hidden_layers_after):\n",
        "    # Hyperparameters to tune\n",
        "    encoding_dim = hp.Int('encoding_dim', min_value=2, max_value=5, step=1)\n",
        "    neurons = hp.Int('neurons', min_value=6, max_value=24, step=3)\n",
        "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "    batch_size = hp.Choice('batch_size', [16, 32, 64])\n",
        "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "    # alpha tuned\n",
        "    alpha = hp.Choice('alpha', [1e-3, 1e-2, 1e-1, 1.0])\n",
        "\n",
        "    # Build the model structure\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "    x = input_layer\n",
        "\n",
        "    # Encoder layers\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_encoder_{i+1}')(x)\n",
        "\n",
        "    # Bottleneck layer with orthogonal regularization\n",
        "    bottleneck = Dense(\n",
        "        encoding_dim,\n",
        "        activation=activation,\n",
        "        kernel_constraint=tf.keras.constraints.UnitNorm(axis=0),\n",
        "        name='bottleneck'\n",
        "    )(x)\n",
        "\n",
        "    # Apply orthogonal regularization\n",
        "    bottleneck = OrthogonalRegularization(alpha=alpha)(bottleneck) #modified alpha for tunin\n",
        "\n",
        "    # Decoder layers\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_decoder_{i+1}')(x)\n",
        "\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Create and compile model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        loss='mse'  # Using standard MSE loss now\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "3XNqw7UFXy7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import Hyperband\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "tHckgm6cXy7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        min_delta=1e-4\n",
        "    )\n",
        "]\n"
      ],
      "metadata": {
        "id": "g2gQDM7AXy7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define search space for each configuration\n",
        "tuner_config_1 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=3, hidden_layers_after=3),\n",
        "    objective='val_loss',\n",
        "    max_epochs=50,\n",
        "    factor=3,\n",
        "    directory='hyperpara_tuning_1_ortho_alp',\n",
        "    project_name='model_config_1'\n",
        ")\n",
        "\n",
        "# Define search space for each configuration\n",
        "tuner_config_2 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=4, hidden_layers_after=4),\n",
        "    objective='val_loss',\n",
        "    max_epochs=50,\n",
        "    factor=3,\n",
        "    directory='hyperpara_tuning_2_ortho_alp',\n",
        "    project_name='model_config_2',\n",
        "    overwrite=True\n",
        ")"
      ],
      "metadata": {
        "id": "VK_tDramXy7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning\n",
        "tuner_config_1.search(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs=50,\n",
        "    validation_data=(X_test, X_test),\n",
        "    callbacks=callbacks,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eceb45ca-cd8f-43ee-d4c3-ea064e420f24",
        "id": "bcgCmhTmXy7N"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 27s]\n",
            "val_loss: 0.028448501601815224\n",
            "\n",
            "Best val_loss So Far: 0.009290081448853016\n",
            "Total elapsed time: 00h 27m 32s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning\n",
        "tuner_config_2.search(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs=50,\n",
        "    validation_data=(X_test, X_test),\n",
        "    callbacks=callbacks,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b1cc89-a771-4da0-e117-5a5d69f68aa1",
        "id": "Xe9J2DDmXy7N"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 29s]\n",
            "val_loss: 0.009475469589233398\n",
            "\n",
            "Best val_loss So Far: 0.009475469589233398\n",
            "Total elapsed time: 00h 32m 58s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### regularization"
      ],
      "metadata": {
        "id": "GKEx64tGXy7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "id": "NweBcUIjXy7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_1.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_1.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d870e4e6-2e06-4e2d-91c5-a6884020c237",
        "id": "v7-iEcbXXy7O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 5, 'neurons': 18, 'learning_rate': 0.01, 'batch_size': 64, 'activation': 'tanh', 'alpha': 0.01, 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0076'}\n",
            "\n",
            "Test Loss: 0.009290081448853016\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "[[ 1.         -0.21559774 -0.37336696  0.36021264 -0.23835218]\n",
            " [-0.21559774  1.          0.17705809  0.10282089 -0.42454685]\n",
            " [-0.37336696  0.17705809  1.          0.01535451  0.15280912]\n",
            " [ 0.36021264  0.10282089  0.01535451  1.         -0.25548381]\n",
            " [-0.23835218 -0.42454685  0.15280912 -0.25548381  1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer"
      ],
      "metadata": {
        "id": "-BcAf5BiXy7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract encoder and decoder from the trained autoencoder\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=best_model_config_1.get_layer('bottleneck').output)\n",
        "\n",
        "# Create a decoder model (assuming symmetric architecture)\n",
        "bottleneck_input = tf.keras.Input(shape=(encoder.output.shape[1],))\n",
        "x = bottleneck_input\n",
        "for layer_name in [l.name for l in best_model_config_1.layers if 'dense_decoder' in l.name]:\n",
        "    x = best_model_config_1.get_layer(layer_name)(x)\n",
        "decoder_output = best_model_config_1.get_layer('output_layer')(x)\n",
        "decoder = Model(inputs=bottleneck_input, outputs=decoder_output)\n"
      ],
      "metadata": {
        "id": "vo_X3JG-Xy7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "zvJvmr9xXy7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate bottleneck contributions\n",
        "def calculate_bottleneck_contributions(autoencoder, encoder, decoder, X):\n",
        "    bottleneck_output = encoder.predict(X)\n",
        "    contributions = []\n",
        "\n",
        "    for dim in range(bottleneck_output.shape[1]):\n",
        "        # Isolate one dimension at a time\n",
        "        isolated_latent = np.zeros_like(bottleneck_output)\n",
        "        isolated_latent[:, dim] = bottleneck_output[:, dim]\n",
        "\n",
        "        # Reconstruct input using only the isolated latent dimension\n",
        "        reconstructed = decoder.predict(isolated_latent)\n",
        "\n",
        "        # Compute reconstruction loss (e.g., MSE)\n",
        "        loss = mean_squared_error(X, reconstructed)\n",
        "        contributions.append(loss)\n",
        "\n",
        "    # Normalize contributions\n",
        "    contributions = np.array(contributions)\n",
        "    normalized_contributions = 1 - (contributions / np.sum(contributions))\n",
        "\n",
        "    return normalized_contributions"
      ],
      "metadata": {
        "id": "Ttfb-QiWXy7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contributions\n",
        "contributions = calculate_bottleneck_contributions(best_model_config_1, encoder, decoder, X_train)\n",
        "\n",
        "# Print contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb677356-2238-4b1b-88d3-6290b674bd41",
        "id": "mPidA-gjXy7O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.7589\n",
            "Latent Dimension 2: 0.7655\n",
            "Latent Dimension 3: 0.9235\n",
            "Latent Dimension 4: 0.7744\n",
            "Latent Dimension 5: 0.7777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the contributions so they sum to 1\n",
        "def normalize_contributions(contributions):\n",
        "    total = sum(contributions)\n",
        "    return [c / total for c in contributions]\n",
        "\n",
        "# Calculate contributions\n",
        "#contributions = calculate_bottleneck_contributions(best_model_config_1, encoder, decoder, X_train)\n",
        "\n",
        "# Normalize contributions\n",
        "normalized_contributions = normalize_contributions(contributions)\n",
        "\n",
        "# Print normalized contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(normalized_contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")\n",
        "\n",
        "# Verify they sum to 1\n",
        "print(\"Sum of Normalized Contributions:\", sum(normalized_contributions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd99c70-23a2-4a92-9fa2-a631e8c1bd38",
        "id": "Gfx373sAXy7O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.1897\n",
            "Latent Dimension 2: 0.1914\n",
            "Latent Dimension 3: 0.2309\n",
            "Latent Dimension 4: 0.1936\n",
            "Latent Dimension 5: 0.1944\n",
            "Sum of Normalized Contributions: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_contributions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2602bd6-d9a2-4b89-8c02-3530d90d8352",
        "id": "LLg-PMYuXy7O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1897325750513584,\n",
              " 0.19138099932297334,\n",
              " 0.23086371752359017,\n",
              " 0.19359327271286708,\n",
              " 0.194429435389211]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_1 = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder_model_config_1 = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer_config_1)\n",
        "bottleneck_output_1 = encoder_model_config_1.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c1ea8ef-7c7a-4f4f-bff4-9815f6bedacb",
        "id": "sgLPNy3AXy7O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions = np.array(normalized_contributions)\n",
        "\n",
        "# Calculate MI scores\n",
        "mi_scores = []\n",
        "for i in range(bottleneck_output_1.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_1[:, i], random_state=42)\n",
        "    mi_scores.append(mi)"
      ],
      "metadata": {
        "id": "wsA-iirnXy7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e4b987-e294-4acd-a872-2964d9c1d949",
        "id": "GVmBKu1hXy7O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_1.shape[1]))\n",
        "\n",
        "# Multiply MI scores by latent space contributions for each bottleneck dimension\n",
        "for dim in range(bottleneck_output_1.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim] * latent_contributions[dim]"
      ],
      "metadata": {
        "id": "o8lKnmi0Xy7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a4d003-7407-4897-d913-8286b4bab0bd",
        "id": "MWNtOkBMXy7P"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.18973258, 0.191381  , 0.23086372, 0.19359327, 0.19442944])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_mi_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "418008cd-7496-4522-a7c6-1e377d2db4ff",
        "id": "L4v719SgXy7P"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04403813, 0.05912023, 0.03839699, 0.04514464, 0.04380568],\n",
              "       [0.04136017, 0.03875533, 0.03831339, 0.04681214, 0.03465181],\n",
              "       [0.04543249, 0.04364298, 0.0355126 , 0.03563134, 0.04264342],\n",
              "       [0.04026794, 0.05259841, 0.06006437, 0.03846253, 0.04155085],\n",
              "       [0.04861087, 0.04362248, 0.04052443, 0.03941416, 0.06098905],\n",
              "       [0.04024098, 0.04166316, 0.03992578, 0.04416311, 0.04214621],\n",
              "       [0.04879535, 0.04532305, 0.0370296 , 0.04556244, 0.04750156],\n",
              "       [0.04389576, 0.04184179, 0.04172719, 0.06047009, 0.03881507],\n",
              "       [0.05056276, 0.05635183, 0.0457511 , 0.05823634, 0.05125694],\n",
              "       [0.04952685, 0.04300422, 0.03962841, 0.04086586, 0.04700478],\n",
              "       [0.04580567, 0.05581204, 0.04118017, 0.05232595, 0.04757477],\n",
              "       [0.02835891, 0.01857804, 0.01302364, 0.0182495 , 0.01097345],\n",
              "       [0.03890976, 0.03966699, 0.04982663, 0.03954378, 0.03289627],\n",
              "       [0.04352458, 0.03814445, 0.03879363, 0.04595992, 0.04226888],\n",
              "       [0.03653422, 0.03912507, 0.07351073, 0.03499749, 0.04316514],\n",
              "       [0.03882283, 0.0479063 , 0.05992074, 0.02994733, 0.03782163],\n",
              "       [0.04355739, 0.04977448, 0.04813745, 0.03998076, 0.04391133],\n",
              "       [0.03836026, 0.03473452, 0.03605106, 0.04031975, 0.04211195],\n",
              "       [0.03830581, 0.02962119, 0.0385062 , 0.04326668, 0.03812114],\n",
              "       [0.05189081, 0.03908561, 0.03951712, 0.04002841, 0.04369591],\n",
              "       [0.0377224 , 0.03810426, 0.03349044, 0.03779273, 0.04039369],\n",
              "       [0.0340837 , 0.02719271, 0.03079564, 0.03332509, 0.04542696],\n",
              "       [0.03758761, 0.03442738, 0.04243298, 0.0502525 , 0.0429874 ],\n",
              "       [0.03380473, 0.04190349, 0.03793971, 0.03924747, 0.03828613]])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))\n",
        "\n",
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "J2aTZhpIXy7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Excel\n",
        "df.to_excel(\"real_se_AUTOENCODER_best_auto_config1_1208_with_weights_mod_mm.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "P5t8vDKxXy7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "config 2"
      ],
      "metadata": {
        "id": "lYLkpVZIXy7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36eae10f-2619-41d2-dd08-22f61f37b8b9",
        "id": "JATa4z1qXy7P"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 42 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_2.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_2.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a1a43e0-eaa5-419b-c552-cb55bb1f7226",
        "id": "j4IDfEY1Xy7P"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 4, 'neurons': 21, 'learning_rate': 0.01, 'batch_size': 32, 'activation': 'tanh', 'alpha': 0.001, 'tuner/epochs': 50, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
            "\n",
            "Test Loss: 0.009475469589233398\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 229ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "[[ 1.         -0.29614563  0.59267155 -0.29757324]\n",
            " [-0.29614563  1.         -0.02364822 -0.20476406]\n",
            " [ 0.59267155 -0.02364822  1.         -0.42211233]\n",
            " [-0.29757324 -0.20476406 -0.42211233  1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract encoder and decoder from the trained autoencoder\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=best_model_config_2.get_layer('bottleneck').output)\n",
        "\n",
        "# Create a decoder model (assuming symmetric architecture)\n",
        "bottleneck_input = tf.keras.Input(shape=(encoder.output.shape[1],))\n",
        "x = bottleneck_input\n",
        "for layer_name in [l.name for l in best_model_config_2.layers if 'dense_decoder' in l.name]:\n",
        "    x = best_model_config_2.get_layer(layer_name)(x)\n",
        "decoder_output = best_model_config_2.get_layer('output_layer')(x)\n",
        "decoder = Model(inputs=bottleneck_input, outputs=decoder_output)"
      ],
      "metadata": {
        "id": "8ygeIAm1Xy7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contributions\n",
        "contributions = calculate_bottleneck_contributions(best_model_config_2, encoder, decoder, X_train)\n",
        "\n",
        "# Print contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3206d416-3832-4653-bb47-bb6ca9576e53",
        "id": "b0azgO_PXy7P"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  \n",
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.7162\n",
            "Latent Dimension 2: 0.6938\n",
            "Latent Dimension 3: 0.8896\n",
            "Latent Dimension 4: 0.7003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize contributions\n",
        "normalized_contributions = normalize_contributions(contributions)\n",
        "\n",
        "# Print normalized contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(normalized_contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")\n",
        "\n",
        "# Verify they sum to 1\n",
        "print(\"Sum of Normalized Contributions:\", sum(normalized_contributions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c225e40-9c5e-4789-b4f7-4bf5e95e5100",
        "id": "TEikgd7cXy7P"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.2387\n",
            "Latent Dimension 2: 0.2313\n",
            "Latent Dimension 3: 0.2965\n",
            "Latent Dimension 4: 0.2334\n",
            "Sum of Normalized Contributions: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_2 = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder_model_config_2 = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer_config_2)\n",
        "bottleneck_output_2 = encoder_model_config_2.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e079926-5c88-40b4-fd18-bab014b2175c",
        "id": "MWsclhTyXy7P"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions = np.array(normalized_contributions)  # Make sure this is normalized\n",
        "\n",
        "mi_scores = []\n",
        "for i in range(bottleneck_output_2.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_2[:, i], random_state=42)\n",
        "    mi_scores.append(mi)"
      ],
      "metadata": {
        "id": "3xre7BEYXy7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6135d5a4-f57a-42ed-b44a-486e158fa035",
        "id": "fzdoo9PPXy7Q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_2.shape[1]))\n",
        "\n",
        "# Multiply MI scores by latent space contributions for each bottleneck dimension\n",
        "for dim in range(bottleneck_output_2.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim] * latent_contributions[dim]"
      ],
      "metadata": {
        "id": "Rp9YPs75Xy7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))\n",
        "\n",
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "pN4PMcysXy7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Excel\n",
        "df.to_excel(\"real_se_AUTOENCODER_best_auto_config2_1208_with_weights_mod_mm.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "cEO7wGmYXy7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_config_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "1b6341c2-ce70-407a-c4b6-78d24530df52",
        "id": "udO6woU3Xy7Q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m450\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m95\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ orthogonal_regularization            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mOrthogonalRegularization\u001b[0m)           │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m108\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m456\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ orthogonal_regularization            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OrthogonalRegularization</span>)           │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">456</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,477\u001b[0m (9.68 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,477</span> (9.68 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,477\u001b[0m (9.68 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,477</span> (9.68 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_config_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "1e0f940a-5b12-4da7-e325-5940894e8b0c",
        "id": "JyNlKy0PXy7Q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m525\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │              \u001b[38;5;34m88\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ orthogonal_regularization            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mOrthogonalRegularization\u001b[0m)           │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m105\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │             \u001b[38;5;34m462\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">525</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ orthogonal_regularization            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OrthogonalRegularization</span>)           │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,018\u001b[0m (15.70 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,018</span> (15.70 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,018\u001b[0m (15.70 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,018</span> (15.70 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## res - different numbers of nerons with regularization techiniques (alpha tuned) - corr standard (method 3)"
      ],
      "metadata": {
        "id": "NtdQqtfMszGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('SE_Original_(NOT SHARED) FOR USE_2020_residential.xlsx')\n",
        "X_ori = data.iloc[:, 3:27].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X_ori)\n",
        "\n",
        "# Split\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "kF2xFwR1szGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def create_autoencoder(input_dim, encoding_dim, hidden_layers_before, hidden_layers_after, neurons_before, neurons_after):\n",
        "    # Define the input layer\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "\n",
        "    # Build the encoder part\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons_before, activation='relu', name=f'dense_encoder_{i+1}')(x)\n",
        "\n",
        "    # Bottleneck layer (encoding layer)\n",
        "    bottleneck = Dense(encoding_dim, activation='relu', name='bottleneck')(x)\n",
        "\n",
        "    # Build the decoder part\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons_after, activation='relu', name=f'dense_decoder_{i+1}')(x)\n",
        "\n",
        "    # Output layer, with the same dimension as the input\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Define the complete autoencoder model\n",
        "    autoencoder = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "Bs_f28HlszGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial tuning\n",
        "hidden_layers_options = [2, 4, 6, 8]  # Even numbers to ensure symmetry\n",
        "neurons_options = [8, 12, 16]\n",
        "encoding_dims_options = [1, 2, 3, 4, 5]\n",
        "results = []\n",
        "\n",
        "# Iterate through each combination of hyperparameters\n",
        "for hidden_layers in hidden_layers_options:\n",
        "    hidden_layers_before = hidden_layers // 2\n",
        "    hidden_layers_after = hidden_layers // 2\n",
        "\n",
        "    for neurons in neurons_options:\n",
        "        for encoding_dim in encoding_dims_options:\n",
        "            autoencoder = create_autoencoder(\n",
        "                input_dim=X_train.shape[1],\n",
        "                encoding_dim=encoding_dim,\n",
        "                hidden_layers_before=hidden_layers_before,\n",
        "                hidden_layers_after=hidden_layers_after,\n",
        "                neurons_before=neurons,\n",
        "                neurons_after=neurons\n",
        "            )\n",
        "            autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "            history = autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, verbose=0, validation_data=(X_test, X_test))\n",
        "\n",
        "            # Calculate average loss on the test set\n",
        "            test_loss = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
        "            results.append((hidden_layers, encoding_dim, neurons, test_loss))\n",
        "\n",
        "# Sort results by the lowest test loss and select the best two configurations\n",
        "sorted_results = sorted(results, key=lambda x: x[3])\n",
        "best_configs = sorted_results[:2]\n",
        "\n",
        "# Print best configurations for reference and show model summary\n",
        "print(\"Top two configurations:\")\n",
        "for config in best_configs:\n",
        "    hidden_layers, encoding_dim, neurons, test_loss = config\n",
        "    print(f\"Hidden layers: {hidden_layers}, Encoding dimension: {encoding_dim}, Neurons: {neurons}, Test loss: {test_loss}\")\n",
        "\n",
        "    # Recreate and display the model summary for the best configurations\n",
        "    autoencoder = create_autoencoder(\n",
        "        input_dim=X_train.shape[1],\n",
        "        encoding_dim=encoding_dim,\n",
        "        hidden_layers_before=hidden_layers // 2,\n",
        "        hidden_layers_after=hidden_layers // 2,\n",
        "        neurons_before=neurons,\n",
        "        neurons_after=neurons\n",
        "    )\n",
        "    autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "outputId": "cddbc4c5-253b-4e8b-c656-c9c4f77fbe84",
        "id": "_54EjrBbszGG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top two configurations:\n",
            "Hidden layers: 4, Encoding dimension: 3, Neurons: 16, Test loss: 0.4787726402282715\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m408\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,467\u001b[0m (5.73 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,467</span> (5.73 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,467\u001b[0m (5.73 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,467</span> (5.73 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden layers: 6, Encoding dimension: 5, Neurons: 16, Test loss: 0.497527539730072\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m96\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m408\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,077\u001b[0m (8.11 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,077</span> (8.11 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,077\u001b[0m (8.11 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,077</span> (8.11 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "add orthogonal regularization (w/ alpha tuned)"
      ],
      "metadata": {
        "id": "yVDvqG64szGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "# Custom layer for orthogonal regularization\n",
        "class OrthogonalRegularization(Layer):\n",
        "    def __init__(self, alpha=1e-2, **kwargs):\n",
        "        super(OrthogonalRegularization, self).__init__(**kwargs)\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def call(self, bottleneck_output):\n",
        "        # Get the batch size\n",
        "        batch_size = tf.cast(tf.shape(bottleneck_output)[0], tf.float32)\n",
        "\n",
        "        # Normalize the bottleneck outputs\n",
        "        normalized_output = bottleneck_output / tf.sqrt(batch_size)\n",
        "\n",
        "        # Compute correlation matrix\n",
        "        correlation = tf.matmul(\n",
        "            tf.transpose(normalized_output),\n",
        "            normalized_output\n",
        "        )\n",
        "\n",
        "        # Create identity matrix of the correct shape\n",
        "        shape = tf.shape(correlation)[0]\n",
        "        identity = tf.eye(shape)\n",
        "\n",
        "        # Calculate loss (excluding diagonal elements)\n",
        "        mask = tf.ones_like(correlation) - tf.eye(shape)\n",
        "        loss = tf.reduce_sum(tf.square(correlation * mask))\n",
        "\n",
        "        # Add loss to the layer\n",
        "        self.add_loss(self.alpha * loss)\n",
        "\n",
        "        return bottleneck_output\n"
      ],
      "metadata": {
        "id": "9mxTZRb7szGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp, input_dim, hidden_layers_before, hidden_layers_after):\n",
        "    # Hyperparameters to tune\n",
        "    encoding_dim = hp.Int('encoding_dim', min_value=2, max_value=5, step=1)\n",
        "    neurons = hp.Int('neurons', min_value=6, max_value=24, step=3)\n",
        "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "    batch_size = hp.Choice('batch_size', [16, 32, 64])\n",
        "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "    # alpha tuned\n",
        "    alpha = hp.Choice('alpha', [1e-3, 1e-2, 1e-1, 1.0])\n",
        "\n",
        "    # Build the model structure\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "    x = input_layer\n",
        "\n",
        "    # Encoder layers\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_encoder_{i+1}')(x)\n",
        "\n",
        "    # Bottleneck layer with orthogonal regularization\n",
        "    bottleneck = Dense(\n",
        "        encoding_dim,\n",
        "        activation=activation,\n",
        "        kernel_constraint=tf.keras.constraints.UnitNorm(axis=0),\n",
        "        name='bottleneck'\n",
        "    )(x)\n",
        "\n",
        "    # Apply orthogonal regularization\n",
        "    bottleneck = OrthogonalRegularization(alpha=alpha)(bottleneck) #modified alpha for tunin\n",
        "\n",
        "    # Decoder layers\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_decoder_{i+1}')(x)\n",
        "\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Create and compile model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        loss='mse'  # Using standard MSE loss\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "p1FdCD6rszGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import Hyperband\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "T0FTszL0szGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        min_delta=1e-4\n",
        "    )\n",
        "]\n"
      ],
      "metadata": {
        "id": "YBIdRapiszGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner_config_1 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=2, hidden_layers_after=2),\n",
        "    objective='val_loss',\n",
        "    max_epochs=50,\n",
        "    factor=3,\n",
        "    directory='hyperpara_tuning_1_ort_ho_aaal',\n",
        "    project_name='model_config_1'\n",
        ")\n",
        "\n",
        "tuner_config_2 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=3, hidden_layers_after=3),\n",
        "    objective='val_loss',\n",
        "    max_epochs=50,\n",
        "    factor=3,\n",
        "    directory='hyperpara_tuning_2_ort_ho_aaal',\n",
        "    project_name='model_config_2',\n",
        "    overwrite=True\n",
        ")"
      ],
      "metadata": {
        "id": "ML64WZTAszGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning\n",
        "tuner_config_1.search(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs=50,\n",
        "    validation_data=(X_test, X_test),\n",
        "    callbacks=callbacks,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "hNCDOgN5szGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning\n",
        "tuner_config_2.search(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs=50,\n",
        "    validation_data=(X_test, X_test),\n",
        "    callbacks=callbacks,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c0c18e-df64-4d2a-ba5f-74f6e4c9db4a",
        "id": "EY4ffOpBszGI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 22s]\n",
            "val_loss: 0.48952168226242065\n",
            "\n",
            "Best val_loss So Far: 0.36945563554763794\n",
            "Total elapsed time: 00h 22m 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### regularization"
      ],
      "metadata": {
        "id": "Zc2zCdHMszGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "id": "jHUsxE0bszGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_1.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_1.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05fe2eb3-16bc-4752-908c-6a57fad395f1",
        "id": "WxokaQbFszGI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 4, 'neurons': 9, 'learning_rate': 0.01, 'batch_size': 32, 'activation': 'tanh', 'alpha': 0.001, 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0049'}\n",
            "\n",
            "Test Loss: 0.42116695642471313\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "[[ 1.          0.19574385  0.34091679 -0.25850344]\n",
            " [ 0.19574385  1.         -0.01460667 -0.13430074]\n",
            " [ 0.34091679 -0.01460667  1.          0.08144593]\n",
            " [-0.25850344 -0.13430074  0.08144593  1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer"
      ],
      "metadata": {
        "id": "ZFdKsh6eszGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract encoder and decoder from the trained autoencoder\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=best_model_config_1.get_layer('bottleneck').output)\n",
        "\n",
        "# Create a decoder model\n",
        "bottleneck_input = tf.keras.Input(shape=(encoder.output.shape[1],))\n",
        "x = bottleneck_input\n",
        "for layer_name in [l.name for l in best_model_config_1.layers if 'dense_decoder' in l.name]:\n",
        "    x = best_model_config_1.get_layer(layer_name)(x)\n",
        "decoder_output = best_model_config_1.get_layer('output_layer')(x)\n",
        "decoder = Model(inputs=bottleneck_input, outputs=decoder_output)\n"
      ],
      "metadata": {
        "id": "JSADgANkszGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "b7khEnRdszGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate bottleneck contributions\n",
        "def calculate_bottleneck_contributions(autoencoder, encoder, decoder, X):\n",
        "    bottleneck_output = encoder.predict(X)\n",
        "    contributions = []\n",
        "\n",
        "    for dim in range(bottleneck_output.shape[1]):\n",
        "        # Isolate one dimension at a time\n",
        "        isolated_latent = np.zeros_like(bottleneck_output)\n",
        "        isolated_latent[:, dim] = bottleneck_output[:, dim]\n",
        "\n",
        "        # Reconstruct input using only the isolated latent dimension\n",
        "        reconstructed = decoder.predict(isolated_latent)\n",
        "\n",
        "        # Compute reconstruction loss (e.g., MSE)\n",
        "        loss = mean_squared_error(X, reconstructed)\n",
        "        contributions.append(loss)\n",
        "\n",
        "    # Normalize contributions\n",
        "    contributions = np.array(contributions)\n",
        "    normalized_contributions = 1 - (contributions / np.sum(contributions))\n",
        "\n",
        "    return normalized_contributions"
      ],
      "metadata": {
        "id": "2XQsQ5J_szGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contributions\n",
        "contributions = calculate_bottleneck_contributions(best_model_config_1, encoder, decoder, X_train)\n",
        "\n",
        "# Print contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f50d5e2-9a39-40c4-8b20-b51979627dbc",
        "id": "ktY9_TsBszGJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c0f22aa1ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c0f22aa1ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.7957\n",
            "Latent Dimension 2: 0.7104\n",
            "Latent Dimension 3: 0.7155\n",
            "Latent Dimension 4: 0.7784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the contributions so they sum to 1\n",
        "def normalize_contributions(contributions):\n",
        "    total = sum(contributions)\n",
        "    return [c / total for c in contributions]\n",
        "\n",
        "# Calculate contributions\n",
        "#contributions = calculate_bottleneck_contributions(best_model_config_1, encoder, decoder, X_train)\n",
        "\n",
        "# Normalize contributions\n",
        "normalized_contributions = normalize_contributions(contributions)\n",
        "\n",
        "# Print normalized contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(normalized_contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")\n",
        "\n",
        "# Verify they sum to 1\n",
        "print(\"Sum of Normalized Contributions:\", sum(normalized_contributions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97771907-4a90-4993-f328-7f976e152993",
        "id": "O74zc4QLszGJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.2652\n",
            "Latent Dimension 2: 0.2368\n",
            "Latent Dimension 3: 0.2385\n",
            "Latent Dimension 4: 0.2595\n",
            "Sum of Normalized Contributions: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_contributions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d9c999-f005-4e81-8f73-f4c358c52e43",
        "id": "Qh1c1W0nszGN"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.26524618572247743,\n",
              " 0.2367890555818817,\n",
              " 0.23848427740582467,\n",
              " 0.25948048128981616]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_1 = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder_model_config_1 = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer_config_1)\n",
        "bottleneck_output_1 = encoder_model_config_1.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f5d120d-5c3d-4c68-b119-8de1e18bae7f",
        "id": "oj2-j42fszGN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions = np.array(normalized_contributions)\n",
        "\n",
        "# Calculate MI scores\n",
        "mi_scores = []\n",
        "for i in range(bottleneck_output_1.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_1[:, i], random_state=42)\n",
        "    mi_scores.append(mi)"
      ],
      "metadata": {
        "id": "NvbRyWposzGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c55798-3522-493c-e81b-5fb019b78f5f",
        "id": "Us8MzepJszGN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_1.shape[1]))\n",
        "\n",
        "# Multiply MI scores by latent space contributions for each bottleneck dimension\n",
        "for dim in range(bottleneck_output_1.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim] * latent_contributions[dim]"
      ],
      "metadata": {
        "id": "EmgRMs-0szGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f391de02-1ab3-4565-ddf3-b09441f6237d",
        "id": "nZsUMmHiszGN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.26524619, 0.23678906, 0.23848428, 0.25948048])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_mi_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc769ffe-19ce-408d-b220-e98700232875",
        "id": "EFQXHnqHszGN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01515752, 0.04344681, 0.10705445, 0.04080098],\n",
              "       [0.03881546, 0.00881835, 0.01268705, 0.02942444],\n",
              "       [0.02404602, 0.00827871, 0.01085959, 0.02392484],\n",
              "       [0.05136616, 0.01921884, 0.02615977, 0.04440986],\n",
              "       [0.01941352, 0.00858951, 0.01233614, 0.0486103 ],\n",
              "       [0.05409721, 0.01793388, 0.        , 0.04150236],\n",
              "       [0.00912314, 0.0764245 , 0.01076848, 0.06065779],\n",
              "       [0.02273975, 0.10227275, 0.09987156, 0.03804776],\n",
              "       [0.07799483, 0.11171129, 0.03973089, 0.08412775],\n",
              "       [0.07283676, 0.07978642, 0.0315235 , 0.03583767],\n",
              "       [0.06033529, 0.04812358, 0.03085356, 0.08893628],\n",
              "       [0.05010548, 0.05428267, 0.        , 0.05592727],\n",
              "       [0.03940379, 0.02494944, 0.08412399, 0.01787343],\n",
              "       [0.03112605, 0.02603981, 0.04735304, 0.05508552],\n",
              "       [0.05605788, 0.03219124, 0.05254708, 0.01771771],\n",
              "       [0.04733839, 0.05114924, 0.05850563, 0.03035254],\n",
              "       [0.03114441, 0.01501434, 0.09180902, 0.04365745],\n",
              "       [0.02593845, 0.02865191, 0.05071796, 0.01236865],\n",
              "       [0.05026577, 0.04466279, 0.        , 0.01340563],\n",
              "       [0.0805873 , 0.06055945, 0.04112003, 0.05901259],\n",
              "       [0.06938673, 0.03510842, 0.05712153, 0.07312158],\n",
              "       [0.02437204, 0.06827719, 0.03055265, 0.02016511],\n",
              "       [0.02637713, 0.01539711, 0.05455246, 0.02726833],\n",
              "       [0.02197091, 0.01911176, 0.04975164, 0.03776417]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))\n",
        "\n",
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "xWiDiXm2szGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Excel\n",
        "df.to_excel(\"real_se_AUTOENCODER_best_auto_config1_1208_with_weights_res_ss.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "sGtNTRhNszGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "config 2"
      ],
      "metadata": {
        "id": "g7IDYnpDszGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "id": "-VojCkOyszGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_2.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_2.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "id": "JyCxWqcJszGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffff36cc-39f7-4fae-d777-e410df34b43f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 5, 'neurons': 18, 'learning_rate': 0.01, 'batch_size': 16, 'activation': 'tanh', 'alpha': 0.01, 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0067'}\n",
            "\n",
            "Test Loss: 0.36945563554763794\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "[[ 1.         -0.05741718 -0.23807442  0.08793147 -0.03243081]\n",
            " [-0.05741718  1.          0.2016903  -0.14877315  0.16399051]\n",
            " [-0.23807442  0.2016903   1.         -0.52844769  0.21047439]\n",
            " [ 0.08793147 -0.14877315 -0.52844769  1.         -0.11207877]\n",
            " [-0.03243081  0.16399051  0.21047439 -0.11207877  1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract encoder and decoder from the trained autoencoder\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=best_model_config_2.get_layer('bottleneck').output)\n",
        "\n",
        "# Create a decoder model (assuming symmetric architecture)\n",
        "bottleneck_input = tf.keras.Input(shape=(encoder.output.shape[1],))\n",
        "x = bottleneck_input\n",
        "for layer_name in [l.name for l in best_model_config_2.layers if 'dense_decoder' in l.name]:\n",
        "    x = best_model_config_2.get_layer(layer_name)(x)\n",
        "decoder_output = best_model_config_2.get_layer('output_layer')(x)\n",
        "decoder = Model(inputs=bottleneck_input, outputs=decoder_output)"
      ],
      "metadata": {
        "id": "DG2AW-IgszGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contributions\n",
        "contributions = calculate_bottleneck_contributions(best_model_config_2, encoder, decoder, X_train)\n",
        "\n",
        "# Print contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a82ecdd5-049a-403e-9eeb-2af7ceca31c5",
        "id": "Cgx_bhO2szGO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.7905\n",
            "Latent Dimension 2: 0.8653\n",
            "Latent Dimension 3: 0.7955\n",
            "Latent Dimension 4: 0.7739\n",
            "Latent Dimension 5: 0.7747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize contributions\n",
        "normalized_contributions = normalize_contributions(contributions)\n",
        "\n",
        "# Print normalized contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(normalized_contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")\n",
        "\n",
        "# Verify sum to 1\n",
        "print(\"Sum of Normalized Contributions:\", sum(normalized_contributions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db3ed1f2-cccf-45b8-9bac-7c3eaf07529f",
        "id": "0KvB7_W4szGO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.1976\n",
            "Latent Dimension 2: 0.2163\n",
            "Latent Dimension 3: 0.1989\n",
            "Latent Dimension 4: 0.1935\n",
            "Latent Dimension 5: 0.1937\n",
            "Sum of Normalized Contributions: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_2 = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder_model_config_2 = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer_config_2)\n",
        "bottleneck_output_2 = encoder_model_config_2.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24ed5e4c-85f4-4a4f-d886-699389c87033",
        "id": "f80xOCFaszGO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions = np.array(normalized_contributions)\n",
        "\n",
        "mi_scores = []\n",
        "for i in range(bottleneck_output_2.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_2[:, i], random_state=42)\n",
        "    mi_scores.append(mi)"
      ],
      "metadata": {
        "id": "AFOr2uuEszGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d102243c-cdd5-49f2-b530-fb159bd91e09",
        "id": "uiLXmyIfszGO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_2.shape[1]))\n",
        "\n",
        "# Multiply MI scores by latent space contributions for each bottleneck dimension\n",
        "for dim in range(bottleneck_output_2.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim] * latent_contributions[dim]"
      ],
      "metadata": {
        "id": "UFloGvEGszGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))\n",
        "\n",
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "InoVF6FRszGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Excel\n",
        "df.to_excel(\"real_se_AUTOENCODER_best_auto_config2_1215_with_weights_res_ss.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "_f-W4tdjszGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_config_1.summary()"
      ],
      "metadata": {
        "id": "kNyOrdkCinmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_config_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "5e279ece-6a0e-48eb-9ae5-4d63cb7202dc",
        "id": "PVc8g-VFszGP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m450\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m95\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ orthogonal_regularization            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mOrthogonalRegularization\u001b[0m)           │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m108\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  │             \u001b[38;5;34m342\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m456\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ orthogonal_regularization            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OrthogonalRegularization</span>)           │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">456</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,477\u001b[0m (9.68 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,477</span> (9.68 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,477\u001b[0m (9.68 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,477</span> (9.68 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## res - different numbers of nerons with regularization techiniques (alpha tuned) - corr minmax (method 3)"
      ],
      "metadata": {
        "id": "lzpPN4Qu3uA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('SE_Original_(NOT SHARED) FOR USE_2020_residential.xlsx')\n",
        "X_ori = data.iloc[:, 3:27].values\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X_ori)\n",
        "\n",
        "# Split\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "brF5BS0r3uA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "def create_autoencoder(input_dim, encoding_dim, hidden_layers_before, hidden_layers_after, neurons_before, neurons_after):\n",
        "    # Define the input layer\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "\n",
        "    # Build the encoder part\n",
        "    x = input_layer\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons_before, activation='relu', name=f'dense_encoder_{i+1}')(x)\n",
        "\n",
        "    # Bottleneck layer (encoding layer)\n",
        "    bottleneck = Dense(encoding_dim, activation='relu', name='bottleneck')(x)\n",
        "\n",
        "    # Build the decoder part\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons_after, activation='relu', name=f'dense_decoder_{i+1}')(x)\n",
        "\n",
        "    # Output layer, with the same dimension as the input\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Define the complete autoencoder model\n",
        "    autoencoder = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "FBv3sAOe3uA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial tuning\n",
        "hidden_layers_options = [2, 4, 6, 8]  # Even numbers to ensure symmetry\n",
        "neurons_options = [8, 12, 16]\n",
        "encoding_dims_options = [1, 2, 3, 4, 5]\n",
        "results = []\n",
        "\n",
        "# Iterate through each combination of hyperparameters\n",
        "for hidden_layers in hidden_layers_options:\n",
        "    hidden_layers_before = hidden_layers // 2\n",
        "    hidden_layers_after = hidden_layers // 2\n",
        "\n",
        "    for neurons in neurons_options:\n",
        "        for encoding_dim in encoding_dims_options:\n",
        "            autoencoder = create_autoencoder(\n",
        "                input_dim=X_train.shape[1],\n",
        "                encoding_dim=encoding_dim,\n",
        "                hidden_layers_before=hidden_layers_before,\n",
        "                hidden_layers_after=hidden_layers_after,\n",
        "                neurons_before=neurons,\n",
        "                neurons_after=neurons\n",
        "            )\n",
        "            autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "            history = autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, verbose=0, validation_data=(X_test, X_test))\n",
        "\n",
        "            # Calculate average loss on the test set\n",
        "            test_loss = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
        "            results.append((hidden_layers, encoding_dim, neurons, test_loss))\n",
        "\n",
        "# Sort results by the lowest test loss and select the best two configurations\n",
        "sorted_results = sorted(results, key=lambda x: x[3])\n",
        "best_configs = sorted_results[:2]\n",
        "\n",
        "# Print best configurations\n",
        "print(\"Top two configurations:\")\n",
        "for config in best_configs:\n",
        "    hidden_layers, encoding_dim, neurons, test_loss = config\n",
        "    print(f\"Hidden layers: {hidden_layers}, Encoding dimension: {encoding_dim}, Neurons: {neurons}, Test loss: {test_loss}\")\n",
        "\n",
        "    # Recreate and display the model summary for the best configurations\n",
        "    autoencoder = create_autoencoder(\n",
        "        input_dim=X_train.shape[1],\n",
        "        encoding_dim=encoding_dim,\n",
        "        hidden_layers_before=hidden_layers // 2,\n",
        "        hidden_layers_after=hidden_layers // 2,\n",
        "        neurons_before=neurons,\n",
        "        neurons_after=neurons\n",
        "    )\n",
        "    autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "6662c8bd-a87c-48b4-ccbf-23130f920978",
        "id": "sK4-B5GR3uA9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top two configurations:\n",
            "Hidden layers: 4, Encoding dimension: 5, Neurons: 16, Test loss: 0.02714536152780056\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m96\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m408\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,533\u001b[0m (5.99 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,533</span> (5.99 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,533\u001b[0m (5.99 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,533</span> (5.99 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden layers: 2, Encoding dimension: 3, Neurons: 16, Test loss: 0.03079284355044365\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m408\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">408</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m923\u001b[0m (3.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">923</span> (3.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m923\u001b[0m (3.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">923</span> (3.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "add orthogonal regularization (w/ alpha tuned)"
      ],
      "metadata": {
        "id": "SvuEgRPC3uA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "# Custom layer for orthogonal regularization\n",
        "class OrthogonalRegularization(Layer):\n",
        "    def __init__(self, alpha=1e-2, **kwargs):\n",
        "        super(OrthogonalRegularization, self).__init__(**kwargs)\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def call(self, bottleneck_output):\n",
        "        # Get the batch size\n",
        "        batch_size = tf.cast(tf.shape(bottleneck_output)[0], tf.float32)\n",
        "\n",
        "        # Normalize the bottleneck outputs\n",
        "        normalized_output = bottleneck_output / tf.sqrt(batch_size)\n",
        "\n",
        "        # Compute correlation matrix\n",
        "        correlation = tf.matmul(\n",
        "            tf.transpose(normalized_output),\n",
        "            normalized_output\n",
        "        )\n",
        "\n",
        "        # Create identity matrix of the correct shape\n",
        "        shape = tf.shape(correlation)[0]\n",
        "        identity = tf.eye(shape)\n",
        "\n",
        "        # Calculate loss (excluding diagonal elements)\n",
        "        mask = tf.ones_like(correlation) - tf.eye(shape)\n",
        "        loss = tf.reduce_sum(tf.square(correlation * mask))\n",
        "\n",
        "        # Add loss to the layer\n",
        "        self.add_loss(self.alpha * loss)\n",
        "\n",
        "        return bottleneck_output\n"
      ],
      "metadata": {
        "id": "NHi5fuqo3uA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp, input_dim, hidden_layers_before, hidden_layers_after):\n",
        "    # Hyperparameters to tune\n",
        "    encoding_dim = hp.Int('encoding_dim', min_value=2, max_value=5, step=1)\n",
        "    neurons = hp.Int('neurons', min_value=6, max_value=24, step=3)\n",
        "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "    batch_size = hp.Choice('batch_size', [16, 32, 64])\n",
        "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "    # alpha tuned\n",
        "    alpha = hp.Choice('alpha', [1e-3, 1e-2, 1e-1, 1.0])\n",
        "\n",
        "    # Build the model structure\n",
        "    input_layer = Input(shape=(input_dim,), name='input_layer')\n",
        "    x = input_layer\n",
        "\n",
        "    # Encoder layers\n",
        "    for i in range(hidden_layers_before):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_encoder_{i+1}')(x)\n",
        "\n",
        "    # Bottleneck layer with orthogonal regularization\n",
        "    bottleneck = Dense(\n",
        "        encoding_dim,\n",
        "        activation=activation,\n",
        "        kernel_constraint=tf.keras.constraints.UnitNorm(axis=0),\n",
        "        name='bottleneck'\n",
        "    )(x)\n",
        "\n",
        "    # Apply orthogonal regularization\n",
        "    bottleneck = OrthogonalRegularization(alpha=alpha)(bottleneck) #modified alpha for tunin\n",
        "\n",
        "    # Decoder layers\n",
        "    x = bottleneck\n",
        "    for i in range(hidden_layers_after):\n",
        "        x = Dense(neurons, activation=activation, name=f'dense_decoder_{i+1}')(x)\n",
        "\n",
        "    output_layer = Dense(input_dim, name='output_layer')(x)\n",
        "\n",
        "    # Create and compile model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer, name='autoencoder_model')\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        loss='mse'  # Using standard MSE loss now\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "-Ef5dMYt3uA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import Hyperband\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "bwqdHa6m3uA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        min_delta=1e-4\n",
        "    )\n",
        "]\n"
      ],
      "metadata": {
        "id": "S2A6GeQL3uA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define search space for each configuration\n",
        "tuner_config_1 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=2, hidden_layers_after=2),\n",
        "    objective='val_loss',\n",
        "    max_epochs=50,\n",
        "    factor=3,\n",
        "    directory='hyperpara_tuning_1_ortho_aaaal',\n",
        "    project_name='model_config_1'\n",
        ")\n",
        "\n",
        "# Define search space for each configuration\n",
        "tuner_config_2 = Hyperband(\n",
        "    lambda hp: build_model(hp, input_dim=24, hidden_layers_before=1, hidden_layers_after=1),\n",
        "    objective='val_loss',\n",
        "    max_epochs=50,\n",
        "    factor=3,\n",
        "    directory='hyperpara_tuning_2_ortho_aaaal',\n",
        "    project_name='model_config_2',\n",
        "    overwrite=True\n",
        ")"
      ],
      "metadata": {
        "id": "z7w8VrY-3uA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning\n",
        "tuner_config_1.search(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs=50,\n",
        "    validation_data=(X_test, X_test),\n",
        "    callbacks=callbacks,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IiBxex_3uA-",
        "outputId": "828026df-654e-4e91-fc2e-ac34679f0800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 27s]\n",
            "val_loss: 0.014893291518092155\n",
            "\n",
            "Best val_loss So Far: 0.013995358720421791\n",
            "Total elapsed time: 00h 35m 36s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the tuning\n",
        "tuner_config_2.search(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs=50,\n",
        "    validation_data=(X_test, X_test),\n",
        "    callbacks=callbacks,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57546666-1177-4a78-9111-6d8fc47e880d",
        "id": "2Do9KvzN3uA-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 90 Complete [00h 00m 27s]\n",
            "val_loss: 0.28906935453414917\n",
            "\n",
            "Best val_loss So Far: 0.01418523769825697\n",
            "Total elapsed time: 00h 30m 09s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### regularization"
      ],
      "metadata": {
        "id": "PIDwYSlE3uA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model_config_1 = tuner_config_1.get_best_models(num_models=1)[0]\n",
        "best_hp_config_1 = tuner_config_1.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "id": "3NYQTei53uA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_1.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_1.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fef741b-7912-4e3c-bdb4-a78541bcadfe",
        "id": "IwfTvLF43uA_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 5, 'neurons': 15, 'learning_rate': 0.01, 'batch_size': 32, 'activation': 'tanh', 'alpha': 0.01, 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0074'}\n",
            "\n",
            "Test Loss: 0.013995358720421791\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "[[ 1.         -0.46536019 -0.17613831  0.386343    0.1593035 ]\n",
            " [-0.46536019  1.          0.12871877  0.16985815 -0.01367104]\n",
            " [-0.17613831  0.12871877  1.         -0.13108603 -0.71509113]\n",
            " [ 0.386343    0.16985815 -0.13108603  1.          0.02495951]\n",
            " [ 0.1593035  -0.01367104 -0.71509113  0.02495951  1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer"
      ],
      "metadata": {
        "id": "SDmYj_HV3uA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract encoder and decoder from the trained autoencoder\n",
        "encoder = Model(inputs=best_model_config_1.input, outputs=best_model_config_1.get_layer('bottleneck').output)\n",
        "\n",
        "# Create a decoder model\n",
        "bottleneck_input = tf.keras.Input(shape=(encoder.output.shape[1],))\n",
        "x = bottleneck_input\n",
        "for layer_name in [l.name for l in best_model_config_1.layers if 'dense_decoder' in l.name]:\n",
        "    x = best_model_config_1.get_layer(layer_name)(x)\n",
        "decoder_output = best_model_config_1.get_layer('output_layer')(x)\n",
        "decoder = Model(inputs=bottleneck_input, outputs=decoder_output)\n"
      ],
      "metadata": {
        "id": "F2e7z4bt3uA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "R7Skpw-v3uA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate bottleneck contributions\n",
        "def calculate_bottleneck_contributions(autoencoder, encoder, decoder, X):\n",
        "    bottleneck_output = encoder.predict(X)\n",
        "    contributions = []\n",
        "\n",
        "    for dim in range(bottleneck_output.shape[1]):\n",
        "        # Isolate one dimension at a time\n",
        "        isolated_latent = np.zeros_like(bottleneck_output)\n",
        "        isolated_latent[:, dim] = bottleneck_output[:, dim]\n",
        "\n",
        "        # Reconstruct input using only the isolated latent dimension\n",
        "        reconstructed = decoder.predict(isolated_latent)\n",
        "\n",
        "        # Compute reconstruction loss (e.g., MSE)\n",
        "        loss = mean_squared_error(X, reconstructed)\n",
        "        contributions.append(loss)\n",
        "\n",
        "    # Normalize contributions\n",
        "    contributions = np.array(contributions)\n",
        "    normalized_contributions = 1 - (contributions / np.sum(contributions))\n",
        "\n",
        "    return normalized_contributions"
      ],
      "metadata": {
        "id": "5LX-g0l93uA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contributions\n",
        "contributions = calculate_bottleneck_contributions(best_model_config_1, encoder, decoder, X_train)\n",
        "\n",
        "# Print contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24be7775-7825-4cd1-889a-fe7ebe5fcf59",
        "id": "w4sSD06z3uA_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.8069\n",
            "Latent Dimension 2: 0.7815\n",
            "Latent Dimension 3: 0.7851\n",
            "Latent Dimension 4: 0.7891\n",
            "Latent Dimension 5: 0.8374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the contributions so they sum to 1\n",
        "def normalize_contributions(contributions):\n",
        "    total = sum(contributions)\n",
        "    return [c / total for c in contributions]\n",
        "\n",
        "# Calculate contributions\n",
        "#contributions = calculate_bottleneck_contributions(best_model_config_1, encoder, decoder, X_train)\n",
        "\n",
        "# Normalize contributions\n",
        "normalized_contributions = normalize_contributions(contributions)\n",
        "\n",
        "# Print normalized contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(normalized_contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")\n",
        "\n",
        "# Verify they sum to 1\n",
        "print(\"Sum of Normalized Contributions:\", sum(normalized_contributions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22be1c78-2385-48ba-e0cc-90b51c2814e3",
        "id": "qMGY8Hhb3uA_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.2017\n",
            "Latent Dimension 2: 0.1954\n",
            "Latent Dimension 3: 0.1963\n",
            "Latent Dimension 4: 0.1973\n",
            "Latent Dimension 5: 0.2093\n",
            "Sum of Normalized Contributions: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_contributions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e07c9ae5-64bc-4812-ed4a-c0626862f565",
        "id": "hXzG3X7r3uA_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2017209275480649,\n",
              " 0.1953778954574629,\n",
              " 0.19627121162009706,\n",
              " 0.19728387606967646,\n",
              " 0.20934608930469867]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_1 = best_model_config_1.get_layer('bottleneck').output\n",
        "encoder_model_config_1 = Model(inputs=best_model_config_1.input, outputs=bottleneck_layer_config_1)\n",
        "bottleneck_output_1 = encoder_model_config_1.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee5b38b-667c-439d-8ebf-b22ec358fa69",
        "id": "EGMrCSHB3uBA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions = np.array(normalized_contributions)\n",
        "\n",
        "# Calculate MI scores (as you have done)\n",
        "mi_scores = []\n",
        "for i in range(bottleneck_output_1.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_1[:, i], random_state=42)\n",
        "    mi_scores.append(mi)"
      ],
      "metadata": {
        "id": "OUxVGC4D3uBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c6bd819-1025-4a26-98a4-51f178c52fd8",
        "id": "39mCG9cS3uBA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_1.shape[1]))\n",
        "\n",
        "# Multiply MI scores by latent space contributions for each bottleneck dimension\n",
        "for dim in range(bottleneck_output_1.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim] * latent_contributions[dim]"
      ],
      "metadata": {
        "id": "kRERbnrd3uBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c312bfcf-f9cd-43b2-ef0c-c1d830c1662f",
        "id": "YhvKpPgo3uBA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.20172093, 0.1953779 , 0.19627121, 0.19728388, 0.20934609])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_mi_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b3323a0-aba6-4df4-cf41-a3ca0d5548ba",
        "id": "42Q3ULsz3uBA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01061809, 0.04500234, 0.1841634 , 0.02868507, 0.00264859],\n",
              "       [0.034778  , 0.02973155, 0.0175726 , 0.0091104 , 0.01922639],\n",
              "       [0.02159798, 0.        , 0.02811489, 0.0065976 , 0.04262017],\n",
              "       [0.05439743, 0.04675682, 0.08121578, 0.03555676, 0.04973733],\n",
              "       [0.01632044, 0.05920884, 0.03681562, 0.02004051, 0.0769772 ],\n",
              "       [0.03846599, 0.05177864, 0.01978123, 0.02037407, 0.01624436],\n",
              "       [0.02700845, 0.0138545 , 0.08366913, 0.01874064, 0.10841944],\n",
              "       [0.04339917, 0.02219113, 0.02837722, 0.11118942, 0.04457535],\n",
              "       [0.10355425, 0.06314486, 0.07429056, 0.12223077, 0.09346068],\n",
              "       [0.07685915, 0.        , 0.03212188, 0.05236498, 0.01881084],\n",
              "       [0.06984075, 0.05250568, 0.0676716 , 0.05597111, 0.08803421],\n",
              "       [0.06071397, 0.04516453, 0.02626451, 0.01693235, 0.04702483],\n",
              "       [0.02449276, 0.04617539, 0.0340543 , 0.03401939, 0.        ],\n",
              "       [0.03118851, 0.02612447, 0.01898988, 0.02386067, 0.03067785],\n",
              "       [0.0600746 , 0.03176965, 0.03869805, 0.07959209, 0.06084089],\n",
              "       [0.04754967, 0.03723453, 0.04591112, 0.08664514, 0.04257067],\n",
              "       [0.02063077, 0.01506327, 0.0850597 , 0.04534999, 0.03491679],\n",
              "       [0.01417877, 0.0127853 , 0.        , 0.00906763, 0.        ],\n",
              "       [0.03323646, 0.0214178 , 0.02043822, 0.01983247, 0.01752255],\n",
              "       [0.09142624, 0.04460735, 0.03574237, 0.07502024, 0.0574225 ],\n",
              "       [0.07326958, 0.11152761, 0.02292329, 0.04880811, 0.05276458],\n",
              "       [0.00506848, 0.15333525, 0.        , 0.03389497, 0.05140995],\n",
              "       [0.0223597 , 0.04363906, 0.        , 0.01859402, 0.00836979],\n",
              "       [0.01897079, 0.02698144, 0.01812464, 0.02752159, 0.03572504]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))\n",
        "\n",
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "CNWbbdhk3uBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excel\n",
        "df.to_excel(\"real_se_AUTOENCODER_best_auto_config1_1208_with_weights_res_mm.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "LWj8lmqy3uBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "config 2"
      ],
      "metadata": {
        "id": "-YKJO02V3uBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model_config_2 = tuner_config_2.get_best_models(num_models=1)[0]\n",
        "best_hp_config_2 = tuner_config_2.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c831c2-6b36-4487-8bf8-035dfbfbb4a3",
        "id": "jfhktpCB3uBA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(best_hp_config_2.values)\n",
        "\n",
        "# Evaluate final model\n",
        "evaluation = best_model_config_2.evaluate(X_test, X_test, verbose=0)\n",
        "print(f\"\\nTest Loss: {evaluation}\")\n",
        "\n",
        "# Extract and analyze bottleneck features\n",
        "bottleneck_layer = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer)\n",
        "bottleneck_features = encoder.predict(X_test)\n",
        "\n",
        "# Check correlation between latent features\n",
        "correlation_matrix = np.corrcoef(bottleneck_features.T)\n",
        "print(\"\\nLatent Feature Correlations:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpVjOmoa3uBB",
        "outputId": "9122f6c2-43bd-461a-c93e-b562dca7dc54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "{'encoding_dim': 5, 'neurons': 12, 'learning_rate': 0.01, 'batch_size': 64, 'activation': 'tanh', 'alpha': 0.1, 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0047'}\n",
            "\n",
            "Test Loss: 0.01418523769825697\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\n",
            "Latent Feature Correlations:\n",
            "[[ 1.         -0.03277693  0.38937205  0.21014547 -0.35259869]\n",
            " [-0.03277693  1.          0.66381462  0.10107188  0.18910883]\n",
            " [ 0.38937205  0.66381462  1.         -0.12258518 -0.16552352]\n",
            " [ 0.21014547  0.10107188 -0.12258518  1.          0.02782786]\n",
            " [-0.35259869  0.18910883 -0.16552352  0.02782786  1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract encoder and decoder from the trained autoencoder\n",
        "encoder = Model(inputs=best_model_config_2.input, outputs=best_model_config_2.get_layer('bottleneck').output)\n",
        "\n",
        "# Create a decoder model (assuming symmetric architecture)\n",
        "bottleneck_input = tf.keras.Input(shape=(encoder.output.shape[1],))\n",
        "x = bottleneck_input\n",
        "for layer_name in [l.name for l in best_model_config_2.layers if 'dense_decoder' in l.name]:\n",
        "    x = best_model_config_2.get_layer(layer_name)(x)\n",
        "decoder_output = best_model_config_2.get_layer('output_layer')(x)\n",
        "decoder = Model(inputs=bottleneck_input, outputs=decoder_output)"
      ],
      "metadata": {
        "id": "sgHrU3GT3uBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contributions\n",
        "contributions = calculate_bottleneck_contributions(best_model_config_2, encoder, decoder, X_train)\n",
        "\n",
        "# Print contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "848acda8-f262-42b7-da97-b6841d25c830",
        "id": "pGypeBCg3uBB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.8806\n",
            "Latent Dimension 2: 0.7722\n",
            "Latent Dimension 3: 0.7909\n",
            "Latent Dimension 4: 0.7751\n",
            "Latent Dimension 5: 0.7813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize contributions\n",
        "normalized_contributions = normalize_contributions(contributions)\n",
        "\n",
        "# Print normalized contributions\n",
        "print(\"Normalized Contributions of Each Bottleneck Dimension:\")\n",
        "for i, c in enumerate(normalized_contributions):\n",
        "    print(f\"Latent Dimension {i+1}: {c:.4f}\")\n",
        "\n",
        "# Verify sum to 1\n",
        "print(\"Sum of Normalized Contributions:\", sum(normalized_contributions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe2a1f8-bc76-4009-e4e9-ff7428a0e857",
        "id": "i-BQHu4P3uBB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Contributions of Each Bottleneck Dimension:\n",
            "Latent Dimension 1: 0.2202\n",
            "Latent Dimension 2: 0.1931\n",
            "Latent Dimension 3: 0.1977\n",
            "Latent Dimension 4: 0.1938\n",
            "Latent Dimension 5: 0.1953\n",
            "Sum of Normalized Contributions: 0.9999999999999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_layer_config_2 = best_model_config_2.get_layer('bottleneck').output\n",
        "encoder_model_config_2 = Model(inputs=best_model_config_2.input, outputs=bottleneck_layer_config_2)\n",
        "bottleneck_output_2 = encoder_model_config_2.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d16e06-ca10-46b6-bbdb-984d9b29d161",
        "id": "pio6PRjs3uBB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_contributions = np.array(normalized_contributions)  # Make sure this is normalized\n",
        "\n",
        "mi_scores = []\n",
        "for i in range(bottleneck_output_2.shape[1]):\n",
        "    mi = mutual_info_regression(X, bottleneck_output_2[:, i], random_state=42)\n",
        "    mi_scores.append(mi)"
      ],
      "metadata": {
        "id": "_ReQ663q3uBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = np.array(mi_scores).T  # Transpose to (features, bottleneck_dim)\n",
        "mi_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54ec6665-0fa8-41c5-f467-fe63444176cf",
        "id": "w2MfOKZn3uBB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize MI scores per bottleneck dimension\n",
        "normalized_mi_scores = mi_scores / np.sum(mi_scores, axis=0)\n",
        "\n",
        "# Initialize an array to store weighted values\n",
        "weighted_values = np.zeros((X.shape[0], X.shape[1], bottleneck_output_2.shape[1]))\n",
        "\n",
        "# Multiply MI scores by latent space contributions for each bottleneck dimension\n",
        "for dim in range(bottleneck_output_2.shape[1]):\n",
        "    weighted_values[:, :, dim] = X * normalized_mi_scores[:, dim] * latent_contributions[dim]"
      ],
      "metadata": {
        "id": "tRNsxV_b3uBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum across bottleneck dimensions for a single weighted value per feature\n",
        "summed_features = np.sum(weighted_values, axis=2)\n",
        "\n",
        "# Sum across features to get the final index\n",
        "final_index = np.sum(summed_features, axis=1)\n",
        "\n",
        "# Reshape and append final index as a new column in X\n",
        "final_index_column = final_index.reshape(-1, 1)\n",
        "X_with_index = np.hstack((X, final_index_column))\n",
        "\n",
        "# Create DataFrame and export to Excel\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])] + [\"Final_Index\"]\n",
        "df = pd.DataFrame(X_with_index, columns=column_names)"
      ],
      "metadata": {
        "id": "UlP0M3tt3uBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excel\n",
        "df.to_excel(\"real_se_AUTOENCODER_best_auto_config2_1208_with_weights_res_mm.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "T8iejVyX3uBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_config_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "f3fb880c-d78f-4649-9129-0e50b86152f1",
        "id": "qoBftwjk3uBC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m375\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m80\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ orthogonal_regularization            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mOrthogonalRegularization\u001b[0m)           │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │              \u001b[38;5;34m90\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m384\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ orthogonal_regularization            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OrthogonalRegularization</span>)           │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,409\u001b[0m (5.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,409</span> (5.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,409\u001b[0m (5.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,409</span> (5.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_config_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "969702af-e5c1-4762-a93d-9cc8456d38ab",
        "id": "5noct5343uBC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"autoencoder_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ orthogonal_regularization            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mOrthogonalRegularization\u001b[0m)           │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │              \u001b[38;5;34m72\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m312\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ orthogonal_regularization            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OrthogonalRegularization</span>)           │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m749\u001b[0m (2.93 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">749</span> (2.93 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m749\u001b[0m (2.93 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">749</span> (2.93 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}